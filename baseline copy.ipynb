{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import itertools\n",
    "import random\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from loss_functions import *\n",
    "from src.activation_functions import *\n",
    "from src.batch_normalization import *\n",
    "from src.data_preprocessing import *\n",
    "from src.ensemble.cascade_correlation import CascadeCorrelation\n",
    "from src.k_fold_cross_validation import *\n",
    "from src.layer import *\n",
    "from src.early_stopping import EarlyStopping\n",
    "from src.neural_network import *\n",
    "from src.optimizers import *\n",
    "from src.random_search import *\n",
    "from src.train_and_evaluate import Train\n",
    "from src.utils import *\n",
    "\n",
    "# from src.random_search import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### Data pre-processing for MONK Datasets  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoded data:  (169, 17)\n",
      "one hot encoded data:  (432, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data(MONK_NUM=2)\n",
    "X_test, y_test = load_data(MONK_NUM=2, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(X_train)\n",
    "y_train, y_val = train_test_split(y_train)\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 135\n",
      "Validation set size: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Validation set size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape:  (135, 17)\n",
      "the shape:  (34, 17)\n",
      "the shape:  (135, 1)\n",
      "the shape:  (34, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the resulting datasets\n",
    "for _ in [X_train, X_val, y_train, y_val]:\n",
    "    print(f\"the shape: \", _.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'hidden_size': [[3], [4], [5], [6], [8]],\n",
    "    'hidden_activation': [Activation_Tanh, Activation_Leaky_ReLU, Activation_Sigmoid, Activation_ReLU],\n",
    "    'batch_norm': [[True], [False]],\n",
    "    'learning_rate': [1e-2, 1e-4, 1e-3, 2e-4,1e-6, 1e-5],\n",
    "    'l1': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'l2': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'dropout_rate': [0.0, 0.1, 0.3],\n",
    "    'batch_size': [8, 16, 32],\n",
    "    'n_epochs': [100, 150, 200, 250, 300],\n",
    "    'weight_decay': [0, 5e-2, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'patience': [0, 20, 30, 50],\n",
    "    'CC': [False],\n",
    "    'weights_init': ['gaussian', 'gaussian_scaled', 'xavier', 'he', 'random'],\n",
    "    # # Define combinations of hidden layer sizes and corresponding activations\n",
    "    # 'hidden_configs': [\n",
    "    #     {'hidden_size': [10], 'hidden_activation': [Activation_Tanh], 'batch_norm' : [True]},\n",
    "    #     {'hidden_size': [10, 10], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm' : [True, True]},\n",
    "    #     {'hidden_size': [10, 10], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm' : [True, True]},\n",
    "    #     {'hidden_size': [20, 20], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm' : [True, False]},\n",
    "    #     {'hidden_size': [20, 20], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm' : [True, True]},\n",
    "    #     {'hidden_size': [20, 20], 'hidden_activation': [Activation_ELU, Activation_ELU], 'batch_norm' : [True, False]},\n",
    "    #     {'hidden_size': [10, 10], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm' : [True, False]},\n",
    "    #     {'hidden_size': [32, 16], 'hidden_activation': [Activation_Leaky_ReLU, Activation_Sigmoid], 'batch_norm' : [False, True]},  \n",
    "    #     {'hidden_size': [30, 30], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm' : [True, False]},\n",
    "    #     {'hidden_size': [64, 32, 16], 'hidden_activation': [Activation_ReLU, Activation_ReLU, Activation_Tanh], 'batch_norm' : [True, False, True]},\n",
    "    #     {'hidden_size': [30, 30], 'hidden_activation': [Activation_Leaky_ReLU, Activation_ELU], 'batch_norm': [True, False]}\n",
    "    # ]   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "Create a seperate best_results csv file for each MONK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2516, Acc: 48.21% | Val Loss: 0.2489, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2861, Acc: 45.54% | Val Loss: 0.2837, Acc: 37.04%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3704\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3031, Acc: 39.29% | Val Loss: 0.3105, Acc: 33.33%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.3333\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3205, Acc: 38.39% | Val Loss: 0.3640, Acc: 22.22%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2222\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2222\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.4278, Acc: 34.82% | Val Loss: 0.3860, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.3704\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2500, Acc: 60.94% | Val Loss: 0.2495, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2473, Acc: 64.84% | Val Loss: 0.2496, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2444, Acc: 66.67% | Val Loss: 0.2495, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2424, Acc: 67.97% | Val Loss: 0.2497, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2391, Acc: 69.27% | Val Loss: 0.2498, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2377, Acc: 69.27% | Val Loss: 0.2499, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2393, Acc: 65.36% | Val Loss: 0.2501, Acc: 51.85%\n",
      "Early stopping at epoch 67\n",
      "Restoring model weights from epoch 17\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2478, Acc: 64.32% | Val Loss: 0.2464, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2467, Acc: 64.32% | Val Loss: 0.2453, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2443, Acc: 61.72% | Val Loss: 0.2433, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2409, Acc: 63.02% | Val Loss: 0.2417, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2391, Acc: 63.02% | Val Loss: 0.2405, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2446, Acc: 60.42% | Val Loss: 0.2394, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2386, Acc: 64.32% | Val Loss: 0.2386, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2382, Acc: 63.02% | Val Loss: 0.2381, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2342, Acc: 65.62% | Val Loss: 0.2376, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2323, Acc: 65.62% | Val Loss: 0.2371, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2374, Acc: 61.72% | Val Loss: 0.2367, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.2337, Acc: 64.32% | Val Loss: 0.2364, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2382, Acc: 61.72% | Val Loss: 0.2361, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.2401, Acc: 59.11% | Val Loss: 0.2358, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2302, Acc: 66.93% | Val Loss: 0.2356, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2309, Acc: 64.32% | Val Loss: 0.2354, Acc: 62.96%\n",
      "Epoch 160: Train Loss: 0.2341, Acc: 63.02% | Val Loss: 0.2352, Acc: 62.96%\n",
      "Epoch 170: Train Loss: 0.2299, Acc: 65.62% | Val Loss: 0.2350, Acc: 62.96%\n",
      "Epoch 180: Train Loss: 0.2352, Acc: 64.32% | Val Loss: 0.2348, Acc: 62.96%\n",
      "Epoch 190: Train Loss: 0.2319, Acc: 64.32% | Val Loss: 0.2347, Acc: 62.96%\n",
      "Epoch 200: Train Loss: 0.2331, Acc: 64.32% | Val Loss: 0.2346, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.2305, Acc: 65.62% | Val Loss: 0.2344, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.2323, Acc: 64.32% | Val Loss: 0.2343, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.2261, Acc: 66.93% | Val Loss: 0.2342, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.2395, Acc: 63.02% | Val Loss: 0.2341, Acc: 62.96%\n",
      "Epoch 250: Train Loss: 0.2280, Acc: 65.62% | Val Loss: 0.2340, Acc: 62.96%\n",
      "Epoch 260: Train Loss: 0.2353, Acc: 63.02% | Val Loss: 0.2339, Acc: 62.96%\n",
      "Epoch 270: Train Loss: 0.2312, Acc: 65.62% | Val Loss: 0.2339, Acc: 62.96%\n",
      "Epoch 280: Train Loss: 0.2380, Acc: 64.32% | Val Loss: 0.2338, Acc: 62.96%\n",
      "Epoch 290: Train Loss: 0.2376, Acc: 63.02% | Val Loss: 0.2338, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2525, Acc: 38.54% | Val Loss: 0.2522, Acc: 29.63%\n",
      "Epoch 10: Train Loss: 0.2480, Acc: 65.10% | Val Loss: 0.2471, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2451, Acc: 67.45% | Val Loss: 0.2455, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2448, Acc: 64.84% | Val Loss: 0.2442, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2451, Acc: 62.24% | Val Loss: 0.2431, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2438, Acc: 63.54% | Val Loss: 0.2422, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2446, Acc: 60.94% | Val Loss: 0.2414, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2440, Acc: 60.94% | Val Loss: 0.2407, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2433, Acc: 62.24% | Val Loss: 0.2401, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2425, Acc: 62.24% | Val Loss: 0.2395, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.2450, Acc: 58.33% | Val Loss: 0.2390, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2440, Acc: 59.64% | Val Loss: 0.2385, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.2422, Acc: 62.24% | Val Loss: 0.2381, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.2399, Acc: 63.54% | Val Loss: 0.2377, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.2391, Acc: 64.84% | Val Loss: 0.2373, Acc: 66.67%\n",
      "Epoch 150: Train Loss: 0.2388, Acc: 66.15% | Val Loss: 0.2370, Acc: 66.67%\n",
      "Epoch 160: Train Loss: 0.2395, Acc: 63.54% | Val Loss: 0.2367, Acc: 66.67%\n",
      "Epoch 170: Train Loss: 0.2386, Acc: 64.84% | Val Loss: 0.2364, Acc: 66.67%\n",
      "Epoch 180: Train Loss: 0.2427, Acc: 60.94% | Val Loss: 0.2361, Acc: 66.67%\n",
      "Epoch 190: Train Loss: 0.2363, Acc: 66.15% | Val Loss: 0.2359, Acc: 66.67%\n",
      "Epoch 200: Train Loss: 0.2415, Acc: 60.94% | Val Loss: 0.2357, Acc: 66.67%\n",
      "Epoch 210: Train Loss: 0.2385, Acc: 63.54% | Val Loss: 0.2355, Acc: 66.67%\n",
      "Epoch 220: Train Loss: 0.2405, Acc: 62.24% | Val Loss: 0.2353, Acc: 66.67%\n",
      "Epoch 230: Train Loss: 0.2378, Acc: 63.54% | Val Loss: 0.2351, Acc: 66.67%\n",
      "Epoch 240: Train Loss: 0.2391, Acc: 62.24% | Val Loss: 0.2349, Acc: 66.67%\n",
      "Epoch 250: Train Loss: 0.2422, Acc: 60.94% | Val Loss: 0.2347, Acc: 66.67%\n",
      "Epoch 260: Train Loss: 0.2378, Acc: 63.54% | Val Loss: 0.2346, Acc: 66.67%\n",
      "Epoch 270: Train Loss: 0.2414, Acc: 60.94% | Val Loss: 0.2344, Acc: 66.67%\n",
      "Epoch 280: Train Loss: 0.2392, Acc: 63.54% | Val Loss: 0.2342, Acc: 66.67%\n",
      "Epoch 290: Train Loss: 0.2351, Acc: 64.84% | Val Loss: 0.2341, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2457, Acc: 54.95% | Val Loss: 0.2217, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.2470, Acc: 54.17% | Val Loss: 0.2212, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2393, Acc: 61.46% | Val Loss: 0.2191, Acc: 77.78%\n",
      "Epoch 30: Train Loss: 0.2359, Acc: 57.29% | Val Loss: 0.2187, Acc: 77.78%\n",
      "Epoch 40: Train Loss: 0.2375, Acc: 63.80% | Val Loss: 0.2198, Acc: 77.78%\n",
      "Epoch 50: Train Loss: 0.2414, Acc: 59.90% | Val Loss: 0.2200, Acc: 77.78%\n",
      "Epoch 60: Train Loss: 0.2366, Acc: 63.80% | Val Loss: 0.2183, Acc: 77.78%\n",
      "Epoch 70: Train Loss: 0.2368, Acc: 61.20% | Val Loss: 0.2170, Acc: 77.78%\n",
      "Epoch 80: Train Loss: 0.2370, Acc: 59.90% | Val Loss: 0.2161, Acc: 77.78%\n",
      "Epoch 90: Train Loss: 0.2364, Acc: 61.20% | Val Loss: 0.2148, Acc: 77.78%\n",
      "Epoch 100: Train Loss: 0.2428, Acc: 59.90% | Val Loss: 0.2140, Acc: 77.78%\n",
      "Epoch 110: Train Loss: 0.2428, Acc: 61.20% | Val Loss: 0.2142, Acc: 77.78%\n",
      "Epoch 120: Train Loss: 0.2309, Acc: 62.50% | Val Loss: 0.2138, Acc: 77.78%\n",
      "Epoch 130: Train Loss: 0.2420, Acc: 58.59% | Val Loss: 0.2128, Acc: 77.78%\n",
      "Epoch 140: Train Loss: 0.2355, Acc: 58.59% | Val Loss: 0.2124, Acc: 77.78%\n",
      "Epoch 150: Train Loss: 0.2362, Acc: 59.90% | Val Loss: 0.2119, Acc: 77.78%\n",
      "Epoch 160: Train Loss: 0.2367, Acc: 62.50% | Val Loss: 0.2114, Acc: 77.78%\n",
      "Epoch 170: Train Loss: 0.2337, Acc: 63.80% | Val Loss: 0.2109, Acc: 77.78%\n",
      "Epoch 180: Train Loss: 0.2424, Acc: 59.90% | Val Loss: 0.2104, Acc: 77.78%\n",
      "Epoch 190: Train Loss: 0.2384, Acc: 61.20% | Val Loss: 0.2102, Acc: 77.78%\n",
      "Epoch 200: Train Loss: 0.2398, Acc: 59.90% | Val Loss: 0.2097, Acc: 77.78%\n",
      "Epoch 210: Train Loss: 0.2391, Acc: 57.29% | Val Loss: 0.2093, Acc: 77.78%\n",
      "Epoch 220: Train Loss: 0.2403, Acc: 63.80% | Val Loss: 0.2089, Acc: 77.78%\n",
      "Epoch 230: Train Loss: 0.2361, Acc: 58.59% | Val Loss: 0.2088, Acc: 77.78%\n",
      "Epoch 240: Train Loss: 0.2327, Acc: 62.50% | Val Loss: 0.2085, Acc: 77.78%\n",
      "Epoch 250: Train Loss: 0.2436, Acc: 61.20% | Val Loss: 0.2084, Acc: 77.78%\n",
      "Epoch 260: Train Loss: 0.2310, Acc: 63.80% | Val Loss: 0.2084, Acc: 77.78%\n",
      "Epoch 270: Train Loss: 0.2391, Acc: 57.29% | Val Loss: 0.2083, Acc: 77.78%\n",
      "Epoch 280: Train Loss: 0.2343, Acc: 62.50% | Val Loss: 0.2084, Acc: 77.78%\n",
      "Epoch 290: Train Loss: 0.2395, Acc: 62.50% | Val Loss: 0.2081, Acc: 77.78%\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2567, Acc: 55.73% | Val Loss: 0.2371, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2358, Acc: 66.93% | Val Loss: 0.2311, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2278, Acc: 65.36% | Val Loss: 0.2319, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2237, Acc: 65.89% | Val Loss: 0.2334, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2391, Acc: 63.02% | Val Loss: 0.2338, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2315, Acc: 67.45% | Val Loss: 0.2341, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2224, Acc: 69.27% | Val Loss: 0.2343, Acc: 59.26%\n",
      "Early stopping at epoch 60\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6370\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3657, Acc: 42.26% | Val Loss: 0.2872, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3323, Acc: 51.49% | Val Loss: 0.2649, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2977, Acc: 57.44% | Val Loss: 0.2564, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2896, Acc: 58.33% | Val Loss: 0.2515, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2492, Acc: 68.15% | Val Loss: 0.2493, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2769, Acc: 56.25% | Val Loss: 0.2485, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2744, Acc: 58.04% | Val Loss: 0.2482, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2646, Acc: 57.14% | Val Loss: 0.2482, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2597, Acc: 57.14% | Val Loss: 0.2483, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2479, Acc: 60.12% | Val Loss: 0.2482, Acc: 51.85%\n",
      "Early stopping at epoch 95\n",
      "Restoring model weights from epoch 65\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3096, Acc: 55.95% | Val Loss: 0.2676, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2817, Acc: 58.93% | Val Loss: 0.2596, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2939, Acc: 51.79% | Val Loss: 0.2545, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2524, Acc: 61.61% | Val Loss: 0.2506, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2941, Acc: 54.17% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2640, Acc: 57.74% | Val Loss: 0.2473, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2490, Acc: 61.01% | Val Loss: 0.2458, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2756, Acc: 57.74% | Val Loss: 0.2441, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2784, Acc: 58.33% | Val Loss: 0.2426, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2633, Acc: 51.79% | Val Loss: 0.2413, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2461, Acc: 59.52% | Val Loss: 0.2403, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.2553, Acc: 56.55% | Val Loss: 0.2392, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2431, Acc: 60.71% | Val Loss: 0.2383, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.2370, Acc: 60.71% | Val Loss: 0.2376, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2555, Acc: 59.82% | Val Loss: 0.2369, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2152, Acc: 64.29% | Val Loss: 0.2362, Acc: 62.96%\n",
      "Epoch 160: Train Loss: 0.2335, Acc: 60.71% | Val Loss: 0.2356, Acc: 62.96%\n",
      "Epoch 170: Train Loss: 0.2558, Acc: 60.42% | Val Loss: 0.2350, Acc: 62.96%\n",
      "Epoch 180: Train Loss: 0.2285, Acc: 63.10% | Val Loss: 0.2346, Acc: 62.96%\n",
      "Epoch 190: Train Loss: 0.2504, Acc: 56.85% | Val Loss: 0.2341, Acc: 62.96%\n",
      "Epoch 200: Train Loss: 0.2358, Acc: 58.63% | Val Loss: 0.2336, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.2385, Acc: 63.69% | Val Loss: 0.2332, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.2164, Acc: 66.67% | Val Loss: 0.2328, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.2432, Acc: 53.87% | Val Loss: 0.2325, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.2351, Acc: 63.39% | Val Loss: 0.2323, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5926\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2806, Acc: 56.85% | Val Loss: 0.3162, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2849, Acc: 50.30% | Val Loss: 0.2851, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2934, Acc: 52.38% | Val Loss: 0.2745, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2717, Acc: 54.46% | Val Loss: 0.2684, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2686, Acc: 57.14% | Val Loss: 0.2644, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2637, Acc: 56.25% | Val Loss: 0.2615, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2599, Acc: 58.33% | Val Loss: 0.2598, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2345, Acc: 59.82% | Val Loss: 0.2585, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2547, Acc: 59.23% | Val Loss: 0.2574, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2391, Acc: 59.82% | Val Loss: 0.2564, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.2598, Acc: 58.63% | Val Loss: 0.2554, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2478, Acc: 58.33% | Val Loss: 0.2545, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.2386, Acc: 60.71% | Val Loss: 0.2539, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.2513, Acc: 59.82% | Val Loss: 0.2536, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.2501, Acc: 59.82% | Val Loss: 0.2533, Acc: 66.67%\n",
      "Epoch 150: Train Loss: 0.2363, Acc: 60.12% | Val Loss: 0.2531, Acc: 66.67%\n",
      "Epoch 160: Train Loss: 0.2403, Acc: 60.12% | Val Loss: 0.2530, Acc: 66.67%\n",
      "Epoch 170: Train Loss: 0.2497, Acc: 58.93% | Val Loss: 0.2528, Acc: 66.67%\n",
      "Epoch 180: Train Loss: 0.2393, Acc: 59.52% | Val Loss: 0.2526, Acc: 66.67%\n",
      "Epoch 190: Train Loss: 0.2411, Acc: 60.71% | Val Loss: 0.2524, Acc: 66.67%\n",
      "Epoch 200: Train Loss: 0.2307, Acc: 60.42% | Val Loss: 0.2522, Acc: 66.67%\n",
      "Epoch 210: Train Loss: 0.2310, Acc: 60.42% | Val Loss: 0.2521, Acc: 66.67%\n",
      "Epoch 220: Train Loss: 0.2358, Acc: 62.50% | Val Loss: 0.2520, Acc: 66.67%\n",
      "Epoch 230: Train Loss: 0.2340, Acc: 59.52% | Val Loss: 0.2520, Acc: 66.67%\n",
      "Epoch 240: Train Loss: 0.2285, Acc: 59.52% | Val Loss: 0.2519, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2513, Acc: 51.79% | Val Loss: 0.2501, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2480, Acc: 56.85% | Val Loss: 0.2410, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.2492, Acc: 57.14% | Val Loss: 0.2375, Acc: 70.37%\n",
      "Epoch 30: Train Loss: 0.2488, Acc: 58.93% | Val Loss: 0.2350, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.2419, Acc: 58.93% | Val Loss: 0.2329, Acc: 74.07%\n",
      "Epoch 50: Train Loss: 0.2421, Acc: 58.33% | Val Loss: 0.2312, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.2430, Acc: 57.44% | Val Loss: 0.2298, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.2456, Acc: 58.33% | Val Loss: 0.2290, Acc: 74.07%\n",
      "Epoch 80: Train Loss: 0.2423, Acc: 60.42% | Val Loss: 0.2281, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.2515, Acc: 59.82% | Val Loss: 0.2271, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.2339, Acc: 62.50% | Val Loss: 0.2266, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.2416, Acc: 60.12% | Val Loss: 0.2261, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.2405, Acc: 61.31% | Val Loss: 0.2256, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.2387, Acc: 60.42% | Val Loss: 0.2253, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.2410, Acc: 62.20% | Val Loss: 0.2249, Acc: 74.07%\n",
      "Epoch 150: Train Loss: 0.2439, Acc: 58.93% | Val Loss: 0.2245, Acc: 74.07%\n",
      "Epoch 160: Train Loss: 0.2355, Acc: 64.58% | Val Loss: 0.2241, Acc: 74.07%\n",
      "Epoch 170: Train Loss: 0.2330, Acc: 61.01% | Val Loss: 0.2236, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.2455, Acc: 60.42% | Val Loss: 0.2233, Acc: 74.07%\n",
      "Epoch 190: Train Loss: 0.2381, Acc: 62.20% | Val Loss: 0.2229, Acc: 74.07%\n",
      "Epoch 200: Train Loss: 0.2392, Acc: 61.90% | Val Loss: 0.2226, Acc: 74.07%\n",
      "Epoch 210: Train Loss: 0.2413, Acc: 61.31% | Val Loss: 0.2221, Acc: 74.07%\n",
      "Epoch 220: Train Loss: 0.2383, Acc: 62.20% | Val Loss: 0.2219, Acc: 74.07%\n",
      "Epoch 230: Train Loss: 0.2407, Acc: 60.42% | Val Loss: 0.2217, Acc: 74.07%\n",
      "Epoch 240: Train Loss: 0.2337, Acc: 62.80% | Val Loss: 0.2213, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2655, Acc: 54.46% | Val Loss: 0.2512, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2818, Acc: 50.00% | Val Loss: 0.2480, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2589, Acc: 49.70% | Val Loss: 0.2482, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2382, Acc: 51.49% | Val Loss: 0.2491, Acc: 66.67%\n",
      "Early stopping at epoch 39\n",
      "Restoring model weights from epoch 9\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6667\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6370\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2956, Acc: 41.07% | Val Loss: 0.2845, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2201, Acc: 65.48% | Val Loss: 0.2835, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2090, Acc: 66.37% | Val Loss: 0.2822, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.1953, Acc: 70.83% | Val Loss: 0.2740, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.1862, Acc: 72.62% | Val Loss: 0.2649, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.1889, Acc: 68.15% | Val Loss: 0.2601, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.1748, Acc: 75.00% | Val Loss: 0.2509, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.1627, Acc: 74.70% | Val Loss: 0.2435, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.1599, Acc: 72.32% | Val Loss: 0.2346, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.1633, Acc: 71.73% | Val Loss: 0.2264, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.1497, Acc: 77.68% | Val Loss: 0.2206, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.1476, Acc: 77.68% | Val Loss: 0.2166, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.1406, Acc: 79.17% | Val Loss: 0.2124, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.1422, Acc: 78.87% | Val Loss: 0.2084, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.1375, Acc: 80.65% | Val Loss: 0.2054, Acc: 59.26%\n",
      "Epoch 150: Train Loss: 0.1293, Acc: 84.52% | Val Loss: 0.2019, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.1346, Acc: 82.14% | Val Loss: 0.1983, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.1277, Acc: 82.14% | Val Loss: 0.1948, Acc: 59.26%\n",
      "Epoch 180: Train Loss: 0.1261, Acc: 82.44% | Val Loss: 0.1911, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.1275, Acc: 82.14% | Val Loss: 0.1874, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.1168, Acc: 86.01% | Val Loss: 0.1844, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.1095, Acc: 89.88% | Val Loss: 0.1811, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.1146, Acc: 89.58% | Val Loss: 0.1779, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.1054, Acc: 90.77% | Val Loss: 0.1748, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.1085, Acc: 88.69% | Val Loss: 0.1724, Acc: 62.96%\n",
      "Epoch 250: Train Loss: 0.1076, Acc: 89.88% | Val Loss: 0.1688, Acc: 62.96%\n",
      "Epoch 260: Train Loss: 0.1116, Acc: 89.58% | Val Loss: 0.1662, Acc: 66.67%\n",
      "Epoch 270: Train Loss: 0.1039, Acc: 91.67% | Val Loss: 0.1638, Acc: 66.67%\n",
      "Epoch 280: Train Loss: 0.1013, Acc: 92.86% | Val Loss: 0.1612, Acc: 70.37%\n",
      "Epoch 290: Train Loss: 0.0984, Acc: 93.15% | Val Loss: 0.1596, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6667\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3109, Acc: 44.64% | Val Loss: 0.3173, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2315, Acc: 57.14% | Val Loss: 0.2479, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2190, Acc: 62.50% | Val Loss: 0.2443, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2052, Acc: 68.75% | Val Loss: 0.2437, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.1949, Acc: 72.92% | Val Loss: 0.2409, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.1975, Acc: 69.64% | Val Loss: 0.2389, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.1785, Acc: 77.38% | Val Loss: 0.2355, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.1725, Acc: 75.00% | Val Loss: 0.2318, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.1743, Acc: 75.89% | Val Loss: 0.2283, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.1604, Acc: 79.46% | Val Loss: 0.2256, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.1564, Acc: 79.76% | Val Loss: 0.2242, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.1467, Acc: 82.74% | Val Loss: 0.2231, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.1470, Acc: 82.74% | Val Loss: 0.2218, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.1584, Acc: 81.55% | Val Loss: 0.2197, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.1537, Acc: 83.04% | Val Loss: 0.2180, Acc: 66.67%\n",
      "Epoch 150: Train Loss: 0.1372, Acc: 84.82% | Val Loss: 0.2169, Acc: 66.67%\n",
      "Epoch 160: Train Loss: 0.1508, Acc: 81.55% | Val Loss: 0.2154, Acc: 70.37%\n",
      "Epoch 170: Train Loss: 0.1408, Acc: 82.44% | Val Loss: 0.2143, Acc: 70.37%\n",
      "Epoch 180: Train Loss: 0.1406, Acc: 81.25% | Val Loss: 0.2140, Acc: 70.37%\n",
      "Epoch 190: Train Loss: 0.1391, Acc: 80.36% | Val Loss: 0.2129, Acc: 70.37%\n",
      "Epoch 200: Train Loss: 0.1315, Acc: 84.52% | Val Loss: 0.2120, Acc: 70.37%\n",
      "Epoch 210: Train Loss: 0.1295, Acc: 86.01% | Val Loss: 0.2109, Acc: 74.07%\n",
      "Epoch 220: Train Loss: 0.1217, Acc: 85.71% | Val Loss: 0.2106, Acc: 74.07%\n",
      "Epoch 230: Train Loss: 0.1215, Acc: 84.82% | Val Loss: 0.2103, Acc: 74.07%\n",
      "Epoch 240: Train Loss: 0.1357, Acc: 82.74% | Val Loss: 0.2092, Acc: 74.07%\n",
      "Epoch 250: Train Loss: 0.1200, Acc: 88.99% | Val Loss: 0.2086, Acc: 74.07%\n",
      "Epoch 260: Train Loss: 0.1180, Acc: 86.31% | Val Loss: 0.2082, Acc: 74.07%\n",
      "Epoch 270: Train Loss: 0.1313, Acc: 85.12% | Val Loss: 0.2079, Acc: 74.07%\n",
      "Epoch 280: Train Loss: 0.1138, Acc: 88.39% | Val Loss: 0.2067, Acc: 74.07%\n",
      "Epoch 290: Train Loss: 0.1200, Acc: 88.10% | Val Loss: 0.2061, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.7407\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2461, Acc: 49.70% | Val Loss: 0.2387, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2319, Acc: 65.48% | Val Loss: 0.2293, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2180, Acc: 67.26% | Val Loss: 0.2230, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.1996, Acc: 71.43% | Val Loss: 0.2178, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.1882, Acc: 75.30% | Val Loss: 0.2144, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.1829, Acc: 78.87% | Val Loss: 0.2098, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.1706, Acc: 74.70% | Val Loss: 0.2049, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.1611, Acc: 78.87% | Val Loss: 0.1987, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.1575, Acc: 82.14% | Val Loss: 0.1928, Acc: 70.37%\n",
      "Epoch 90: Train Loss: 0.1446, Acc: 83.04% | Val Loss: 0.1870, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.1469, Acc: 83.93% | Val Loss: 0.1809, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.1423, Acc: 81.55% | Val Loss: 0.1750, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.1327, Acc: 84.52% | Val Loss: 0.1696, Acc: 77.78%\n",
      "Epoch 130: Train Loss: 0.1341, Acc: 83.63% | Val Loss: 0.1646, Acc: 77.78%\n",
      "Epoch 140: Train Loss: 0.1202, Acc: 88.69% | Val Loss: 0.1601, Acc: 81.48%\n",
      "Epoch 150: Train Loss: 0.1216, Acc: 87.20% | Val Loss: 0.1559, Acc: 81.48%\n",
      "Epoch 160: Train Loss: 0.1209, Acc: 87.20% | Val Loss: 0.1516, Acc: 81.48%\n",
      "Epoch 170: Train Loss: 0.1149, Acc: 87.80% | Val Loss: 0.1475, Acc: 81.48%\n",
      "Epoch 180: Train Loss: 0.1039, Acc: 92.26% | Val Loss: 0.1439, Acc: 85.19%\n",
      "Epoch 190: Train Loss: 0.1050, Acc: 91.37% | Val Loss: 0.1402, Acc: 88.89%\n",
      "Epoch 200: Train Loss: 0.1128, Acc: 91.07% | Val Loss: 0.1373, Acc: 88.89%\n",
      "Epoch 210: Train Loss: 0.1013, Acc: 91.07% | Val Loss: 0.1339, Acc: 88.89%\n",
      "Epoch 220: Train Loss: 0.0914, Acc: 92.86% | Val Loss: 0.1308, Acc: 88.89%\n",
      "Epoch 230: Train Loss: 0.0990, Acc: 93.45% | Val Loss: 0.1282, Acc: 88.89%\n",
      "Epoch 240: Train Loss: 0.0900, Acc: 91.67% | Val Loss: 0.1256, Acc: 88.89%\n",
      "Epoch 250: Train Loss: 0.0868, Acc: 92.26% | Val Loss: 0.1231, Acc: 88.89%\n",
      "Epoch 260: Train Loss: 0.0942, Acc: 89.29% | Val Loss: 0.1209, Acc: 88.89%\n",
      "Epoch 270: Train Loss: 0.0980, Acc: 89.58% | Val Loss: 0.1187, Acc: 88.89%\n",
      "Epoch 280: Train Loss: 0.0876, Acc: 88.99% | Val Loss: 0.1162, Acc: 88.89%\n",
      "Epoch 290: Train Loss: 0.0874, Acc: 91.07% | Val Loss: 0.1142, Acc: 88.89%\n",
      "Final Validation Accuracy: 0.9259\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.9259\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2378, Acc: 58.33% | Val Loss: 0.2104, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.2225, Acc: 63.69% | Val Loss: 0.1845, Acc: 85.19%\n",
      "Epoch 20: Train Loss: 0.2130, Acc: 66.07% | Val Loss: 0.1774, Acc: 85.19%\n",
      "Epoch 30: Train Loss: 0.1972, Acc: 70.83% | Val Loss: 0.1699, Acc: 85.19%\n",
      "Epoch 40: Train Loss: 0.1888, Acc: 74.70% | Val Loss: 0.1619, Acc: 85.19%\n",
      "Epoch 50: Train Loss: 0.1765, Acc: 76.19% | Val Loss: 0.1536, Acc: 88.89%\n",
      "Epoch 60: Train Loss: 0.1643, Acc: 79.46% | Val Loss: 0.1455, Acc: 88.89%\n",
      "Epoch 70: Train Loss: 0.1521, Acc: 85.12% | Val Loss: 0.1374, Acc: 88.89%\n",
      "Epoch 80: Train Loss: 0.1475, Acc: 85.71% | Val Loss: 0.1288, Acc: 92.59%\n",
      "Epoch 90: Train Loss: 0.1375, Acc: 84.23% | Val Loss: 0.1215, Acc: 92.59%\n",
      "Epoch 100: Train Loss: 0.1270, Acc: 85.42% | Val Loss: 0.1151, Acc: 92.59%\n",
      "Epoch 110: Train Loss: 0.1273, Acc: 85.42% | Val Loss: 0.1091, Acc: 92.59%\n",
      "Epoch 120: Train Loss: 0.1268, Acc: 85.12% | Val Loss: 0.1036, Acc: 92.59%\n",
      "Epoch 130: Train Loss: 0.1192, Acc: 85.71% | Val Loss: 0.0985, Acc: 92.59%\n",
      "Epoch 140: Train Loss: 0.1128, Acc: 94.64% | Val Loss: 0.0942, Acc: 100.00%\n",
      "Epoch 150: Train Loss: 0.1102, Acc: 96.43% | Val Loss: 0.0906, Acc: 100.00%\n",
      "Epoch 160: Train Loss: 0.1052, Acc: 96.43% | Val Loss: 0.0869, Acc: 100.00%\n",
      "Epoch 170: Train Loss: 0.0970, Acc: 98.21% | Val Loss: 0.0836, Acc: 100.00%\n",
      "Epoch 180: Train Loss: 0.0939, Acc: 97.32% | Val Loss: 0.0807, Acc: 100.00%\n",
      "Epoch 190: Train Loss: 0.1002, Acc: 94.35% | Val Loss: 0.0780, Acc: 100.00%\n",
      "Epoch 200: Train Loss: 0.0950, Acc: 96.13% | Val Loss: 0.0756, Acc: 100.00%\n",
      "Epoch 210: Train Loss: 0.0954, Acc: 96.43% | Val Loss: 0.0731, Acc: 100.00%\n",
      "Epoch 220: Train Loss: 0.0913, Acc: 96.43% | Val Loss: 0.0707, Acc: 100.00%\n",
      "Epoch 230: Train Loss: 0.0888, Acc: 94.94% | Val Loss: 0.0685, Acc: 100.00%\n",
      "Epoch 240: Train Loss: 0.0824, Acc: 97.32% | Val Loss: 0.0665, Acc: 100.00%\n",
      "Epoch 250: Train Loss: 0.0819, Acc: 96.43% | Val Loss: 0.0646, Acc: 100.00%\n",
      "Epoch 260: Train Loss: 0.0776, Acc: 99.11% | Val Loss: 0.0628, Acc: 100.00%\n",
      "Epoch 270: Train Loss: 0.0831, Acc: 97.32% | Val Loss: 0.0612, Acc: 100.00%\n",
      "Epoch 280: Train Loss: 0.0774, Acc: 95.54% | Val Loss: 0.0596, Acc: 100.00%\n",
      "Epoch 290: Train Loss: 0.0677, Acc: 100.00% | Val Loss: 0.0579, Acc: 100.00%\n",
      "Final Validation Accuracy: 1.0000\n",
      "âœ… Fold 4/5 | Validation Accuracy: 1.0000\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2429, Acc: 55.95% | Val Loss: 0.2535, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2214, Acc: 65.48% | Val Loss: 0.2527, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2203, Acc: 64.29% | Val Loss: 0.2499, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2107, Acc: 67.86% | Val Loss: 0.2498, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2085, Acc: 66.37% | Val Loss: 0.2493, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2029, Acc: 71.43% | Val Loss: 0.2498, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2034, Acc: 67.86% | Val Loss: 0.2508, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2002, Acc: 71.13% | Val Loss: 0.2519, Acc: 59.26%\n",
      "Early stopping at epoch 77\n",
      "Restoring model weights from epoch 27\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6296\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.7926\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3962, Acc: 48.21% | Val Loss: 0.2378, Acc: 62.96%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2745, Acc: 60.71% | Val Loss: 0.2686, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2750, Acc: 56.25% | Val Loss: 0.2978, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2850, Acc: 43.75% | Val Loss: 0.2582, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3334, Acc: 52.68% | Val Loss: 0.2577, Acc: 62.96%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6296\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5481\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2472, Acc: 53.57% | Val Loss: 0.2783, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2409, Acc: 63.39% | Val Loss: 0.2785, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2382, Acc: 68.75% | Val Loss: 0.2785, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2414, Acc: 65.18% | Val Loss: 0.2785, Acc: 48.15%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2437, Acc: 57.14% | Val Loss: 0.2390, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2388, Acc: 61.61% | Val Loss: 0.2369, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2318, Acc: 60.71% | Val Loss: 0.2351, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2317, Acc: 64.29% | Val Loss: 0.2332, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2223, Acc: 66.96% | Val Loss: 0.2310, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2237, Acc: 66.07% | Val Loss: 0.2295, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2206, Acc: 67.86% | Val Loss: 0.2282, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2230, Acc: 60.71% | Val Loss: 0.2272, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2142, Acc: 66.07% | Val Loss: 0.2267, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2150, Acc: 66.07% | Val Loss: 0.2261, Acc: 55.56%\n",
      "Epoch 100: Train Loss: 0.2129, Acc: 66.96% | Val Loss: 0.2255, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2198, Acc: 65.18% | Val Loss: 0.2249, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2051, Acc: 68.75% | Val Loss: 0.2242, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.2054, Acc: 66.96% | Val Loss: 0.2237, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.1980, Acc: 67.86% | Val Loss: 0.2230, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5556\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2281, Acc: 61.61% | Val Loss: 0.2377, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2264, Acc: 59.82% | Val Loss: 0.2352, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2275, Acc: 60.71% | Val Loss: 0.2329, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2278, Acc: 60.71% | Val Loss: 0.2313, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2129, Acc: 69.64% | Val Loss: 0.2300, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2196, Acc: 63.39% | Val Loss: 0.2288, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2141, Acc: 63.39% | Val Loss: 0.2279, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2194, Acc: 61.61% | Val Loss: 0.2270, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2148, Acc: 62.50% | Val Loss: 0.2262, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2121, Acc: 63.39% | Val Loss: 0.2255, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2103, Acc: 64.29% | Val Loss: 0.2249, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2104, Acc: 65.18% | Val Loss: 0.2242, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.2129, Acc: 63.39% | Val Loss: 0.2236, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2063, Acc: 64.29% | Val Loss: 0.2232, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.2066, Acc: 64.29% | Val Loss: 0.2226, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5926\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2989, Acc: 56.25% | Val Loss: 0.2174, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.2706, Acc: 63.39% | Val Loss: 0.2157, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2948, Acc: 55.36% | Val Loss: 0.2142, Acc: 77.78%\n",
      "Epoch 30: Train Loss: 0.2547, Acc: 63.39% | Val Loss: 0.2124, Acc: 77.78%\n",
      "Epoch 40: Train Loss: 0.2814, Acc: 56.25% | Val Loss: 0.2113, Acc: 77.78%\n",
      "Epoch 50: Train Loss: 0.2683, Acc: 62.50% | Val Loss: 0.2106, Acc: 77.78%\n",
      "Epoch 60: Train Loss: 0.2779, Acc: 58.93% | Val Loss: 0.2097, Acc: 77.78%\n",
      "Epoch 70: Train Loss: 0.2729, Acc: 60.71% | Val Loss: 0.2085, Acc: 77.78%\n",
      "Epoch 80: Train Loss: 0.2680, Acc: 61.61% | Val Loss: 0.2075, Acc: 77.78%\n",
      "Epoch 90: Train Loss: 0.2591, Acc: 63.39% | Val Loss: 0.2071, Acc: 77.78%\n",
      "Epoch 100: Train Loss: 0.2731, Acc: 57.14% | Val Loss: 0.2069, Acc: 77.78%\n",
      "Epoch 110: Train Loss: 0.2525, Acc: 61.61% | Val Loss: 0.2063, Acc: 77.78%\n",
      "Epoch 120: Train Loss: 0.2693, Acc: 60.71% | Val Loss: 0.2062, Acc: 77.78%\n",
      "Epoch 130: Train Loss: 0.2744, Acc: 56.25% | Val Loss: 0.2059, Acc: 77.78%\n",
      "Epoch 140: Train Loss: 0.2722, Acc: 58.93% | Val Loss: 0.2055, Acc: 77.78%\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2919, Acc: 55.36% | Val Loss: 0.2995, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2966, Acc: 54.46% | Val Loss: 0.2895, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2791, Acc: 56.25% | Val Loss: 0.2816, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2945, Acc: 58.04% | Val Loss: 0.2759, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2646, Acc: 61.61% | Val Loss: 0.2713, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2625, Acc: 61.61% | Val Loss: 0.2677, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2597, Acc: 57.14% | Val Loss: 0.2649, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2639, Acc: 59.82% | Val Loss: 0.2625, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2558, Acc: 56.25% | Val Loss: 0.2606, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2362, Acc: 61.61% | Val Loss: 0.2594, Acc: 55.56%\n",
      "Epoch 100: Train Loss: 0.2478, Acc: 58.93% | Val Loss: 0.2582, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2383, Acc: 58.93% | Val Loss: 0.2573, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2297, Acc: 63.39% | Val Loss: 0.2568, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.2346, Acc: 61.61% | Val Loss: 0.2561, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.2132, Acc: 62.50% | Val Loss: 0.2557, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6000\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3135, Acc: 66.67% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.3079, Acc: 67.26% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.3190, Acc: 66.07% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.3106, Acc: 66.96% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.3107, Acc: 66.96% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.3076, Acc: 67.26% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.3187, Acc: 66.07% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.3129, Acc: 66.67% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.3191, Acc: 66.07% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.3187, Acc: 66.07% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.3107, Acc: 66.96% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 110: Train Loss: 0.3107, Acc: 66.96% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 120: Train Loss: 0.3135, Acc: 66.67% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 130: Train Loss: 0.3164, Acc: 66.37% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 140: Train Loss: 0.3136, Acc: 66.67% | Val Loss: 0.4462, Acc: 51.85%\n",
      "Epoch 150: Train Loss: 0.3182, Acc: 66.07% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 160: Train Loss: 0.3192, Acc: 66.07% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 170: Train Loss: 0.3105, Acc: 66.96% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 180: Train Loss: 0.3134, Acc: 66.67% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 190: Train Loss: 0.3132, Acc: 66.67% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 200: Train Loss: 0.3102, Acc: 66.96% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 210: Train Loss: 0.3132, Acc: 66.67% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 220: Train Loss: 0.3105, Acc: 66.96% | Val Loss: 0.4461, Acc: 51.85%\n",
      "Epoch 230: Train Loss: 0.3134, Acc: 66.67% | Val Loss: 0.4460, Acc: 51.85%\n",
      "Epoch 240: Train Loss: 0.3106, Acc: 66.96% | Val Loss: 0.4460, Acc: 51.85%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2501, Acc: 63.99% | Val Loss: 0.2556, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2467, Acc: 64.58% | Val Loss: 0.2556, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2521, Acc: 63.39% | Val Loss: 0.2556, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2449, Acc: 64.88% | Val Loss: 0.2556, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2503, Acc: 63.99% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2474, Acc: 64.29% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2515, Acc: 63.69% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2516, Acc: 63.69% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2527, Acc: 63.39% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2477, Acc: 64.29% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2550, Acc: 63.10% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.2551, Acc: 63.10% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2462, Acc: 64.58% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.2518, Acc: 63.69% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2488, Acc: 64.29% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2505, Acc: 63.69% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 160: Train Loss: 0.2517, Acc: 63.69% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 170: Train Loss: 0.2544, Acc: 63.10% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 180: Train Loss: 0.2526, Acc: 63.39% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 190: Train Loss: 0.2450, Acc: 64.88% | Val Loss: 0.2554, Acc: 62.96%\n",
      "Epoch 200: Train Loss: 0.2516, Acc: 63.69% | Val Loss: 0.2553, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.2547, Acc: 63.10% | Val Loss: 0.2553, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.2479, Acc: 64.29% | Val Loss: 0.2553, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.2509, Acc: 63.69% | Val Loss: 0.2553, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.2495, Acc: 63.99% | Val Loss: 0.2553, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3177, Acc: 62.80% | Val Loss: 0.2846, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.3150, Acc: 63.10% | Val Loss: 0.2846, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.3147, Acc: 63.10% | Val Loss: 0.2846, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.3225, Acc: 62.20% | Val Loss: 0.2846, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.3129, Acc: 63.39% | Val Loss: 0.2846, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.3201, Acc: 62.50% | Val Loss: 0.2845, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.3148, Acc: 63.10% | Val Loss: 0.2845, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.3150, Acc: 63.10% | Val Loss: 0.2845, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.3126, Acc: 63.39% | Val Loss: 0.2845, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.3279, Acc: 61.61% | Val Loss: 0.2845, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.3151, Acc: 63.10% | Val Loss: 0.2845, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.3176, Acc: 62.80% | Val Loss: 0.2844, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.3152, Acc: 63.10% | Val Loss: 0.2844, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.3103, Acc: 63.69% | Val Loss: 0.2844, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.3245, Acc: 61.90% | Val Loss: 0.2844, Acc: 66.67%\n",
      "Epoch 150: Train Loss: 0.3150, Acc: 63.10% | Val Loss: 0.2844, Acc: 66.67%\n",
      "Epoch 160: Train Loss: 0.3203, Acc: 62.50% | Val Loss: 0.2843, Acc: 66.67%\n",
      "Epoch 170: Train Loss: 0.3146, Acc: 63.10% | Val Loss: 0.2843, Acc: 66.67%\n",
      "Epoch 180: Train Loss: 0.3216, Acc: 62.20% | Val Loss: 0.2843, Acc: 66.67%\n",
      "Epoch 190: Train Loss: 0.3203, Acc: 62.50% | Val Loss: 0.2843, Acc: 66.67%\n",
      "Epoch 200: Train Loss: 0.3197, Acc: 62.50% | Val Loss: 0.2843, Acc: 66.67%\n",
      "Epoch 210: Train Loss: 0.3177, Acc: 62.80% | Val Loss: 0.2843, Acc: 66.67%\n",
      "Epoch 220: Train Loss: 0.3174, Acc: 62.80% | Val Loss: 0.2842, Acc: 66.67%\n",
      "Epoch 230: Train Loss: 0.3151, Acc: 63.10% | Val Loss: 0.2842, Acc: 66.67%\n",
      "Epoch 240: Train Loss: 0.3203, Acc: 62.50% | Val Loss: 0.2842, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2487, Acc: 60.42% | Val Loss: 0.2457, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2506, Acc: 59.52% | Val Loss: 0.2456, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2489, Acc: 60.12% | Val Loss: 0.2456, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2501, Acc: 59.52% | Val Loss: 0.2456, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2466, Acc: 60.71% | Val Loss: 0.2456, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2487, Acc: 60.42% | Val Loss: 0.2455, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2495, Acc: 59.82% | Val Loss: 0.2455, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2485, Acc: 60.42% | Val Loss: 0.2455, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2490, Acc: 60.12% | Val Loss: 0.2454, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2487, Acc: 60.12% | Val Loss: 0.2454, Acc: 55.56%\n",
      "Epoch 100: Train Loss: 0.2482, Acc: 60.71% | Val Loss: 0.2454, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2500, Acc: 59.52% | Val Loss: 0.2454, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2494, Acc: 60.12% | Val Loss: 0.2453, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.2487, Acc: 60.42% | Val Loss: 0.2453, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.2479, Acc: 59.82% | Val Loss: 0.2453, Acc: 55.56%\n",
      "Epoch 150: Train Loss: 0.2491, Acc: 59.23% | Val Loss: 0.2452, Acc: 55.56%\n",
      "Epoch 160: Train Loss: 0.2473, Acc: 59.82% | Val Loss: 0.2452, Acc: 55.56%\n",
      "Epoch 170: Train Loss: 0.2483, Acc: 59.52% | Val Loss: 0.2452, Acc: 55.56%\n",
      "Epoch 180: Train Loss: 0.2482, Acc: 59.52% | Val Loss: 0.2452, Acc: 55.56%\n",
      "Epoch 190: Train Loss: 0.2506, Acc: 58.33% | Val Loss: 0.2451, Acc: 55.56%\n",
      "Epoch 200: Train Loss: 0.2488, Acc: 58.93% | Val Loss: 0.2451, Acc: 55.56%\n",
      "Epoch 210: Train Loss: 0.2489, Acc: 59.52% | Val Loss: 0.2451, Acc: 55.56%\n",
      "Epoch 220: Train Loss: 0.2483, Acc: 59.52% | Val Loss: 0.2450, Acc: 55.56%\n",
      "Epoch 230: Train Loss: 0.2484, Acc: 59.52% | Val Loss: 0.2450, Acc: 55.56%\n",
      "Epoch 240: Train Loss: 0.2479, Acc: 59.82% | Val Loss: 0.2450, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5556\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2669, Acc: 64.58% | Val Loss: 0.2973, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2650, Acc: 64.88% | Val Loss: 0.2973, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2649, Acc: 64.88% | Val Loss: 0.2972, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2711, Acc: 63.99% | Val Loss: 0.2972, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2641, Acc: 64.88% | Val Loss: 0.2972, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2586, Acc: 65.77% | Val Loss: 0.2971, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2658, Acc: 64.58% | Val Loss: 0.2971, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2645, Acc: 64.88% | Val Loss: 0.2971, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2658, Acc: 64.58% | Val Loss: 0.2970, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2603, Acc: 65.48% | Val Loss: 0.2970, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2649, Acc: 64.88% | Val Loss: 0.2970, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2623, Acc: 65.18% | Val Loss: 0.2969, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.2688, Acc: 64.29% | Val Loss: 0.2969, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2628, Acc: 65.18% | Val Loss: 0.2969, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.2668, Acc: 64.58% | Val Loss: 0.2969, Acc: 59.26%\n",
      "Epoch 150: Train Loss: 0.2645, Acc: 64.88% | Val Loss: 0.2968, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.2618, Acc: 65.18% | Val Loss: 0.2968, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.2605, Acc: 65.48% | Val Loss: 0.2968, Acc: 59.26%\n",
      "Epoch 180: Train Loss: 0.2626, Acc: 65.18% | Val Loss: 0.2967, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.2687, Acc: 64.29% | Val Loss: 0.2967, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.2640, Acc: 64.88% | Val Loss: 0.2967, Acc: 59.26%\n",
      "Epoch 210: Train Loss: 0.2699, Acc: 63.99% | Val Loss: 0.2966, Acc: 59.26%\n",
      "Epoch 220: Train Loss: 0.2638, Acc: 64.88% | Val Loss: 0.2966, Acc: 59.26%\n",
      "Epoch 230: Train Loss: 0.2662, Acc: 64.58% | Val Loss: 0.2966, Acc: 59.26%\n",
      "Epoch 240: Train Loss: 0.2601, Acc: 65.48% | Val Loss: 0.2965, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5926\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3312, Acc: 50.89% | Val Loss: 0.4130, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.3335, Acc: 54.46% | Val Loss: 0.3946, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.3081, Acc: 53.57% | Val Loss: 0.3812, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.3044, Acc: 56.25% | Val Loss: 0.3696, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2736, Acc: 59.82% | Val Loss: 0.3570, Acc: 44.44%\n",
      "Epoch 50: Train Loss: 0.3056, Acc: 51.79% | Val Loss: 0.3519, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.2527, Acc: 62.50% | Val Loss: 0.3531, Acc: 44.44%\n",
      "Epoch 70: Train Loss: 0.2513, Acc: 62.50% | Val Loss: 0.3565, Acc: 44.44%\n",
      "Epoch 80: Train Loss: 0.2831, Acc: 54.46% | Val Loss: 0.3475, Acc: 48.15%\n",
      "Early stopping at epoch 86\n",
      "Restoring model weights from epoch 66\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2570, Acc: 61.61% | Val Loss: 0.3803, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2548, Acc: 58.93% | Val Loss: 0.3402, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2611, Acc: 60.71% | Val Loss: 0.3218, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2208, Acc: 65.18% | Val Loss: 0.3034, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2325, Acc: 61.61% | Val Loss: 0.2982, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2139, Acc: 64.29% | Val Loss: 0.2943, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2099, Acc: 66.07% | Val Loss: 0.2888, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2001, Acc: 66.07% | Val Loss: 0.2810, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.1927, Acc: 69.64% | Val Loss: 0.2738, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.1936, Acc: 71.43% | Val Loss: 0.2806, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2018, Acc: 66.96% | Val Loss: 0.2697, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2048, Acc: 65.18% | Val Loss: 0.2701, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2037, Acc: 68.75% | Val Loss: 0.2700, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.1910, Acc: 72.32% | Val Loss: 0.2691, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.1810, Acc: 70.54% | Val Loss: 0.2646, Acc: 55.56%\n",
      "Epoch 150: Train Loss: 0.2048, Acc: 68.75% | Val Loss: 0.2611, Acc: 62.96%\n",
      "Epoch 160: Train Loss: 0.1777, Acc: 73.21% | Val Loss: 0.2588, Acc: 55.56%\n",
      "Epoch 170: Train Loss: 0.1709, Acc: 75.89% | Val Loss: 0.2594, Acc: 55.56%\n",
      "Epoch 180: Train Loss: 0.1905, Acc: 69.64% | Val Loss: 0.2611, Acc: 62.96%\n",
      "Epoch 190: Train Loss: 0.1512, Acc: 81.25% | Val Loss: 0.2621, Acc: 62.96%\n",
      "Epoch 200: Train Loss: 0.1927, Acc: 71.43% | Val Loss: 0.2522, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.1841, Acc: 70.54% | Val Loss: 0.2505, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.1917, Acc: 69.64% | Val Loss: 0.2524, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.1969, Acc: 68.75% | Val Loss: 0.2496, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.1822, Acc: 72.32% | Val Loss: 0.2557, Acc: 59.26%\n",
      "Epoch 250: Train Loss: 0.1873, Acc: 66.96% | Val Loss: 0.2489, Acc: 62.96%\n",
      "Epoch 260: Train Loss: 0.1718, Acc: 71.43% | Val Loss: 0.2472, Acc: 62.96%\n",
      "Early stopping at epoch 263\n",
      "Restoring model weights from epoch 243\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2733, Acc: 53.57% | Val Loss: 0.2903, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2648, Acc: 54.46% | Val Loss: 0.2896, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2403, Acc: 57.14% | Val Loss: 0.2892, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2310, Acc: 65.18% | Val Loss: 0.2836, Acc: 48.15%\n",
      "Early stopping at epoch 32\n",
      "Restoring model weights from epoch 12\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4444\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2771, Acc: 58.04% | Val Loss: 0.2825, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.3035, Acc: 53.57% | Val Loss: 0.2800, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2635, Acc: 58.93% | Val Loss: 0.2718, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2672, Acc: 58.04% | Val Loss: 0.2565, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2585, Acc: 59.82% | Val Loss: 0.2360, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2676, Acc: 63.39% | Val Loss: 0.2282, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2431, Acc: 61.61% | Val Loss: 0.2130, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2140, Acc: 66.96% | Val Loss: 0.2030, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2428, Acc: 60.71% | Val Loss: 0.1921, Acc: 70.37%\n",
      "Epoch 90: Train Loss: 0.2204, Acc: 63.39% | Val Loss: 0.1939, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.2155, Acc: 67.86% | Val Loss: 0.1825, Acc: 70.37%\n",
      "Epoch 110: Train Loss: 0.2354, Acc: 61.61% | Val Loss: 0.1923, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.2313, Acc: 57.14% | Val Loss: 0.1838, Acc: 74.07%\n",
      "Early stopping at epoch 120\n",
      "Restoring model weights from epoch 100\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4552, Acc: 44.64% | Val Loss: 0.4846, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.4247, Acc: 43.75% | Val Loss: 0.4625, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.3598, Acc: 50.00% | Val Loss: 0.4306, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.3469, Acc: 53.57% | Val Loss: 0.4216, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.3516, Acc: 43.75% | Val Loss: 0.4100, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.2968, Acc: 54.46% | Val Loss: 0.3892, Acc: 37.04%\n",
      "Epoch 60: Train Loss: 0.2874, Acc: 59.82% | Val Loss: 0.3978, Acc: 37.04%\n",
      "Epoch 70: Train Loss: 0.2917, Acc: 56.25% | Val Loss: 0.3861, Acc: 37.04%\n",
      "Epoch 80: Train Loss: 0.2533, Acc: 55.36% | Val Loss: 0.3830, Acc: 37.04%\n",
      "Epoch 90: Train Loss: 0.2746, Acc: 58.04% | Val Loss: 0.3658, Acc: 37.04%\n",
      "Epoch 100: Train Loss: 0.2318, Acc: 65.18% | Val Loss: 0.3672, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.2562, Acc: 66.07% | Val Loss: 0.3604, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.2293, Acc: 68.75% | Val Loss: 0.3575, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.2363, Acc: 66.07% | Val Loss: 0.3473, Acc: 37.04%\n",
      "Epoch 140: Train Loss: 0.2315, Acc: 65.18% | Val Loss: 0.3424, Acc: 37.04%\n",
      "Epoch 150: Train Loss: 0.2142, Acc: 69.64% | Val Loss: 0.3355, Acc: 37.04%\n",
      "Early stopping at epoch 157\n",
      "Restoring model weights from epoch 137\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3704\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5407\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3581, Acc: 41.96% | Val Loss: 0.2586, Acc: 55.56%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5556\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2567, Acc: 58.93% | Val Loss: 0.2525, Acc: 59.26%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5926\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2636, Acc: 50.89% | Val Loss: 0.2716, Acc: 44.44%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4444\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3762, Acc: 46.43% | Val Loss: 0.3145, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.4074\n",
      "[4] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3136, Acc: 53.57% | Val Loss: 0.3168, Acc: 37.04%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3704\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4741\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3786, Acc: 47.02% | Val Loss: 0.2603, Acc: 70.37%\n",
      "Epoch 10: Train Loss: 0.3818, Acc: 47.02% | Val Loss: 0.2681, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.3797, Acc: 49.11% | Val Loss: 0.2695, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.3766, Acc: 45.54% | Val Loss: 0.2702, Acc: 66.67%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6667\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3825, Acc: 44.05% | Val Loss: 0.2417, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.3755, Acc: 46.43% | Val Loss: 0.2498, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.3827, Acc: 49.70% | Val Loss: 0.2512, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.3755, Acc: 47.32% | Val Loss: 0.2489, Acc: 62.96%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3372, Acc: 48.51% | Val Loss: 0.5690, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.3404, Acc: 47.62% | Val Loss: 0.4636, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.3455, Acc: 44.64% | Val Loss: 0.4670, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.3265, Acc: 54.46% | Val Loss: 0.4618, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.3455, Acc: 51.79% | Val Loss: 0.4625, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.3547, Acc: 40.77% | Val Loss: 0.4671, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.3548, Acc: 47.02% | Val Loss: 0.4672, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.3462, Acc: 50.89% | Val Loss: 0.4634, Acc: 40.74%\n",
      "Early stopping at epoch 74\n",
      "Restoring model weights from epoch 44\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4074\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2975, Acc: 48.51% | Val Loss: 0.2734, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2952, Acc: 47.02% | Val Loss: 0.2849, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2995, Acc: 49.40% | Val Loss: 0.2859, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2970, Acc: 45.24% | Val Loss: 0.2871, Acc: 44.44%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.4444\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2918, Acc: 57.14% | Val Loss: 0.3928, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2852, Acc: 54.17% | Val Loss: 0.3466, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.3100, Acc: 53.57% | Val Loss: 0.3462, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.2895, Acc: 55.65% | Val Loss: 0.3471, Acc: 37.04%\n",
      "Epoch 40: Train Loss: 0.2835, Acc: 57.44% | Val Loss: 0.3473, Acc: 37.04%\n",
      "Early stopping at epoch 46\n",
      "Restoring model weights from epoch 16\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3704\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5037\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.3138, Acc: 58.59% | Val Loss: 0.2431, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2785, Acc: 64.58% | Val Loss: 0.3235, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2896, Acc: 60.16% | Val Loss: 0.3612, Acc: 55.56%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5556\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.4989, Acc: 35.16% | Val Loss: 0.2685, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.4982, Acc: 35.16% | Val Loss: 0.4146, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.4645, Acc: 38.54% | Val Loss: 0.4563, Acc: 37.04%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3704\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.4044, Acc: 45.57% | Val Loss: 0.2674, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.3964, Acc: 46.35% | Val Loss: 0.3642, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3605, Acc: 51.56% | Val Loss: 0.4062, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.3148, Acc: 50.00% | Val Loss: 0.2462, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2927, Acc: 53.91% | Val Loss: 0.2625, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3066, Acc: 51.82% | Val Loss: 0.3117, Acc: 59.26%\n",
      "Early stopping at epoch 24\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5926\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2613, Acc: 58.85% | Val Loss: 0.2493, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2334, Acc: 66.67% | Val Loss: 0.2767, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2417, Acc: 65.10% | Val Loss: 0.2957, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4815\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4963\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 150, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3632, Acc: 41.67% | Val Loss: 0.3237, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3614, Acc: 41.41% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3481, Acc: 46.35% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.3390, Acc: 49.48% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2917, Acc: 51.82% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.3455, Acc: 51.56% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.3400, Acc: 46.35% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.3198, Acc: 50.78% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.3281, Acc: 50.52% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.3205, Acc: 47.66% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.3386, Acc: 47.40% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.3039, Acc: 50.00% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.3520, Acc: 42.19% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.3325, Acc: 45.83% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.3746, Acc: 40.62% | Val Loss: 0.3236, Acc: 48.15%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 150, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3276, Acc: 50.52% | Val Loss: 0.3762, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.3478, Acc: 46.61% | Val Loss: 0.3761, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.3499, Acc: 47.14% | Val Loss: 0.3761, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.3342, Acc: 43.49% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.3703, Acc: 49.48% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.3498, Acc: 47.66% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.3402, Acc: 41.93% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.3208, Acc: 51.30% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.3271, Acc: 48.18% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 90: Train Loss: 0.3526, Acc: 43.49% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 100: Train Loss: 0.3179, Acc: 52.34% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.3151, Acc: 50.00% | Val Loss: 0.3760, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.3594, Acc: 44.01% | Val Loss: 0.3759, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.3486, Acc: 48.70% | Val Loss: 0.3759, Acc: 40.74%\n",
      "Epoch 140: Train Loss: 0.3678, Acc: 42.45% | Val Loss: 0.3759, Acc: 40.74%\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4074\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 150, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3061, Acc: 34.38% | Val Loss: 0.2992, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2846, Acc: 46.35% | Val Loss: 0.2991, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.3080, Acc: 40.10% | Val Loss: 0.2990, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.3007, Acc: 42.97% | Val Loss: 0.2990, Acc: 37.04%\n",
      "Epoch 40: Train Loss: 0.3016, Acc: 37.76% | Val Loss: 0.2989, Acc: 37.04%\n",
      "Epoch 50: Train Loss: 0.2774, Acc: 50.78% | Val Loss: 0.2989, Acc: 37.04%\n",
      "Epoch 60: Train Loss: 0.2932, Acc: 47.40% | Val Loss: 0.2989, Acc: 37.04%\n",
      "Epoch 70: Train Loss: 0.2875, Acc: 43.75% | Val Loss: 0.2989, Acc: 37.04%\n",
      "Epoch 80: Train Loss: 0.2684, Acc: 51.82% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Epoch 90: Train Loss: 0.2932, Acc: 42.45% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Epoch 100: Train Loss: 0.2929, Acc: 43.49% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Epoch 110: Train Loss: 0.2897, Acc: 50.00% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Epoch 120: Train Loss: 0.2926, Acc: 45.83% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Epoch 130: Train Loss: 0.2808, Acc: 49.22% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Epoch 140: Train Loss: 0.2845, Acc: 44.79% | Val Loss: 0.2988, Acc: 37.04%\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.3704\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 150, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3244, Acc: 54.69% | Val Loss: 0.2065, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2983, Acc: 58.07% | Val Loss: 0.2065, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2939, Acc: 57.81% | Val Loss: 0.2065, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.3265, Acc: 53.91% | Val Loss: 0.2065, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.3125, Acc: 50.52% | Val Loss: 0.2065, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2651, Acc: 62.50% | Val Loss: 0.2065, Acc: 66.67%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6667\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 150, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2897, Acc: 45.57% | Val Loss: 0.2514, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2675, Acc: 53.39% | Val Loss: 0.2513, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2953, Acc: 41.67% | Val Loss: 0.2513, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2539, Acc: 55.73% | Val Loss: 0.2513, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.3100, Acc: 49.74% | Val Loss: 0.2513, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2957, Acc: 47.66% | Val Loss: 0.2513, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2496, Acc: 54.95% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2849, Acc: 53.39% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.3043, Acc: 53.39% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2990, Acc: 49.22% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 100: Train Loss: 0.3084, Acc: 46.61% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.3014, Acc: 48.70% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2992, Acc: 52.86% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.2970, Acc: 50.52% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.2559, Acc: 58.07% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5556\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4963\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3076, Acc: 66.07% | Val Loss: 0.4428, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2698, Acc: 66.96% | Val Loss: 0.3992, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2289, Acc: 68.75% | Val Loss: 0.3235, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2491, Acc: 62.50% | Val Loss: 0.2965, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2632, Acc: 63.39% | Val Loss: 0.2797, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2486, Acc: 62.50% | Val Loss: 0.2733, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2275, Acc: 66.07% | Val Loss: 0.2737, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.2221, Acc: 63.39% | Val Loss: 0.2703, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2035, Acc: 69.64% | Val Loss: 0.2709, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2259, Acc: 68.75% | Val Loss: 0.2725, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2015, Acc: 71.43% | Val Loss: 0.2706, Acc: 51.85%\n",
      "Early stopping at epoch 100\n",
      "Restoring model weights from epoch 70\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.4862, Acc: 35.71% | Val Loss: 0.4283, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.3142, Acc: 45.54% | Val Loss: 0.2588, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2427, Acc: 58.93% | Val Loss: 0.2217, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.2822, Acc: 50.89% | Val Loss: 0.2206, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2559, Acc: 55.36% | Val Loss: 0.2244, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2366, Acc: 58.93% | Val Loss: 0.2258, Acc: 62.96%\n",
      "Early stopping at epoch 56\n",
      "Restoring model weights from epoch 26\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3601, Acc: 42.86% | Val Loss: 0.3971, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.3364, Acc: 37.50% | Val Loss: 0.2827, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2458, Acc: 58.04% | Val Loss: 0.2405, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2366, Acc: 58.04% | Val Loss: 0.2331, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2217, Acc: 65.18% | Val Loss: 0.2309, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2353, Acc: 60.71% | Val Loss: 0.2319, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2372, Acc: 63.39% | Val Loss: 0.2327, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2510, Acc: 57.14% | Val Loss: 0.2342, Acc: 66.67%\n",
      "Early stopping at epoch 70\n",
      "Restoring model weights from epoch 40\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2831, Acc: 58.93% | Val Loss: 0.1710, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.2480, Acc: 58.93% | Val Loss: 0.1748, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2403, Acc: 59.82% | Val Loss: 0.1839, Acc: 77.78%\n",
      "Epoch 30: Train Loss: 0.2360, Acc: 58.93% | Val Loss: 0.1895, Acc: 77.78%\n",
      "Early stopping at epoch 33\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3108, Acc: 43.75% | Val Loss: 0.2634, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2327, Acc: 64.29% | Val Loss: 0.2396, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2633, Acc: 53.57% | Val Loss: 0.2422, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2331, Acc: 66.07% | Val Loss: 0.2443, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2490, Acc: 61.61% | Val Loss: 0.2450, Acc: 59.26%\n",
      "Early stopping at epoch 40\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6370\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2868, Acc: 46.43% | Val Loss: 0.2536, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2492, Acc: 59.82% | Val Loss: 0.2493, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2437, Acc: 65.18% | Val Loss: 0.2493, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2417, Acc: 66.07% | Val Loss: 0.2491, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2398, Acc: 67.86% | Val Loss: 0.2494, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2392, Acc: 65.18% | Val Loss: 0.2500, Acc: 51.85%\n",
      "Early stopping at epoch 54\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2591, Acc: 48.21% | Val Loss: 0.2599, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2457, Acc: 58.04% | Val Loss: 0.2468, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2329, Acc: 67.86% | Val Loss: 0.2425, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2339, Acc: 64.29% | Val Loss: 0.2397, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2320, Acc: 64.29% | Val Loss: 0.2373, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2339, Acc: 64.29% | Val Loss: 0.2360, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2314, Acc: 63.39% | Val Loss: 0.2354, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2286, Acc: 65.18% | Val Loss: 0.2348, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2305, Acc: 64.29% | Val Loss: 0.2343, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2317, Acc: 63.39% | Val Loss: 0.2338, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2354, Acc: 62.50% | Val Loss: 0.2335, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.2346, Acc: 63.39% | Val Loss: 0.2333, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2321, Acc: 64.29% | Val Loss: 0.2330, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.2298, Acc: 62.50% | Val Loss: 0.2328, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2269, Acc: 63.39% | Val Loss: 0.2326, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2747, Acc: 53.57% | Val Loss: 0.2668, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2467, Acc: 58.93% | Val Loss: 0.2391, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2354, Acc: 61.61% | Val Loss: 0.2347, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2262, Acc: 62.50% | Val Loss: 0.2333, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2395, Acc: 57.14% | Val Loss: 0.2328, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2264, Acc: 62.50% | Val Loss: 0.2333, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2253, Acc: 66.07% | Val Loss: 0.2328, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2304, Acc: 61.61% | Val Loss: 0.2324, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2334, Acc: 65.18% | Val Loss: 0.2317, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2267, Acc: 66.07% | Val Loss: 0.2311, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.2255, Acc: 66.96% | Val Loss: 0.2308, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2274, Acc: 64.29% | Val Loss: 0.2304, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.2336, Acc: 67.86% | Val Loss: 0.2303, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.2330, Acc: 62.50% | Val Loss: 0.2301, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.2302, Acc: 63.39% | Val Loss: 0.2300, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2810, Acc: 48.21% | Val Loss: 0.3110, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.2610, Acc: 50.89% | Val Loss: 0.2546, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2555, Acc: 53.57% | Val Loss: 0.2430, Acc: 70.37%\n",
      "Epoch 30: Train Loss: 0.2507, Acc: 58.04% | Val Loss: 0.2379, Acc: 77.78%\n",
      "Epoch 40: Train Loss: 0.2469, Acc: 57.14% | Val Loss: 0.2352, Acc: 77.78%\n",
      "Epoch 50: Train Loss: 0.2459, Acc: 60.71% | Val Loss: 0.2331, Acc: 77.78%\n",
      "Epoch 60: Train Loss: 0.2441, Acc: 60.71% | Val Loss: 0.2316, Acc: 77.78%\n",
      "Epoch 70: Train Loss: 0.2468, Acc: 56.25% | Val Loss: 0.2305, Acc: 77.78%\n",
      "Epoch 80: Train Loss: 0.2445, Acc: 58.93% | Val Loss: 0.2297, Acc: 77.78%\n",
      "Epoch 90: Train Loss: 0.2434, Acc: 60.71% | Val Loss: 0.2290, Acc: 77.78%\n",
      "Epoch 100: Train Loss: 0.2428, Acc: 60.71% | Val Loss: 0.2284, Acc: 77.78%\n",
      "Epoch 110: Train Loss: 0.2429, Acc: 58.93% | Val Loss: 0.2279, Acc: 77.78%\n",
      "Epoch 120: Train Loss: 0.2441, Acc: 58.93% | Val Loss: 0.2275, Acc: 77.78%\n",
      "Epoch 130: Train Loss: 0.2416, Acc: 60.71% | Val Loss: 0.2271, Acc: 77.78%\n",
      "Epoch 140: Train Loss: 0.2417, Acc: 60.71% | Val Loss: 0.2268, Acc: 77.78%\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2527, Acc: 50.89% | Val Loss: 0.2543, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2462, Acc: 66.96% | Val Loss: 0.2490, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2442, Acc: 64.29% | Val Loss: 0.2467, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2432, Acc: 64.29% | Val Loss: 0.2458, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2424, Acc: 64.29% | Val Loss: 0.2454, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2412, Acc: 65.18% | Val Loss: 0.2450, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2407, Acc: 65.18% | Val Loss: 0.2448, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2409, Acc: 64.29% | Val Loss: 0.2446, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2392, Acc: 66.07% | Val Loss: 0.2444, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2396, Acc: 65.18% | Val Loss: 0.2443, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2386, Acc: 66.07% | Val Loss: 0.2441, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2391, Acc: 65.18% | Val Loss: 0.2440, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.2381, Acc: 66.07% | Val Loss: 0.2439, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2386, Acc: 65.18% | Val Loss: 0.2438, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.2384, Acc: 65.18% | Val Loss: 0.2437, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6370\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3428, Acc: 44.79% | Val Loss: 0.3277, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.3336, Acc: 47.14% | Val Loss: 0.3436, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.3438, Acc: 47.14% | Val Loss: 0.3421, Acc: 44.44%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4444\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3723, Acc: 45.05% | Val Loss: 0.3100, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3584, Acc: 45.05% | Val Loss: 0.3259, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3417, Acc: 47.14% | Val Loss: 0.3253, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2685, Acc: 51.04% | Val Loss: 0.3300, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.3163, Acc: 47.40% | Val Loss: 0.3826, Acc: 29.63%\n",
      "Epoch 20: Train Loss: 0.2841, Acc: 49.48% | Val Loss: 0.3784, Acc: 29.63%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2963\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2963\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3079, Acc: 51.04% | Val Loss: 0.3433, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.2904, Acc: 55.73% | Val Loss: 0.2759, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3051, Acc: 49.48% | Val Loss: 0.2766, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2874, Acc: 50.78% | Val Loss: 0.2742, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2959, Acc: 53.39% | Val Loss: 0.2688, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.3018, Acc: 51.04% | Val Loss: 0.2718, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2845, Acc: 57.03% | Val Loss: 0.2778, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.2944, Acc: 48.18% | Val Loss: 0.2726, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2973, Acc: 53.39% | Val Loss: 0.2657, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.3089, Acc: 53.65% | Val Loss: 0.2681, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5185\n",
      "[4] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3187, Acc: 47.66% | Val Loss: 0.3539, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2982, Acc: 49.22% | Val Loss: 0.3626, Acc: 33.33%\n",
      "Epoch 20: Train Loss: 0.3283, Acc: 44.01% | Val Loss: 0.3632, Acc: 33.33%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3333\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4148\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2726, Acc: 58.04% | Val Loss: 0.3667, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4074\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3306, Acc: 58.63% | Val Loss: 0.3238, Acc: 55.56%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5556\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4930, Acc: 39.29% | Val Loss: 0.4411, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4074\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4871, Acc: 43.45% | Val Loss: 0.6345, Acc: 22.22%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2222\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2222\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.5553, Acc: 35.42% | Val Loss: 0.5224, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4000\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.3885, Acc: 35.12% | Val Loss: 0.3076, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3357, Acc: 38.69% | Val Loss: 0.2888, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3045, Acc: 43.45% | Val Loss: 0.2743, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2859, Acc: 51.19% | Val Loss: 0.2641, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2544, Acc: 60.42% | Val Loss: 0.2572, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2414, Acc: 65.77% | Val Loss: 0.2542, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2318, Acc: 58.93% | Val Loss: 0.2568, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2179, Acc: 63.39% | Val Loss: 0.2540, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2213, Acc: 59.23% | Val Loss: 0.2553, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2044, Acc: 71.73% | Val Loss: 0.2577, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.2127, Acc: 64.29% | Val Loss: 0.2601, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2106, Acc: 68.75% | Val Loss: 0.2636, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2135, Acc: 69.05% | Val Loss: 0.2663, Acc: 48.15%\n",
      "Early stopping at epoch 121\n",
      "Restoring model weights from epoch 71\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.3851, Acc: 35.42% | Val Loss: 0.3550, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.3118, Acc: 42.86% | Val Loss: 0.3140, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2837, Acc: 56.85% | Val Loss: 0.2924, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2588, Acc: 62.80% | Val Loss: 0.2874, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2577, Acc: 62.20% | Val Loss: 0.2820, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2433, Acc: 64.58% | Val Loss: 0.2769, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2287, Acc: 63.39% | Val Loss: 0.2735, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2297, Acc: 63.69% | Val Loss: 0.2681, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2220, Acc: 62.50% | Val Loss: 0.2638, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2327, Acc: 59.52% | Val Loss: 0.2627, Acc: 44.44%\n",
      "Epoch 100: Train Loss: 0.2273, Acc: 62.80% | Val Loss: 0.2606, Acc: 51.85%\n",
      "Epoch 110: Train Loss: 0.2217, Acc: 66.67% | Val Loss: 0.2579, Acc: 51.85%\n",
      "Epoch 120: Train Loss: 0.2092, Acc: 66.37% | Val Loss: 0.2565, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.2080, Acc: 64.58% | Val Loss: 0.2569, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2121, Acc: 67.86% | Val Loss: 0.2544, Acc: 51.85%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2827, Acc: 53.57% | Val Loss: 0.2159, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2545, Acc: 65.77% | Val Loss: 0.2152, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2496, Acc: 61.61% | Val Loss: 0.2370, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2493, Acc: 61.01% | Val Loss: 0.2579, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2142, Acc: 66.67% | Val Loss: 0.2764, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2123, Acc: 70.83% | Val Loss: 0.2888, Acc: 51.85%\n",
      "Early stopping at epoch 55\n",
      "Restoring model weights from epoch 5\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2837, Acc: 44.05% | Val Loss: 0.2464, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2409, Acc: 62.80% | Val Loss: 0.2245, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.2474, Acc: 55.95% | Val Loss: 0.2044, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2346, Acc: 59.23% | Val Loss: 0.1969, Acc: 70.37%\n",
      "Epoch 40: Train Loss: 0.2229, Acc: 59.52% | Val Loss: 0.1941, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2213, Acc: 59.23% | Val Loss: 0.1910, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2197, Acc: 61.90% | Val Loss: 0.1878, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2289, Acc: 59.23% | Val Loss: 0.1873, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2319, Acc: 60.42% | Val Loss: 0.1874, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2357, Acc: 56.25% | Val Loss: 0.1879, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.2289, Acc: 58.33% | Val Loss: 0.1894, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2225, Acc: 63.39% | Val Loss: 0.1884, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.2239, Acc: 61.31% | Val Loss: 0.1877, Acc: 66.67%\n",
      "Early stopping at epoch 127\n",
      "Restoring model weights from epoch 77\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6667\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2467, Acc: 63.39% | Val Loss: 0.2419, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2265, Acc: 61.31% | Val Loss: 0.2471, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2156, Acc: 60.71% | Val Loss: 0.2529, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2157, Acc: 61.90% | Val Loss: 0.2510, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2164, Acc: 63.39% | Val Loss: 0.2485, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2184, Acc: 61.90% | Val Loss: 0.2499, Acc: 59.26%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5407\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3705, Acc: 57.29% | Val Loss: 0.3706, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.3327, Acc: 60.94% | Val Loss: 0.3706, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2699, Acc: 71.61% | Val Loss: 0.3706, Acc: 59.26%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5926\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3168, Acc: 41.67% | Val Loss: 0.2983, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2797, Acc: 57.81% | Val Loss: 0.2983, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2917, Acc: 50.00% | Val Loss: 0.2983, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.3003, Acc: 52.34% | Val Loss: 0.2982, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2874, Acc: 52.08% | Val Loss: 0.2982, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.3163, Acc: 47.92% | Val Loss: 0.2982, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.2774, Acc: 54.17% | Val Loss: 0.2982, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2968, Acc: 48.96% | Val Loss: 0.2981, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2945, Acc: 49.74% | Val Loss: 0.2981, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.2975, Acc: 51.30% | Val Loss: 0.2981, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.2795, Acc: 59.11% | Val Loss: 0.2981, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2730, Acc: 55.99% | Val Loss: 0.2980, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2837, Acc: 51.82% | Val Loss: 0.2980, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.3056, Acc: 47.92% | Val Loss: 0.2980, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2974, Acc: 49.74% | Val Loss: 0.2980, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.3024, Acc: 53.12% | Val Loss: 0.2979, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.2928, Acc: 52.08% | Val Loss: 0.2979, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2594, Acc: 59.38% | Val Loss: 0.2979, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.3188, Acc: 55.73% | Val Loss: 0.2979, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2697, Acc: 51.56% | Val Loss: 0.2978, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2926, Acc: 52.86% | Val Loss: 0.2978, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.3039, Acc: 55.47% | Val Loss: 0.2978, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.2918, Acc: 55.47% | Val Loss: 0.2978, Acc: 48.15%\n",
      "Epoch 230: Train Loss: 0.2785, Acc: 46.09% | Val Loss: 0.2977, Acc: 48.15%\n",
      "Epoch 240: Train Loss: 0.2964, Acc: 53.39% | Val Loss: 0.2977, Acc: 48.15%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3387, Acc: 47.66% | Val Loss: 0.4262, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3764, Acc: 47.92% | Val Loss: 0.4262, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3694, Acc: 47.40% | Val Loss: 0.4262, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3318, Acc: 51.82% | Val Loss: 0.3355, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2737, Acc: 62.50% | Val Loss: 0.3355, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2975, Acc: 57.03% | Val Loss: 0.3354, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.2912, Acc: 61.72% | Val Loss: 0.3354, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.2624, Acc: 64.58% | Val Loss: 0.3354, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.2880, Acc: 64.06% | Val Loss: 0.3353, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.3591, Acc: 49.22% | Val Loss: 0.3353, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.3549, Acc: 53.91% | Val Loss: 0.3352, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.3413, Acc: 51.30% | Val Loss: 0.3352, Acc: 40.74%\n",
      "Epoch 90: Train Loss: 0.3234, Acc: 54.95% | Val Loss: 0.3351, Acc: 40.74%\n",
      "Epoch 100: Train Loss: 0.3529, Acc: 54.17% | Val Loss: 0.3351, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.3138, Acc: 53.39% | Val Loss: 0.3350, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.3287, Acc: 55.47% | Val Loss: 0.3350, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.3294, Acc: 52.34% | Val Loss: 0.3349, Acc: 40.74%\n",
      "Epoch 140: Train Loss: 0.3121, Acc: 54.17% | Val Loss: 0.3349, Acc: 40.74%\n",
      "Epoch 150: Train Loss: 0.3159, Acc: 54.95% | Val Loss: 0.3349, Acc: 40.74%\n",
      "Epoch 160: Train Loss: 0.3042, Acc: 55.47% | Val Loss: 0.3348, Acc: 40.74%\n",
      "Epoch 170: Train Loss: 0.3536, Acc: 46.35% | Val Loss: 0.3348, Acc: 40.74%\n",
      "Epoch 180: Train Loss: 0.3293, Acc: 54.69% | Val Loss: 0.3347, Acc: 40.74%\n",
      "Epoch 190: Train Loss: 0.3108, Acc: 55.21% | Val Loss: 0.3347, Acc: 40.74%\n",
      "Epoch 200: Train Loss: 0.3256, Acc: 49.48% | Val Loss: 0.3346, Acc: 40.74%\n",
      "Epoch 210: Train Loss: 0.3245, Acc: 57.29% | Val Loss: 0.3346, Acc: 40.74%\n",
      "Epoch 220: Train Loss: 0.2987, Acc: 57.55% | Val Loss: 0.3345, Acc: 40.74%\n",
      "Epoch 230: Train Loss: 0.3024, Acc: 59.64% | Val Loss: 0.3345, Acc: 40.74%\n",
      "Epoch 240: Train Loss: 0.3334, Acc: 48.70% | Val Loss: 0.3345, Acc: 40.74%\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.4074\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3281, Acc: 64.32% | Val Loss: 0.3083, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.3280, Acc: 65.10% | Val Loss: 0.3083, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.3442, Acc: 61.98% | Val Loss: 0.3083, Acc: 62.96%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6296\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5185\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3964, Acc: 29.43% | Val Loss: 0.3157, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2549, Acc: 63.02% | Val Loss: 0.2583, Acc: 62.96%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2542, Acc: 53.12% | Val Loss: 0.2711, Acc: 44.44%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4444\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4091, Acc: 42.71% | Val Loss: 0.5227, Acc: 22.22%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2222\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2222\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3154, Acc: 48.70% | Val Loss: 0.3266, Acc: 33.33%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3333\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4222\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2442, Acc: 61.61% | Val Loss: 0.2917, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2521, Acc: 53.57% | Val Loss: 0.3046, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2447, Acc: 57.14% | Val Loss: 0.3018, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3237, Acc: 47.32% | Val Loss: 0.2675, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3469, Acc: 41.07% | Val Loss: 0.2879, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3108, Acc: 51.79% | Val Loss: 0.2883, Acc: 51.85%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5185\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2587, Acc: 60.71% | Val Loss: 0.2612, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2579, Acc: 61.61% | Val Loss: 0.2789, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2557, Acc: 60.71% | Val Loss: 0.2787, Acc: 55.56%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5556\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2862, Acc: 58.93% | Val Loss: 0.1993, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.2607, Acc: 61.61% | Val Loss: 0.1952, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2792, Acc: 60.71% | Val Loss: 0.1934, Acc: 77.78%\n",
      "Early stopping at epoch 28\n",
      "Restoring model weights from epoch 8\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2785, Acc: 64.29% | Val Loss: 0.3224, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2783, Acc: 63.39% | Val Loss: 0.3356, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2709, Acc: 60.71% | Val Loss: 0.3437, Acc: 55.56%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5556\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5778\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3636, Acc: 40.18% | Val Loss: 0.2777, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.3128, Acc: 54.46% | Val Loss: 0.2757, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3295, Acc: 56.25% | Val Loss: 0.2761, Acc: 48.15%\n",
      "Early stopping at epoch 22\n",
      "Restoring model weights from epoch 2\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3773, Acc: 41.96% | Val Loss: 0.4201, Acc: 29.63%\n",
      "Epoch 10: Train Loss: 0.3312, Acc: 52.68% | Val Loss: 0.4078, Acc: 33.33%\n",
      "Epoch 20: Train Loss: 0.3197, Acc: 53.57% | Val Loss: 0.3731, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.2982, Acc: 54.46% | Val Loss: 0.3472, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2519, Acc: 64.29% | Val Loss: 0.3225, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2614, Acc: 60.71% | Val Loss: 0.3133, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2411, Acc: 56.25% | Val Loss: 0.2804, Acc: 44.44%\n",
      "Epoch 70: Train Loss: 0.2339, Acc: 61.61% | Val Loss: 0.2543, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2034, Acc: 64.29% | Val Loss: 0.2448, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2003, Acc: 69.64% | Val Loss: 0.2533, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.1736, Acc: 72.32% | Val Loss: 0.2424, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.1887, Acc: 69.64% | Val Loss: 0.2235, Acc: 70.37%\n",
      "Epoch 120: Train Loss: 0.1652, Acc: 76.79% | Val Loss: 0.2313, Acc: 70.37%\n",
      "Epoch 130: Train Loss: 0.1752, Acc: 75.00% | Val Loss: 0.2241, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.1640, Acc: 80.36% | Val Loss: 0.2105, Acc: 70.37%\n",
      "Epoch 150: Train Loss: 0.1583, Acc: 75.89% | Val Loss: 0.2230, Acc: 59.26%\n",
      "Early stopping at epoch 154\n",
      "Restoring model weights from epoch 134\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5926\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3108, Acc: 55.36% | Val Loss: 0.2900, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2773, Acc: 57.14% | Val Loss: 0.3056, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2755, Acc: 58.04% | Val Loss: 0.3174, Acc: 51.85%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5185\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3150, Acc: 51.79% | Val Loss: 0.2024, Acc: 74.07%\n",
      "Epoch 10: Train Loss: 0.2743, Acc: 62.50% | Val Loss: 0.1863, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.2358, Acc: 64.29% | Val Loss: 0.1840, Acc: 77.78%\n",
      "Epoch 30: Train Loss: 0.2355, Acc: 63.39% | Val Loss: 0.1841, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.2552, Acc: 62.50% | Val Loss: 0.1894, Acc: 74.07%\n",
      "Early stopping at epoch 44\n",
      "Restoring model weights from epoch 24\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2990, Acc: 55.36% | Val Loss: 0.2031, Acc: 74.07%\n",
      "Epoch 10: Train Loss: 0.3081, Acc: 51.79% | Val Loss: 0.1986, Acc: 70.37%\n",
      "Epoch 20: Train Loss: 0.2619, Acc: 60.71% | Val Loss: 0.1996, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2442, Acc: 60.71% | Val Loss: 0.2047, Acc: 70.37%\n",
      "Early stopping at epoch 39\n",
      "Restoring model weights from epoch 19\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6296\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5926\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.3428, Acc: 39.58% | Val Loss: 0.3144, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2158, Acc: 66.07% | Val Loss: 0.3134, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2160, Acc: 66.07% | Val Loss: 0.3030, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2249, Acc: 60.12% | Val Loss: 0.2928, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.1979, Acc: 68.75% | Val Loss: 0.2929, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.2101, Acc: 66.37% | Val Loss: 0.2964, Acc: 48.15%\n",
      "Early stopping at epoch 52\n",
      "Restoring model weights from epoch 32\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2544, Acc: 48.51% | Val Loss: 0.2488, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2178, Acc: 71.73% | Val Loss: 0.2364, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2253, Acc: 69.94% | Val Loss: 0.2378, Acc: 59.26%\n",
      "Early stopping at epoch 29\n",
      "Restoring model weights from epoch 9\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2860, Acc: 42.56% | Val Loss: 0.2658, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2361, Acc: 61.90% | Val Loss: 0.2289, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2302, Acc: 65.48% | Val Loss: 0.2357, Acc: 66.67%\n",
      "Early stopping at epoch 27\n",
      "Restoring model weights from epoch 7\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2692, Acc: 46.43% | Val Loss: 0.2447, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2510, Acc: 57.74% | Val Loss: 0.1947, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2293, Acc: 58.04% | Val Loss: 0.1910, Acc: 81.48%\n",
      "Epoch 30: Train Loss: 0.2454, Acc: 57.74% | Val Loss: 0.1847, Acc: 77.78%\n",
      "Epoch 40: Train Loss: 0.2208, Acc: 67.56% | Val Loss: 0.1824, Acc: 77.78%\n",
      "Epoch 50: Train Loss: 0.2313, Acc: 63.99% | Val Loss: 0.1822, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.2232, Acc: 65.77% | Val Loss: 0.1842, Acc: 70.37%\n",
      "Epoch 70: Train Loss: 0.2203, Acc: 64.58% | Val Loss: 0.1801, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2281, Acc: 63.69% | Val Loss: 0.1819, Acc: 70.37%\n",
      "Epoch 90: Train Loss: 0.2199, Acc: 64.29% | Val Loss: 0.1791, Acc: 70.37%\n",
      "Epoch 100: Train Loss: 0.2221, Acc: 61.90% | Val Loss: 0.1804, Acc: 66.67%\n",
      "Early stopping at epoch 104\n",
      "Restoring model weights from epoch 84\n",
      "Final Validation Accuracy: 0.7037\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7037\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 150, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 0.2198, Acc: 67.86% | Val Loss: 0.2190, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2179, Acc: 63.39% | Val Loss: 0.2270, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2207, Acc: 64.88% | Val Loss: 0.2320, Acc: 66.67%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6667\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6296\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2754, Acc: 55.21% | Val Loss: 0.2964, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2453, Acc: 54.17% | Val Loss: 0.3047, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.2511, Acc: 52.60% | Val Loss: 0.3037, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.2679, Acc: 52.08% | Val Loss: 0.3035, Acc: 37.04%\n",
      "Epoch 40: Train Loss: 0.2597, Acc: 52.34% | Val Loss: 0.3028, Acc: 37.04%\n",
      "Epoch 50: Train Loss: 0.2403, Acc: 60.42% | Val Loss: 0.3022, Acc: 37.04%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.3704\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2512, Acc: 63.54% | Val Loss: 0.3070, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2744, Acc: 51.30% | Val Loss: 0.2383, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2641, Acc: 54.17% | Val Loss: 0.2373, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2661, Acc: 55.21% | Val Loss: 0.2374, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2829, Acc: 46.88% | Val Loss: 0.2366, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2641, Acc: 51.82% | Val Loss: 0.2360, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2643, Acc: 52.34% | Val Loss: 0.2369, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2630, Acc: 52.34% | Val Loss: 0.2368, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2648, Acc: 55.73% | Val Loss: 0.2358, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2631, Acc: 53.39% | Val Loss: 0.2362, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2650, Acc: 53.12% | Val Loss: 0.2354, Acc: 62.96%\n",
      "Early stopping at epoch 105\n",
      "Restoring model weights from epoch 55\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3538, Acc: 34.38% | Val Loss: 0.3192, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.3386, Acc: 36.46% | Val Loss: 0.3475, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.3535, Acc: 32.03% | Val Loss: 0.3476, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.3346, Acc: 42.97% | Val Loss: 0.3484, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.3360, Acc: 35.94% | Val Loss: 0.3466, Acc: 37.04%\n",
      "Epoch 50: Train Loss: 0.3237, Acc: 41.93% | Val Loss: 0.3485, Acc: 37.04%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.3704\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2692, Acc: 58.33% | Val Loss: 0.3193, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.2949, Acc: 50.78% | Val Loss: 0.2616, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2534, Acc: 61.20% | Val Loss: 0.2603, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2725, Acc: 57.81% | Val Loss: 0.2608, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2658, Acc: 53.91% | Val Loss: 0.2557, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2555, Acc: 59.90% | Val Loss: 0.2585, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2511, Acc: 64.84% | Val Loss: 0.2555, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2662, Acc: 57.29% | Val Loss: 0.2508, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2676, Acc: 55.73% | Val Loss: 0.2535, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2675, Acc: 55.47% | Val Loss: 0.2482, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.2691, Acc: 55.21% | Val Loss: 0.2468, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2586, Acc: 59.64% | Val Loss: 0.2480, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.2521, Acc: 58.33% | Val Loss: 0.2490, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.2456, Acc: 60.68% | Val Loss: 0.2449, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.2558, Acc: 58.33% | Val Loss: 0.2454, Acc: 66.67%\n",
      "Epoch 150: Train Loss: 0.2493, Acc: 56.51% | Val Loss: 0.2460, Acc: 66.67%\n",
      "Epoch 160: Train Loss: 0.2604, Acc: 58.59% | Val Loss: 0.2443, Acc: 66.67%\n",
      "Epoch 170: Train Loss: 0.2502, Acc: 55.47% | Val Loss: 0.2405, Acc: 66.67%\n",
      "Epoch 180: Train Loss: 0.2512, Acc: 61.98% | Val Loss: 0.2399, Acc: 66.67%\n",
      "Epoch 190: Train Loss: 0.2597, Acc: 54.17% | Val Loss: 0.2370, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6667\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3927, Acc: 46.09% | Val Loss: 0.3118, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.4193, Acc: 40.10% | Val Loss: 0.3169, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.4084, Acc: 39.06% | Val Loss: 0.3170, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.3885, Acc: 44.27% | Val Loss: 0.3151, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.4332, Acc: 43.49% | Val Loss: 0.3142, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.3821, Acc: 41.67% | Val Loss: 0.3141, Acc: 59.26%\n",
      "Early stopping at epoch 51\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5556\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5185\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2713, Acc: 52.08% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2592, Acc: 49.22% | Val Loss: 0.2663, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2516, Acc: 59.11% | Val Loss: 0.2687, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2371, Acc: 59.90% | Val Loss: 0.2613, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2026, Acc: 70.05% | Val Loss: 0.2610, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2172, Acc: 63.02% | Val Loss: 0.2634, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.1891, Acc: 71.88% | Val Loss: 0.2628, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.1962, Acc: 71.35% | Val Loss: 0.2722, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2014, Acc: 69.27% | Val Loss: 0.2757, Acc: 48.15%\n",
      "Early stopping at epoch 83\n",
      "Restoring model weights from epoch 33\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2734, Acc: 61.72% | Val Loss: 0.2643, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2323, Acc: 64.32% | Val Loss: 0.2620, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2314, Acc: 63.28% | Val Loss: 0.2596, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2114, Acc: 66.67% | Val Loss: 0.2586, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2275, Acc: 66.41% | Val Loss: 0.2571, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2111, Acc: 65.62% | Val Loss: 0.2582, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2067, Acc: 68.23% | Val Loss: 0.2568, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.1942, Acc: 72.66% | Val Loss: 0.2577, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.1967, Acc: 70.05% | Val Loss: 0.2578, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2133, Acc: 68.49% | Val Loss: 0.2580, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2068, Acc: 66.93% | Val Loss: 0.2590, Acc: 51.85%\n",
      "Epoch 110: Train Loss: 0.2015, Acc: 72.14% | Val Loss: 0.2595, Acc: 51.85%\n",
      "Early stopping at epoch 111\n",
      "Restoring model weights from epoch 61\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5185\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.3127, Acc: 40.62% | Val Loss: 0.3372, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.2764, Acc: 49.74% | Val Loss: 0.3327, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2554, Acc: 56.77% | Val Loss: 0.3218, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2315, Acc: 60.16% | Val Loss: 0.3137, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.2202, Acc: 64.32% | Val Loss: 0.3044, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.2224, Acc: 64.06% | Val Loss: 0.2956, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.2172, Acc: 60.16% | Val Loss: 0.2980, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2183, Acc: 67.71% | Val Loss: 0.2920, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2095, Acc: 59.64% | Val Loss: 0.2895, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.2156, Acc: 65.36% | Val Loss: 0.2856, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.2074, Acc: 68.49% | Val Loss: 0.2843, Acc: 44.44%\n",
      "Epoch 110: Train Loss: 0.2052, Acc: 68.75% | Val Loss: 0.2846, Acc: 44.44%\n",
      "Epoch 120: Train Loss: 0.2171, Acc: 69.27% | Val Loss: 0.2855, Acc: 44.44%\n",
      "Epoch 130: Train Loss: 0.2396, Acc: 64.06% | Val Loss: 0.2877, Acc: 44.44%\n",
      "Epoch 140: Train Loss: 0.2024, Acc: 70.31% | Val Loss: 0.2868, Acc: 44.44%\n",
      "Epoch 150: Train Loss: 0.2068, Acc: 70.05% | Val Loss: 0.2871, Acc: 44.44%\n",
      "Epoch 160: Train Loss: 0.2238, Acc: 67.45% | Val Loss: 0.2860, Acc: 44.44%\n",
      "Early stopping at epoch 167\n",
      "Restoring model weights from epoch 117\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4444\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2800, Acc: 57.29% | Val Loss: 0.1777, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.2591, Acc: 53.39% | Val Loss: 0.1832, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2444, Acc: 55.99% | Val Loss: 0.1792, Acc: 70.37%\n",
      "Epoch 30: Train Loss: 0.2151, Acc: 66.41% | Val Loss: 0.1786, Acc: 70.37%\n",
      "Epoch 40: Train Loss: 0.2133, Acc: 61.72% | Val Loss: 0.1783, Acc: 70.37%\n",
      "Epoch 50: Train Loss: 0.2202, Acc: 60.68% | Val Loss: 0.1798, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.2192, Acc: 60.94% | Val Loss: 0.1810, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.2441, Acc: 57.03% | Val Loss: 0.1815, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2341, Acc: 58.33% | Val Loss: 0.1835, Acc: 66.67%\n",
      "Early stopping at epoch 89\n",
      "Restoring model weights from epoch 39\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6667\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2899, Acc: 54.17% | Val Loss: 0.2642, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2794, Acc: 57.55% | Val Loss: 0.2923, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2216, Acc: 67.97% | Val Loss: 0.2934, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2039, Acc: 69.27% | Val Loss: 0.2808, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2245, Acc: 63.54% | Val Loss: 0.2810, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2268, Acc: 67.19% | Val Loss: 0.2717, Acc: 55.56%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5556\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5333\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.01, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3635, Acc: 52.98% | Val Loss: 0.2603, Acc: 70.37%\n",
      "Epoch 10: Train Loss: 0.4307, Acc: 46.43% | Val Loss: 0.2674, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.3539, Acc: 53.87% | Val Loss: 0.2677, Acc: 66.67%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6667\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.01, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3007, Acc: 48.21% | Val Loss: 0.2898, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2841, Acc: 51.19% | Val Loss: 0.2838, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3009, Acc: 50.00% | Val Loss: 0.2831, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2943, Acc: 54.17% | Val Loss: 0.2837, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2784, Acc: 56.85% | Val Loss: 0.2815, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2804, Acc: 49.40% | Val Loss: 0.2788, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2556, Acc: 53.27% | Val Loss: 0.2769, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.2701, Acc: 55.36% | Val Loss: 0.2760, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2944, Acc: 50.30% | Val Loss: 0.2767, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2963, Acc: 48.81% | Val Loss: 0.2782, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2697, Acc: 54.46% | Val Loss: 0.2741, Acc: 51.85%\n",
      "Epoch 110: Train Loss: 0.2564, Acc: 58.93% | Val Loss: 0.2727, Acc: 51.85%\n",
      "Epoch 120: Train Loss: 0.2780, Acc: 57.14% | Val Loss: 0.2702, Acc: 51.85%\n",
      "Epoch 130: Train Loss: 0.2854, Acc: 53.57% | Val Loss: 0.2706, Acc: 51.85%\n",
      "Epoch 140: Train Loss: 0.2722, Acc: 55.06% | Val Loss: 0.2700, Acc: 51.85%\n",
      "Epoch 150: Train Loss: 0.2821, Acc: 51.79% | Val Loss: 0.2686, Acc: 51.85%\n",
      "Epoch 160: Train Loss: 0.2626, Acc: 59.82% | Val Loss: 0.2659, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2592, Acc: 55.95% | Val Loss: 0.2672, Acc: 51.85%\n",
      "Epoch 180: Train Loss: 0.2659, Acc: 54.46% | Val Loss: 0.2653, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2540, Acc: 60.42% | Val Loss: 0.2655, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2739, Acc: 52.68% | Val Loss: 0.2647, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.2663, Acc: 55.36% | Val Loss: 0.2621, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.2483, Acc: 59.82% | Val Loss: 0.2609, Acc: 48.15%\n",
      "Epoch 230: Train Loss: 0.2553, Acc: 54.46% | Val Loss: 0.2591, Acc: 48.15%\n",
      "Epoch 240: Train Loss: 0.2501, Acc: 61.01% | Val Loss: 0.2595, Acc: 48.15%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.01, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3344, Acc: 50.60% | Val Loss: 0.3649, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.3170, Acc: 53.87% | Val Loss: 0.3590, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3232, Acc: 53.57% | Val Loss: 0.3589, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.3641, Acc: 48.81% | Val Loss: 0.3592, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.3575, Acc: 52.98% | Val Loss: 0.3575, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.3018, Acc: 60.42% | Val Loss: 0.3572, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.3006, Acc: 61.01% | Val Loss: 0.3576, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.3465, Acc: 50.60% | Val Loss: 0.3575, Acc: 51.85%\n",
      "Early stopping at epoch 77\n",
      "Restoring model weights from epoch 57\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.01, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4153, Acc: 43.45% | Val Loss: 0.3382, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.3697, Acc: 47.02% | Val Loss: 0.4250, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.4370, Acc: 43.45% | Val Loss: 0.4198, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.01, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3645, Acc: 49.40% | Val Loss: 0.3551, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.3611, Acc: 48.81% | Val Loss: 0.3482, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.3835, Acc: 46.73% | Val Loss: 0.3476, Acc: 51.85%\n",
      "Early stopping at epoch 26\n",
      "Restoring model weights from epoch 6\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5556\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5333\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3266, Acc: 44.35% | Val Loss: 0.3098, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.3671, Acc: 36.01% | Val Loss: 0.3092, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.3551, Acc: 43.45% | Val Loss: 0.3085, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.3848, Acc: 35.71% | Val Loss: 0.3079, Acc: 37.04%\n",
      "Epoch 40: Train Loss: 0.3277, Acc: 47.62% | Val Loss: 0.3073, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.3582, Acc: 40.48% | Val Loss: 0.3067, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.3400, Acc: 43.75% | Val Loss: 0.3061, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.3408, Acc: 42.86% | Val Loss: 0.3055, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.3557, Acc: 38.99% | Val Loss: 0.3050, Acc: 40.74%\n",
      "Epoch 90: Train Loss: 0.3429, Acc: 45.24% | Val Loss: 0.3044, Acc: 40.74%\n",
      "Epoch 100: Train Loss: 0.3422, Acc: 44.94% | Val Loss: 0.3038, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.3522, Acc: 38.99% | Val Loss: 0.3032, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.3449, Acc: 40.77% | Val Loss: 0.3027, Acc: 44.44%\n",
      "Epoch 130: Train Loss: 0.3515, Acc: 36.90% | Val Loss: 0.3021, Acc: 44.44%\n",
      "Epoch 140: Train Loss: 0.3441, Acc: 42.26% | Val Loss: 0.3016, Acc: 44.44%\n",
      "Epoch 150: Train Loss: 0.3123, Acc: 47.32% | Val Loss: 0.3011, Acc: 44.44%\n",
      "Epoch 160: Train Loss: 0.3548, Acc: 38.99% | Val Loss: 0.3006, Acc: 40.74%\n",
      "Epoch 170: Train Loss: 0.3424, Acc: 37.50% | Val Loss: 0.3000, Acc: 40.74%\n",
      "Epoch 180: Train Loss: 0.3336, Acc: 42.86% | Val Loss: 0.2995, Acc: 40.74%\n",
      "Epoch 190: Train Loss: 0.3305, Acc: 45.83% | Val Loss: 0.2990, Acc: 44.44%\n",
      "Epoch 200: Train Loss: 0.3339, Acc: 41.37% | Val Loss: 0.2985, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.3167, Acc: 44.35% | Val Loss: 0.2980, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.3244, Acc: 43.45% | Val Loss: 0.2975, Acc: 48.15%\n",
      "Epoch 230: Train Loss: 0.3245, Acc: 41.07% | Val Loss: 0.2971, Acc: 48.15%\n",
      "Epoch 240: Train Loss: 0.3476, Acc: 39.88% | Val Loss: 0.2966, Acc: 48.15%\n",
      "Epoch 250: Train Loss: 0.3392, Acc: 35.42% | Val Loss: 0.2961, Acc: 48.15%\n",
      "Epoch 260: Train Loss: 0.3416, Acc: 40.77% | Val Loss: 0.2957, Acc: 48.15%\n",
      "Epoch 270: Train Loss: 0.3392, Acc: 37.20% | Val Loss: 0.2952, Acc: 48.15%\n",
      "Epoch 280: Train Loss: 0.3087, Acc: 42.26% | Val Loss: 0.2948, Acc: 48.15%\n",
      "Epoch 290: Train Loss: 0.3235, Acc: 42.26% | Val Loss: 0.2944, Acc: 48.15%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.5222, Acc: 36.31% | Val Loss: 0.5275, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.5080, Acc: 36.61% | Val Loss: 0.5266, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.5258, Acc: 36.01% | Val Loss: 0.5257, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.5272, Acc: 35.42% | Val Loss: 0.5249, Acc: 37.04%\n",
      "Epoch 40: Train Loss: 0.5204, Acc: 36.01% | Val Loss: 0.5240, Acc: 37.04%\n",
      "Epoch 50: Train Loss: 0.5243, Acc: 35.71% | Val Loss: 0.5231, Acc: 37.04%\n",
      "Epoch 60: Train Loss: 0.5101, Acc: 36.01% | Val Loss: 0.5221, Acc: 37.04%\n",
      "Epoch 70: Train Loss: 0.5132, Acc: 36.01% | Val Loss: 0.5212, Acc: 37.04%\n",
      "Epoch 80: Train Loss: 0.5110, Acc: 36.31% | Val Loss: 0.5203, Acc: 37.04%\n",
      "Epoch 90: Train Loss: 0.5081, Acc: 36.01% | Val Loss: 0.5194, Acc: 37.04%\n",
      "Epoch 100: Train Loss: 0.5096, Acc: 36.01% | Val Loss: 0.5184, Acc: 37.04%\n",
      "Epoch 110: Train Loss: 0.5065, Acc: 36.01% | Val Loss: 0.5174, Acc: 37.04%\n",
      "Epoch 120: Train Loss: 0.4920, Acc: 37.20% | Val Loss: 0.5165, Acc: 37.04%\n",
      "Epoch 130: Train Loss: 0.5074, Acc: 36.31% | Val Loss: 0.5155, Acc: 37.04%\n",
      "Epoch 140: Train Loss: 0.5171, Acc: 36.01% | Val Loss: 0.5145, Acc: 37.04%\n",
      "Epoch 150: Train Loss: 0.4891, Acc: 36.61% | Val Loss: 0.5135, Acc: 37.04%\n",
      "Epoch 160: Train Loss: 0.5165, Acc: 36.01% | Val Loss: 0.5125, Acc: 37.04%\n",
      "Epoch 170: Train Loss: 0.4988, Acc: 36.31% | Val Loss: 0.5115, Acc: 37.04%\n",
      "Epoch 180: Train Loss: 0.5110, Acc: 35.42% | Val Loss: 0.5105, Acc: 37.04%\n",
      "Epoch 190: Train Loss: 0.5140, Acc: 36.31% | Val Loss: 0.5095, Acc: 37.04%\n",
      "Epoch 200: Train Loss: 0.4947, Acc: 37.50% | Val Loss: 0.5085, Acc: 37.04%\n",
      "Epoch 210: Train Loss: 0.4890, Acc: 35.71% | Val Loss: 0.5075, Acc: 37.04%\n",
      "Epoch 220: Train Loss: 0.4784, Acc: 37.50% | Val Loss: 0.5064, Acc: 37.04%\n",
      "Epoch 230: Train Loss: 0.4809, Acc: 37.20% | Val Loss: 0.5054, Acc: 37.04%\n",
      "Epoch 240: Train Loss: 0.4989, Acc: 36.01% | Val Loss: 0.5044, Acc: 37.04%\n",
      "Epoch 250: Train Loss: 0.4944, Acc: 36.01% | Val Loss: 0.5033, Acc: 37.04%\n",
      "Epoch 260: Train Loss: 0.4934, Acc: 35.12% | Val Loss: 0.5023, Acc: 37.04%\n",
      "Epoch 270: Train Loss: 0.4993, Acc: 35.71% | Val Loss: 0.5012, Acc: 37.04%\n",
      "Epoch 280: Train Loss: 0.4891, Acc: 35.71% | Val Loss: 0.5001, Acc: 37.04%\n",
      "Epoch 290: Train Loss: 0.4967, Acc: 36.31% | Val Loss: 0.4990, Acc: 37.04%\n",
      "Final Validation Accuracy: 0.3704\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3704\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2661, Acc: 46.13% | Val Loss: 0.2338, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2625, Acc: 50.60% | Val Loss: 0.2335, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2584, Acc: 48.51% | Val Loss: 0.2332, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2470, Acc: 53.57% | Val Loss: 0.2330, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2508, Acc: 48.21% | Val Loss: 0.2327, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2626, Acc: 49.11% | Val Loss: 0.2324, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2506, Acc: 51.79% | Val Loss: 0.2322, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2478, Acc: 51.49% | Val Loss: 0.2319, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2564, Acc: 49.70% | Val Loss: 0.2317, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2474, Acc: 52.08% | Val Loss: 0.2315, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.2520, Acc: 56.25% | Val Loss: 0.2313, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2569, Acc: 50.89% | Val Loss: 0.2310, Acc: 70.37%\n",
      "Epoch 120: Train Loss: 0.2469, Acc: 55.36% | Val Loss: 0.2308, Acc: 70.37%\n",
      "Epoch 130: Train Loss: 0.2520, Acc: 55.36% | Val Loss: 0.2306, Acc: 70.37%\n",
      "Epoch 140: Train Loss: 0.2573, Acc: 51.79% | Val Loss: 0.2304, Acc: 70.37%\n",
      "Epoch 150: Train Loss: 0.2479, Acc: 55.65% | Val Loss: 0.2302, Acc: 70.37%\n",
      "Epoch 160: Train Loss: 0.2571, Acc: 47.62% | Val Loss: 0.2300, Acc: 70.37%\n",
      "Epoch 170: Train Loss: 0.2481, Acc: 56.85% | Val Loss: 0.2297, Acc: 66.67%\n",
      "Epoch 180: Train Loss: 0.2309, Acc: 61.01% | Val Loss: 0.2295, Acc: 66.67%\n",
      "Epoch 190: Train Loss: 0.2400, Acc: 55.95% | Val Loss: 0.2293, Acc: 66.67%\n",
      "Epoch 200: Train Loss: 0.2457, Acc: 52.08% | Val Loss: 0.2291, Acc: 66.67%\n",
      "Epoch 210: Train Loss: 0.2528, Acc: 58.04% | Val Loss: 0.2289, Acc: 66.67%\n",
      "Epoch 220: Train Loss: 0.2463, Acc: 53.87% | Val Loss: 0.2287, Acc: 66.67%\n",
      "Epoch 230: Train Loss: 0.2554, Acc: 53.87% | Val Loss: 0.2285, Acc: 66.67%\n",
      "Epoch 240: Train Loss: 0.2491, Acc: 52.38% | Val Loss: 0.2283, Acc: 62.96%\n",
      "Epoch 250: Train Loss: 0.2385, Acc: 60.42% | Val Loss: 0.2281, Acc: 62.96%\n",
      "Epoch 260: Train Loss: 0.2534, Acc: 49.11% | Val Loss: 0.2279, Acc: 62.96%\n",
      "Epoch 270: Train Loss: 0.2587, Acc: 47.92% | Val Loss: 0.2278, Acc: 62.96%\n",
      "Epoch 280: Train Loss: 0.2466, Acc: 57.74% | Val Loss: 0.2276, Acc: 62.96%\n",
      "Epoch 290: Train Loss: 0.2539, Acc: 50.89% | Val Loss: 0.2274, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6296\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2451, Acc: 58.63% | Val Loss: 0.2259, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2453, Acc: 55.06% | Val Loss: 0.2254, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2676, Acc: 48.21% | Val Loss: 0.2251, Acc: 70.37%\n",
      "Epoch 30: Train Loss: 0.2534, Acc: 57.14% | Val Loss: 0.2247, Acc: 70.37%\n",
      "Epoch 40: Train Loss: 0.2575, Acc: 57.14% | Val Loss: 0.2244, Acc: 70.37%\n",
      "Epoch 50: Train Loss: 0.2595, Acc: 52.68% | Val Loss: 0.2240, Acc: 70.37%\n",
      "Epoch 60: Train Loss: 0.2423, Acc: 56.85% | Val Loss: 0.2237, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.2367, Acc: 58.93% | Val Loss: 0.2234, Acc: 74.07%\n",
      "Epoch 80: Train Loss: 0.2458, Acc: 59.52% | Val Loss: 0.2230, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.2619, Acc: 53.27% | Val Loss: 0.2227, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.2393, Acc: 59.82% | Val Loss: 0.2224, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.2455, Acc: 57.44% | Val Loss: 0.2221, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.2581, Acc: 54.76% | Val Loss: 0.2218, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.2502, Acc: 57.44% | Val Loss: 0.2215, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.2440, Acc: 57.44% | Val Loss: 0.2212, Acc: 74.07%\n",
      "Epoch 150: Train Loss: 0.2532, Acc: 51.19% | Val Loss: 0.2209, Acc: 74.07%\n",
      "Epoch 160: Train Loss: 0.2570, Acc: 55.06% | Val Loss: 0.2205, Acc: 74.07%\n",
      "Epoch 170: Train Loss: 0.2335, Acc: 61.61% | Val Loss: 0.2202, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.2506, Acc: 58.63% | Val Loss: 0.2199, Acc: 74.07%\n",
      "Epoch 190: Train Loss: 0.2559, Acc: 53.87% | Val Loss: 0.2196, Acc: 74.07%\n",
      "Epoch 200: Train Loss: 0.2550, Acc: 55.95% | Val Loss: 0.2193, Acc: 74.07%\n",
      "Epoch 210: Train Loss: 0.2572, Acc: 58.93% | Val Loss: 0.2190, Acc: 74.07%\n",
      "Epoch 220: Train Loss: 0.2650, Acc: 53.57% | Val Loss: 0.2187, Acc: 74.07%\n",
      "Epoch 230: Train Loss: 0.2382, Acc: 59.52% | Val Loss: 0.2185, Acc: 74.07%\n",
      "Epoch 240: Train Loss: 0.2417, Acc: 61.01% | Val Loss: 0.2182, Acc: 74.07%\n",
      "Epoch 250: Train Loss: 0.2425, Acc: 57.74% | Val Loss: 0.2180, Acc: 74.07%\n",
      "Epoch 260: Train Loss: 0.2508, Acc: 59.23% | Val Loss: 0.2177, Acc: 74.07%\n",
      "Epoch 270: Train Loss: 0.2524, Acc: 55.65% | Val Loss: 0.2174, Acc: 74.07%\n",
      "Epoch 280: Train Loss: 0.2455, Acc: 55.06% | Val Loss: 0.2172, Acc: 74.07%\n",
      "Epoch 290: Train Loss: 0.2496, Acc: 58.04% | Val Loss: 0.2169, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2279, Acc: 65.18% | Val Loss: 0.2623, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2340, Acc: 60.71% | Val Loss: 0.2623, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2470, Acc: 65.18% | Val Loss: 0.2622, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2433, Acc: 62.20% | Val Loss: 0.2621, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2504, Acc: 63.69% | Val Loss: 0.2620, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2452, Acc: 61.31% | Val Loss: 0.2620, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2473, Acc: 60.71% | Val Loss: 0.2619, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2451, Acc: 62.20% | Val Loss: 0.2618, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2248, Acc: 66.96% | Val Loss: 0.2617, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2422, Acc: 63.39% | Val Loss: 0.2617, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2368, Acc: 64.88% | Val Loss: 0.2616, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2384, Acc: 62.20% | Val Loss: 0.2616, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.2455, Acc: 61.01% | Val Loss: 0.2615, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2428, Acc: 61.90% | Val Loss: 0.2614, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.2531, Acc: 59.23% | Val Loss: 0.2614, Acc: 59.26%\n",
      "Epoch 150: Train Loss: 0.2339, Acc: 65.48% | Val Loss: 0.2613, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.2336, Acc: 63.69% | Val Loss: 0.2612, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.2525, Acc: 59.52% | Val Loss: 0.2611, Acc: 59.26%\n",
      "Epoch 180: Train Loss: 0.2449, Acc: 65.18% | Val Loss: 0.2611, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.2342, Acc: 63.69% | Val Loss: 0.2610, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.2425, Acc: 62.80% | Val Loss: 0.2609, Acc: 59.26%\n",
      "Epoch 210: Train Loss: 0.2396, Acc: 64.88% | Val Loss: 0.2609, Acc: 59.26%\n",
      "Epoch 220: Train Loss: 0.2466, Acc: 63.99% | Val Loss: 0.2608, Acc: 59.26%\n",
      "Epoch 230: Train Loss: 0.2536, Acc: 61.90% | Val Loss: 0.2607, Acc: 59.26%\n",
      "Epoch 240: Train Loss: 0.2464, Acc: 61.31% | Val Loss: 0.2607, Acc: 59.26%\n",
      "Epoch 250: Train Loss: 0.2468, Acc: 63.39% | Val Loss: 0.2606, Acc: 59.26%\n",
      "Epoch 260: Train Loss: 0.2565, Acc: 58.33% | Val Loss: 0.2605, Acc: 59.26%\n",
      "Epoch 270: Train Loss: 0.2379, Acc: 62.80% | Val Loss: 0.2605, Acc: 59.26%\n",
      "Epoch 280: Train Loss: 0.2466, Acc: 62.80% | Val Loss: 0.2604, Acc: 59.26%\n",
      "Epoch 290: Train Loss: 0.2541, Acc: 57.44% | Val Loss: 0.2604, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5630\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2522, Acc: 48.21% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2503, Acc: 47.32% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2520, Acc: 42.86% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2504, Acc: 47.32% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2517, Acc: 41.07% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.2517, Acc: 46.43% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Early stopping at epoch 51\n",
      "Restoring model weights from epoch 21\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2531, Acc: 46.43% | Val Loss: 0.2632, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2542, Acc: 47.32% | Val Loss: 0.2629, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2533, Acc: 41.07% | Val Loss: 0.2628, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2583, Acc: 44.64% | Val Loss: 0.2628, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2539, Acc: 45.54% | Val Loss: 0.2627, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.2585, Acc: 42.86% | Val Loss: 0.2627, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.2514, Acc: 47.32% | Val Loss: 0.2627, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2547, Acc: 50.00% | Val Loss: 0.2626, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2531, Acc: 43.75% | Val Loss: 0.2626, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.2581, Acc: 45.54% | Val Loss: 0.2626, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.2553, Acc: 45.54% | Val Loss: 0.2626, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2557, Acc: 43.75% | Val Loss: 0.2626, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2519, Acc: 48.21% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.2551, Acc: 43.75% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2531, Acc: 49.11% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.2544, Acc: 50.00% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.2521, Acc: 50.00% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2543, Acc: 44.64% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.2565, Acc: 48.21% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2570, Acc: 44.64% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2495, Acc: 52.68% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.2526, Acc: 49.11% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.2569, Acc: 47.32% | Val Loss: 0.2625, Acc: 48.15%\n",
      "Epoch 230: Train Loss: 0.2566, Acc: 50.89% | Val Loss: 0.2624, Acc: 48.15%\n",
      "Epoch 240: Train Loss: 0.2560, Acc: 47.32% | Val Loss: 0.2624, Acc: 48.15%\n",
      "Epoch 250: Train Loss: 0.2544, Acc: 50.00% | Val Loss: 0.2624, Acc: 51.85%\n",
      "Epoch 260: Train Loss: 0.2552, Acc: 44.64% | Val Loss: 0.2624, Acc: 51.85%\n",
      "Epoch 270: Train Loss: 0.2552, Acc: 47.32% | Val Loss: 0.2624, Acc: 51.85%\n",
      "Epoch 280: Train Loss: 0.2531, Acc: 46.43% | Val Loss: 0.2624, Acc: 51.85%\n",
      "Epoch 290: Train Loss: 0.2514, Acc: 50.89% | Val Loss: 0.2624, Acc: 51.85%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2497, Acc: 50.00% | Val Loss: 0.2490, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2477, Acc: 50.00% | Val Loss: 0.2489, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2481, Acc: 52.68% | Val Loss: 0.2489, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2449, Acc: 58.93% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2509, Acc: 48.21% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2491, Acc: 49.11% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2466, Acc: 61.61% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2456, Acc: 56.25% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2465, Acc: 58.04% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2490, Acc: 55.36% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2491, Acc: 53.57% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.2484, Acc: 49.11% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2500, Acc: 50.00% | Val Loss: 0.2488, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.2479, Acc: 51.79% | Val Loss: 0.2487, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2488, Acc: 45.54% | Val Loss: 0.2487, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2499, Acc: 50.00% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.2486, Acc: 55.36% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.2464, Acc: 54.46% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 180: Train Loss: 0.2478, Acc: 52.68% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.2461, Acc: 55.36% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.2463, Acc: 54.46% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 210: Train Loss: 0.2447, Acc: 54.46% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Epoch 220: Train Loss: 0.2460, Acc: 50.00% | Val Loss: 0.2487, Acc: 59.26%\n",
      "Early stopping at epoch 229\n",
      "Restoring model weights from epoch 199\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5926\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2560, Acc: 40.18% | Val Loss: 0.2524, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.2551, Acc: 42.86% | Val Loss: 0.2521, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2514, Acc: 51.79% | Val Loss: 0.2520, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2567, Acc: 45.54% | Val Loss: 0.2519, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2507, Acc: 49.11% | Val Loss: 0.2519, Acc: 44.44%\n",
      "Epoch 50: Train Loss: 0.2531, Acc: 50.89% | Val Loss: 0.2518, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.2549, Acc: 44.64% | Val Loss: 0.2518, Acc: 44.44%\n",
      "Epoch 70: Train Loss: 0.2537, Acc: 47.32% | Val Loss: 0.2518, Acc: 44.44%\n",
      "Epoch 80: Train Loss: 0.2541, Acc: 46.43% | Val Loss: 0.2517, Acc: 44.44%\n",
      "Epoch 90: Train Loss: 0.2565, Acc: 43.75% | Val Loss: 0.2517, Acc: 44.44%\n",
      "Epoch 100: Train Loss: 0.2566, Acc: 41.07% | Val Loss: 0.2517, Acc: 44.44%\n",
      "Epoch 110: Train Loss: 0.2537, Acc: 44.64% | Val Loss: 0.2517, Acc: 44.44%\n",
      "Epoch 120: Train Loss: 0.2526, Acc: 49.11% | Val Loss: 0.2517, Acc: 44.44%\n",
      "Epoch 130: Train Loss: 0.2597, Acc: 36.61% | Val Loss: 0.2517, Acc: 44.44%\n",
      "Epoch 140: Train Loss: 0.2525, Acc: 50.00% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 150: Train Loss: 0.2577, Acc: 45.54% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 160: Train Loss: 0.2517, Acc: 46.43% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 170: Train Loss: 0.2563, Acc: 42.86% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 180: Train Loss: 0.2580, Acc: 42.86% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 190: Train Loss: 0.2557, Acc: 44.64% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 200: Train Loss: 0.2515, Acc: 49.11% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 210: Train Loss: 0.2518, Acc: 51.79% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 220: Train Loss: 0.2516, Acc: 48.21% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 230: Train Loss: 0.2556, Acc: 42.86% | Val Loss: 0.2516, Acc: 44.44%\n",
      "Epoch 240: Train Loss: 0.2523, Acc: 50.00% | Val Loss: 0.2515, Acc: 44.44%\n",
      "Epoch 250: Train Loss: 0.2504, Acc: 47.32% | Val Loss: 0.2515, Acc: 44.44%\n",
      "Epoch 260: Train Loss: 0.2529, Acc: 48.21% | Val Loss: 0.2515, Acc: 44.44%\n",
      "Epoch 270: Train Loss: 0.2543, Acc: 47.32% | Val Loss: 0.2515, Acc: 44.44%\n",
      "Epoch 280: Train Loss: 0.2543, Acc: 44.64% | Val Loss: 0.2515, Acc: 44.44%\n",
      "Epoch 290: Train Loss: 0.2503, Acc: 50.00% | Val Loss: 0.2515, Acc: 44.44%\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.4444\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 0.001, 'l2': 0.001, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2531, Acc: 52.68% | Val Loss: 0.2467, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2538, Acc: 49.11% | Val Loss: 0.2465, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2651, Acc: 41.07% | Val Loss: 0.2465, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2608, Acc: 52.68% | Val Loss: 0.2464, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2530, Acc: 55.36% | Val Loss: 0.2464, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2647, Acc: 48.21% | Val Loss: 0.2464, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.2583, Acc: 49.11% | Val Loss: 0.2464, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2652, Acc: 47.32% | Val Loss: 0.2464, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2510, Acc: 53.57% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.2731, Acc: 45.54% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.2651, Acc: 51.79% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2612, Acc: 50.89% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2596, Acc: 49.11% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.2670, Acc: 48.21% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2668, Acc: 50.00% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.2638, Acc: 47.32% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.2618, Acc: 43.75% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2584, Acc: 50.00% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.2591, Acc: 50.00% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2652, Acc: 47.32% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2734, Acc: 42.86% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.2638, Acc: 50.00% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.2655, Acc: 49.11% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 230: Train Loss: 0.2649, Acc: 49.11% | Val Loss: 0.2462, Acc: 48.15%\n",
      "Epoch 240: Train Loss: 0.2759, Acc: 37.50% | Val Loss: 0.2462, Acc: 48.15%\n",
      "Epoch 250: Train Loss: 0.2689, Acc: 49.11% | Val Loss: 0.2462, Acc: 48.15%\n",
      "Epoch 260: Train Loss: 0.2645, Acc: 47.32% | Val Loss: 0.2462, Acc: 48.15%\n",
      "Epoch 270: Train Loss: 0.2787, Acc: 42.86% | Val Loss: 0.2462, Acc: 48.15%\n",
      "Epoch 280: Train Loss: 0.2675, Acc: 48.21% | Val Loss: 0.2462, Acc: 48.15%\n",
      "Early stopping at epoch 280\n",
      "Restoring model weights from epoch 250\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4815\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5037\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3678, Acc: 48.21% | Val Loss: 0.2648, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.3735, Acc: 46.43% | Val Loss: 0.2677, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.3690, Acc: 49.11% | Val Loss: 0.2726, Acc: 62.96%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4032, Acc: 50.00% | Val Loss: 0.3326, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.4489, Acc: 46.43% | Val Loss: 0.3248, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.4465, Acc: 43.75% | Val Loss: 0.3230, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.4209, Acc: 42.86% | Val Loss: 0.3256, Acc: 59.26%\n",
      "Early stopping at epoch 32\n",
      "Restoring model weights from epoch 12\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5926\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2939, Acc: 52.68% | Val Loss: 0.3066, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2714, Acc: 58.93% | Val Loss: 0.3266, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2838, Acc: 50.00% | Val Loss: 0.3181, Acc: 48.15%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3553, Acc: 51.79% | Val Loss: 0.2537, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.3096, Acc: 55.36% | Val Loss: 0.2796, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.3099, Acc: 50.89% | Val Loss: 0.2820, Acc: 62.96%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2951, Acc: 52.68% | Val Loss: 0.2697, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.3059, Acc: 50.00% | Val Loss: 0.2733, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.3025, Acc: 50.00% | Val Loss: 0.2696, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2877, Acc: 50.89% | Val Loss: 0.2673, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2862, Acc: 53.57% | Val Loss: 0.2664, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2989, Acc: 50.00% | Val Loss: 0.2689, Acc: 59.26%\n",
      "Early stopping at epoch 58\n",
      "Restoring model weights from epoch 38\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5852\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4214, Acc: 42.26% | Val Loss: 0.3468, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.4161, Acc: 42.56% | Val Loss: 0.3468, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.4203, Acc: 39.88% | Val Loss: 0.3467, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.4199, Acc: 41.96% | Val Loss: 0.3467, Acc: 44.44%\n",
      "Early stopping at epoch 39\n",
      "Restoring model weights from epoch 19\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4444\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4978, Acc: 41.67% | Val Loss: 0.4847, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.5107, Acc: 39.58% | Val Loss: 0.4846, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.5125, Acc: 41.67% | Val Loss: 0.4846, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.5079, Acc: 41.67% | Val Loss: 0.4846, Acc: 40.74%\n",
      "Early stopping at epoch 35\n",
      "Restoring model weights from epoch 15\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4074\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4942, Acc: 34.23% | Val Loss: 0.4461, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.4883, Acc: 34.82% | Val Loss: 0.4461, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.4848, Acc: 35.71% | Val Loss: 0.4461, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.4591, Acc: 36.01% | Val Loss: 0.4461, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.4794, Acc: 37.20% | Val Loss: 0.4460, Acc: 44.44%\n",
      "Epoch 50: Train Loss: 0.4901, Acc: 35.12% | Val Loss: 0.4460, Acc: 44.44%\n",
      "Early stopping at epoch 52\n",
      "Restoring model weights from epoch 32\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4444\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3536, Acc: 60.12% | Val Loss: 0.2031, Acc: 77.78%\n",
      "Epoch 10: Train Loss: 0.3592, Acc: 59.23% | Val Loss: 0.2031, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.3411, Acc: 63.39% | Val Loss: 0.2031, Acc: 77.78%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[4] <class 'src.activation_functions.Activation_ReLU'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.05, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3100, Acc: 66.37% | Val Loss: 0.3990, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.3048, Acc: 67.56% | Val Loss: 0.3990, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.3220, Acc: 63.99% | Val Loss: 0.3990, Acc: 51.85%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5185\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.01, 'l1': 0.001, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2457, Acc: 59.52% | Val Loss: 0.2491, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2175, Acc: 66.07% | Val Loss: 0.2675, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2074, Acc: 69.35% | Val Loss: 0.2612, Acc: 51.85%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.01, 'l1': 0.001, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2439, Acc: 58.33% | Val Loss: 0.2350, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.1930, Acc: 70.24% | Val Loss: 0.2009, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.1850, Acc: 73.21% | Val Loss: 0.1890, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.1756, Acc: 70.83% | Val Loss: 0.1816, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.1523, Acc: 78.57% | Val Loss: 0.1884, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.1447, Acc: 80.65% | Val Loss: 0.1891, Acc: 66.67%\n",
      "Early stopping at epoch 54\n",
      "Restoring model weights from epoch 34\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6667\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.01, 'l1': 0.001, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3302, Acc: 41.37% | Val Loss: 0.2982, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.2231, Acc: 68.45% | Val Loss: 0.2343, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2163, Acc: 68.75% | Val Loss: 0.2328, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2041, Acc: 72.02% | Val Loss: 0.2338, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2067, Acc: 72.02% | Val Loss: 0.2326, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.1995, Acc: 74.11% | Val Loss: 0.2335, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.1976, Acc: 76.49% | Val Loss: 0.2318, Acc: 62.96%\n",
      "Early stopping at epoch 61\n",
      "Restoring model weights from epoch 41\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6296\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.01, 'l1': 0.001, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2731, Acc: 61.01% | Val Loss: 0.1786, Acc: 74.07%\n",
      "Epoch 10: Train Loss: 0.2311, Acc: 60.12% | Val Loss: 0.1693, Acc: 77.78%\n",
      "Epoch 20: Train Loss: 0.2033, Acc: 60.12% | Val Loss: 0.1693, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.1790, Acc: 62.80% | Val Loss: 0.1490, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.1878, Acc: 59.23% | Val Loss: 0.1364, Acc: 74.07%\n",
      "Epoch 50: Train Loss: 0.1784, Acc: 66.07% | Val Loss: 0.1331, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.1640, Acc: 72.92% | Val Loss: 0.1319, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.1636, Acc: 70.83% | Val Loss: 0.1306, Acc: 74.07%\n",
      "Epoch 80: Train Loss: 0.1672, Acc: 70.83% | Val Loss: 0.1260, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.1836, Acc: 62.20% | Val Loss: 0.1269, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.1690, Acc: 68.15% | Val Loss: 0.1278, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.1750, Acc: 66.67% | Val Loss: 0.1255, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.1756, Acc: 64.58% | Val Loss: 0.1250, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.1783, Acc: 62.50% | Val Loss: 0.1242, Acc: 74.07%\n",
      "Early stopping at epoch 131\n",
      "Restoring model weights from epoch 111\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.01, 'l1': 0.001, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3003, Acc: 45.83% | Val Loss: 0.2512, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2109, Acc: 74.40% | Val Loss: 0.2309, Acc: 70.37%\n",
      "Epoch 20: Train Loss: 0.2075, Acc: 72.92% | Val Loss: 0.2229, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.1915, Acc: 74.70% | Val Loss: 0.2195, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.1701, Acc: 78.87% | Val Loss: 0.2145, Acc: 74.07%\n",
      "Epoch 50: Train Loss: 0.1702, Acc: 77.98% | Val Loss: 0.1845, Acc: 77.78%\n",
      "Epoch 60: Train Loss: 0.1537, Acc: 77.68% | Val Loss: 0.1576, Acc: 77.78%\n",
      "Epoch 70: Train Loss: 0.1401, Acc: 81.25% | Val Loss: 0.1456, Acc: 77.78%\n",
      "Epoch 80: Train Loss: 0.1627, Acc: 75.60% | Val Loss: 0.1375, Acc: 77.78%\n",
      "Epoch 90: Train Loss: 0.1510, Acc: 76.79% | Val Loss: 0.1313, Acc: 85.19%\n",
      "Epoch 100: Train Loss: 0.1454, Acc: 78.57% | Val Loss: 0.1242, Acc: 88.89%\n",
      "Epoch 110: Train Loss: 0.1519, Acc: 77.68% | Val Loss: 0.1237, Acc: 88.89%\n",
      "Epoch 120: Train Loss: 0.1448, Acc: 79.76% | Val Loss: 0.1232, Acc: 85.19%\n",
      "Early stopping at epoch 129\n",
      "Restoring model weights from epoch 109\n",
      "Final Validation Accuracy: 0.8519\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.8519\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6815\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2357, Acc: 60.42% | Val Loss: 0.2404, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2228, Acc: 65.48% | Val Loss: 0.2513, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2054, Acc: 66.96% | Val Loss: 0.2556, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2141, Acc: 66.67% | Val Loss: 0.2566, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2266, Acc: 66.67% | Val Loss: 0.2565, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2148, Acc: 66.07% | Val Loss: 0.2573, Acc: 51.85%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2787, Acc: 36.31% | Val Loss: 0.2617, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2467, Acc: 62.20% | Val Loss: 0.2466, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2420, Acc: 64.58% | Val Loss: 0.2440, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2399, Acc: 63.39% | Val Loss: 0.2418, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2375, Acc: 63.69% | Val Loss: 0.2400, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2356, Acc: 64.29% | Val Loss: 0.2388, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2376, Acc: 63.39% | Val Loss: 0.2379, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2353, Acc: 63.69% | Val Loss: 0.2372, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2360, Acc: 63.10% | Val Loss: 0.2367, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2338, Acc: 63.99% | Val Loss: 0.2363, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2452, Acc: 55.95% | Val Loss: 0.2503, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2362, Acc: 61.31% | Val Loss: 0.2433, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2317, Acc: 63.10% | Val Loss: 0.2411, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2312, Acc: 63.10% | Val Loss: 0.2376, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2273, Acc: 63.10% | Val Loss: 0.2353, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2293, Acc: 62.80% | Val Loss: 0.2339, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2280, Acc: 62.50% | Val Loss: 0.2327, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2268, Acc: 63.39% | Val Loss: 0.2318, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2285, Acc: 63.39% | Val Loss: 0.2308, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2237, Acc: 63.69% | Val Loss: 0.2298, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2519, Acc: 58.04% | Val Loss: 0.2339, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2442, Acc: 57.44% | Val Loss: 0.2174, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.2337, Acc: 58.93% | Val Loss: 0.2129, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.2411, Acc: 59.82% | Val Loss: 0.2108, Acc: 77.78%\n",
      "Epoch 40: Train Loss: 0.2329, Acc: 60.12% | Val Loss: 0.2106, Acc: 77.78%\n",
      "Epoch 50: Train Loss: 0.2348, Acc: 60.42% | Val Loss: 0.2101, Acc: 77.78%\n",
      "Epoch 60: Train Loss: 0.2357, Acc: 60.42% | Val Loss: 0.2096, Acc: 77.78%\n",
      "Epoch 70: Train Loss: 0.2368, Acc: 59.82% | Val Loss: 0.2086, Acc: 77.78%\n",
      "Epoch 80: Train Loss: 0.2367, Acc: 59.82% | Val Loss: 0.2083, Acc: 77.78%\n",
      "Epoch 90: Train Loss: 0.2349, Acc: 60.42% | Val Loss: 0.2081, Acc: 77.78%\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[6] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.2583, Acc: 39.58% | Val Loss: 0.2496, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2447, Acc: 65.77% | Val Loss: 0.2476, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2426, Acc: 64.58% | Val Loss: 0.2447, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2372, Acc: 64.58% | Val Loss: 0.2429, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2373, Acc: 64.58% | Val Loss: 0.2421, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2343, Acc: 65.18% | Val Loss: 0.2416, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2322, Acc: 65.18% | Val Loss: 0.2412, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2379, Acc: 64.58% | Val Loss: 0.2409, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2315, Acc: 65.18% | Val Loss: 0.2407, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2355, Acc: 64.58% | Val Loss: 0.2405, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6370\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2599, Acc: 53.57% | Val Loss: 0.2467, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2561, Acc: 59.82% | Val Loss: 0.2464, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2537, Acc: 59.82% | Val Loss: 0.2463, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2541, Acc: 58.93% | Val Loss: 0.2463, Acc: 48.15%\n",
      "Epoch 40: Train Loss: 0.2511, Acc: 60.71% | Val Loss: 0.2463, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2509, Acc: 60.71% | Val Loss: 0.2462, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2516, Acc: 58.93% | Val Loss: 0.2462, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2546, Acc: 58.93% | Val Loss: 0.2462, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2510, Acc: 60.71% | Val Loss: 0.2462, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2516, Acc: 58.93% | Val Loss: 0.2462, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5556\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3297, Acc: 39.29% | Val Loss: 0.2582, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.3231, Acc: 38.39% | Val Loss: 0.2572, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3190, Acc: 39.29% | Val Loss: 0.2568, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.3282, Acc: 36.61% | Val Loss: 0.2566, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.3333, Acc: 37.50% | Val Loss: 0.2564, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.3247, Acc: 37.50% | Val Loss: 0.2563, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.3267, Acc: 36.61% | Val Loss: 0.2562, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.3248, Acc: 37.50% | Val Loss: 0.2561, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.3258, Acc: 38.39% | Val Loss: 0.2560, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.3219, Acc: 38.39% | Val Loss: 0.2560, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5556\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3793, Acc: 56.25% | Val Loss: 0.3659, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.3801, Acc: 56.25% | Val Loss: 0.3650, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.3774, Acc: 56.25% | Val Loss: 0.3648, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.3699, Acc: 57.14% | Val Loss: 0.3646, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.3781, Acc: 56.25% | Val Loss: 0.3644, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.3779, Acc: 56.25% | Val Loss: 0.3643, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.3749, Acc: 56.25% | Val Loss: 0.3642, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.3863, Acc: 54.46% | Val Loss: 0.3642, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.3806, Acc: 54.46% | Val Loss: 0.3641, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.3762, Acc: 55.36% | Val Loss: 0.3640, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6296\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3009, Acc: 50.00% | Val Loss: 0.3271, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2951, Acc: 51.79% | Val Loss: 0.3228, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.3017, Acc: 50.89% | Val Loss: 0.3213, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2980, Acc: 50.00% | Val Loss: 0.3204, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2927, Acc: 51.79% | Val Loss: 0.3197, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.3004, Acc: 50.89% | Val Loss: 0.3192, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2953, Acc: 50.89% | Val Loss: 0.3187, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2926, Acc: 51.79% | Val Loss: 0.3184, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2955, Acc: 50.00% | Val Loss: 0.3181, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2907, Acc: 52.68% | Val Loss: 0.3178, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5556\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.5742, Acc: 35.71% | Val Loss: 0.4975, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.5817, Acc: 34.82% | Val Loss: 0.4945, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.5716, Acc: 35.71% | Val Loss: 0.4934, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.5601, Acc: 36.61% | Val Loss: 0.4927, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.5822, Acc: 34.82% | Val Loss: 0.4922, Acc: 44.44%\n",
      "Epoch 50: Train Loss: 0.5693, Acc: 35.71% | Val Loss: 0.4918, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.5705, Acc: 35.71% | Val Loss: 0.4914, Acc: 44.44%\n",
      "Epoch 70: Train Loss: 0.5588, Acc: 37.50% | Val Loss: 0.4912, Acc: 44.44%\n",
      "Epoch 80: Train Loss: 0.5729, Acc: 35.71% | Val Loss: 0.4909, Acc: 44.44%\n",
      "Epoch 90: Train Loss: 0.5694, Acc: 35.71% | Val Loss: 0.4907, Acc: 44.44%\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4444\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5481\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3517, Acc: 49.11% | Val Loss: 0.4183, Acc: 44.44%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4444\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3247, Acc: 55.95% | Val Loss: 0.4663, Acc: 33.33%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3333\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3056, Acc: 56.25% | Val Loss: 0.2015, Acc: 70.37%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7037\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.7037\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3425, Acc: 52.68% | Val Loss: 0.3110, Acc: 59.26%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5926\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4258, Acc: 43.45% | Val Loss: 0.5285, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4963\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.4498, Acc: 39.06% | Val Loss: 0.4113, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.4962, Acc: 38.28% | Val Loss: 0.4110, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.4522, Acc: 42.45% | Val Loss: 0.4107, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.4957, Acc: 36.72% | Val Loss: 0.4104, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.4924, Acc: 33.07% | Val Loss: 0.4101, Acc: 44.44%\n",
      "Epoch 50: Train Loss: 0.4578, Acc: 41.93% | Val Loss: 0.4098, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.4954, Acc: 36.98% | Val Loss: 0.4095, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.4608, Acc: 43.75% | Val Loss: 0.4092, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.4881, Acc: 36.46% | Val Loss: 0.4089, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.4637, Acc: 40.10% | Val Loss: 0.4086, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.4661, Acc: 38.80% | Val Loss: 0.4083, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.4641, Acc: 38.28% | Val Loss: 0.4080, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.4543, Acc: 39.84% | Val Loss: 0.4077, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.4521, Acc: 43.75% | Val Loss: 0.4074, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.4578, Acc: 39.32% | Val Loss: 0.4072, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.4464, Acc: 43.75% | Val Loss: 0.4069, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.4930, Acc: 35.94% | Val Loss: 0.4066, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.4882, Acc: 37.76% | Val Loss: 0.4064, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.4641, Acc: 33.85% | Val Loss: 0.4061, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.4354, Acc: 43.49% | Val Loss: 0.4059, Acc: 48.15%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.4656, Acc: 36.46% | Val Loss: 0.4326, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.4506, Acc: 39.06% | Val Loss: 0.4312, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.4325, Acc: 44.53% | Val Loss: 0.4299, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.4579, Acc: 40.36% | Val Loss: 0.4286, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.4563, Acc: 38.54% | Val Loss: 0.4273, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.4309, Acc: 39.84% | Val Loss: 0.4261, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.4252, Acc: 44.79% | Val Loss: 0.4249, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.4318, Acc: 41.41% | Val Loss: 0.4236, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.4711, Acc: 36.72% | Val Loss: 0.4223, Acc: 40.74%\n",
      "Epoch 90: Train Loss: 0.4444, Acc: 36.46% | Val Loss: 0.4210, Acc: 40.74%\n",
      "Epoch 100: Train Loss: 0.4623, Acc: 34.90% | Val Loss: 0.4197, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.4289, Acc: 42.19% | Val Loss: 0.4184, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.4564, Acc: 37.24% | Val Loss: 0.4171, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.4192, Acc: 45.05% | Val Loss: 0.4158, Acc: 40.74%\n",
      "Epoch 140: Train Loss: 0.4501, Acc: 35.42% | Val Loss: 0.4146, Acc: 40.74%\n",
      "Epoch 150: Train Loss: 0.4480, Acc: 38.02% | Val Loss: 0.4133, Acc: 40.74%\n",
      "Epoch 160: Train Loss: 0.4204, Acc: 40.62% | Val Loss: 0.4120, Acc: 40.74%\n",
      "Epoch 170: Train Loss: 0.4366, Acc: 40.36% | Val Loss: 0.4107, Acc: 40.74%\n",
      "Epoch 180: Train Loss: 0.4148, Acc: 40.10% | Val Loss: 0.4094, Acc: 40.74%\n",
      "Epoch 190: Train Loss: 0.4586, Acc: 38.54% | Val Loss: 0.4082, Acc: 40.74%\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4074\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.4867, Acc: 37.50% | Val Loss: 0.4764, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.4825, Acc: 33.07% | Val Loss: 0.4747, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.4969, Acc: 35.94% | Val Loss: 0.4733, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.4735, Acc: 41.67% | Val Loss: 0.4717, Acc: 37.04%\n",
      "Epoch 40: Train Loss: 0.4817, Acc: 38.54% | Val Loss: 0.4702, Acc: 37.04%\n",
      "Epoch 50: Train Loss: 0.5073, Acc: 35.42% | Val Loss: 0.4686, Acc: 33.33%\n",
      "Epoch 60: Train Loss: 0.4722, Acc: 38.28% | Val Loss: 0.4671, Acc: 33.33%\n",
      "Epoch 70: Train Loss: 0.4392, Acc: 39.32% | Val Loss: 0.4656, Acc: 33.33%\n",
      "Epoch 80: Train Loss: 0.4668, Acc: 40.62% | Val Loss: 0.4639, Acc: 33.33%\n",
      "Epoch 90: Train Loss: 0.4234, Acc: 45.31% | Val Loss: 0.4623, Acc: 33.33%\n",
      "Epoch 100: Train Loss: 0.4488, Acc: 40.89% | Val Loss: 0.4607, Acc: 33.33%\n",
      "Epoch 110: Train Loss: 0.4583, Acc: 41.67% | Val Loss: 0.4592, Acc: 33.33%\n",
      "Epoch 120: Train Loss: 0.4447, Acc: 41.67% | Val Loss: 0.4577, Acc: 33.33%\n",
      "Epoch 130: Train Loss: 0.4789, Acc: 35.16% | Val Loss: 0.4560, Acc: 33.33%\n",
      "Epoch 140: Train Loss: 0.4797, Acc: 36.72% | Val Loss: 0.4544, Acc: 33.33%\n",
      "Epoch 150: Train Loss: 0.4632, Acc: 35.16% | Val Loss: 0.4528, Acc: 33.33%\n",
      "Epoch 160: Train Loss: 0.4897, Acc: 33.85% | Val Loss: 0.4511, Acc: 33.33%\n",
      "Epoch 170: Train Loss: 0.4775, Acc: 35.68% | Val Loss: 0.4495, Acc: 33.33%\n",
      "Epoch 180: Train Loss: 0.4589, Acc: 35.42% | Val Loss: 0.4480, Acc: 33.33%\n",
      "Epoch 190: Train Loss: 0.4391, Acc: 40.36% | Val Loss: 0.4463, Acc: 33.33%\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.3333\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3417, Acc: 37.50% | Val Loss: 0.4384, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.3354, Acc: 43.49% | Val Loss: 0.4372, Acc: 33.33%\n",
      "Epoch 20: Train Loss: 0.3385, Acc: 40.10% | Val Loss: 0.4360, Acc: 33.33%\n",
      "Epoch 30: Train Loss: 0.3475, Acc: 41.15% | Val Loss: 0.4348, Acc: 33.33%\n",
      "Epoch 40: Train Loss: 0.3261, Acc: 46.88% | Val Loss: 0.4337, Acc: 33.33%\n",
      "Epoch 50: Train Loss: 0.3220, Acc: 44.27% | Val Loss: 0.4325, Acc: 33.33%\n",
      "Epoch 60: Train Loss: 0.3373, Acc: 40.62% | Val Loss: 0.4314, Acc: 33.33%\n",
      "Epoch 70: Train Loss: 0.3401, Acc: 44.79% | Val Loss: 0.4302, Acc: 33.33%\n",
      "Epoch 80: Train Loss: 0.3395, Acc: 41.67% | Val Loss: 0.4290, Acc: 33.33%\n",
      "Epoch 90: Train Loss: 0.3347, Acc: 41.41% | Val Loss: 0.4277, Acc: 33.33%\n",
      "Epoch 100: Train Loss: 0.3194, Acc: 46.09% | Val Loss: 0.4266, Acc: 33.33%\n",
      "Epoch 110: Train Loss: 0.3183, Acc: 45.05% | Val Loss: 0.4255, Acc: 33.33%\n",
      "Epoch 120: Train Loss: 0.3331, Acc: 41.67% | Val Loss: 0.4244, Acc: 33.33%\n",
      "Epoch 130: Train Loss: 0.3468, Acc: 42.19% | Val Loss: 0.4233, Acc: 33.33%\n",
      "Epoch 140: Train Loss: 0.3546, Acc: 41.15% | Val Loss: 0.4222, Acc: 33.33%\n",
      "Epoch 150: Train Loss: 0.3542, Acc: 43.23% | Val Loss: 0.4211, Acc: 33.33%\n",
      "Epoch 160: Train Loss: 0.3426, Acc: 40.10% | Val Loss: 0.4200, Acc: 33.33%\n",
      "Epoch 170: Train Loss: 0.3351, Acc: 42.97% | Val Loss: 0.4190, Acc: 33.33%\n",
      "Epoch 180: Train Loss: 0.3253, Acc: 46.88% | Val Loss: 0.4178, Acc: 33.33%\n",
      "Epoch 190: Train Loss: 0.2973, Acc: 52.60% | Val Loss: 0.4166, Acc: 33.33%\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.3333\n",
      "[8] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-05, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 200, 'weight_decay': 1e-05, 'patience': 20, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3117, Acc: 40.62% | Val Loss: 0.1870, Acc: 74.07%\n",
      "Epoch 10: Train Loss: 0.2911, Acc: 51.30% | Val Loss: 0.1867, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.3129, Acc: 47.40% | Val Loss: 0.1865, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.3063, Acc: 48.44% | Val Loss: 0.1863, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.2857, Acc: 49.48% | Val Loss: 0.1860, Acc: 74.07%\n",
      "Epoch 50: Train Loss: 0.2938, Acc: 51.56% | Val Loss: 0.1858, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.2845, Acc: 55.21% | Val Loss: 0.1856, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.3048, Acc: 47.40% | Val Loss: 0.1854, Acc: 74.07%\n",
      "Epoch 80: Train Loss: 0.2912, Acc: 52.86% | Val Loss: 0.1852, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.2882, Acc: 49.22% | Val Loss: 0.1850, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.3086, Acc: 53.12% | Val Loss: 0.1848, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.2808, Acc: 51.30% | Val Loss: 0.1846, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.2919, Acc: 54.43% | Val Loss: 0.1844, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.2839, Acc: 53.91% | Val Loss: 0.1842, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.3120, Acc: 50.26% | Val Loss: 0.1841, Acc: 74.07%\n",
      "Epoch 150: Train Loss: 0.2851, Acc: 54.43% | Val Loss: 0.1839, Acc: 74.07%\n",
      "Epoch 160: Train Loss: 0.2991, Acc: 46.35% | Val Loss: 0.1837, Acc: 74.07%\n",
      "Epoch 170: Train Loss: 0.3002, Acc: 53.65% | Val Loss: 0.1835, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.2926, Acc: 54.69% | Val Loss: 0.1833, Acc: 74.07%\n",
      "Epoch 190: Train Loss: 0.2870, Acc: 50.26% | Val Loss: 0.1831, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.7407\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4593\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3854, Acc: 32.14% | Val Loss: 0.3052, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4815\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2514, Acc: 64.29% | Val Loss: 0.2598, Acc: 62.96%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2478, Acc: 51.79% | Val Loss: 0.2614, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5185\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4221, Acc: 41.07% | Val Loss: 0.5202, Acc: 22.22%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2222\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2222\n",
      "[4] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [4], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3058, Acc: 50.00% | Val Loss: 0.3302, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4519\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2508, Acc: 48.44% | Val Loss: 0.2491, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2468, Acc: 55.73% | Val Loss: 0.2468, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2471, Acc: 58.07% | Val Loss: 0.2467, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2470, Acc: 57.29% | Val Loss: 0.2465, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2451, Acc: 56.51% | Val Loss: 0.2464, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2468, Acc: 56.77% | Val Loss: 0.2464, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2472, Acc: 56.25% | Val Loss: 0.2462, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2472, Acc: 55.73% | Val Loss: 0.2462, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2484, Acc: 52.60% | Val Loss: 0.2460, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2467, Acc: 57.55% | Val Loss: 0.2460, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6667\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2349, Acc: 62.50% | Val Loss: 0.2514, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2328, Acc: 61.46% | Val Loss: 0.2430, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2302, Acc: 63.80% | Val Loss: 0.2425, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2426, Acc: 56.77% | Val Loss: 0.2429, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2428, Acc: 59.11% | Val Loss: 0.2418, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2386, Acc: 57.29% | Val Loss: 0.2428, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2199, Acc: 67.97% | Val Loss: 0.2417, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2331, Acc: 61.46% | Val Loss: 0.2413, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2322, Acc: 66.15% | Val Loss: 0.2413, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2356, Acc: 63.02% | Val Loss: 0.2413, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6667\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2352, Acc: 61.98% | Val Loss: 0.2302, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2310, Acc: 67.19% | Val Loss: 0.2307, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2385, Acc: 59.11% | Val Loss: 0.2301, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2312, Acc: 64.84% | Val Loss: 0.2301, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2314, Acc: 63.28% | Val Loss: 0.2301, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2301, Acc: 61.46% | Val Loss: 0.2297, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2304, Acc: 63.28% | Val Loss: 0.2294, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2343, Acc: 60.68% | Val Loss: 0.2296, Acc: 66.67%\n",
      "Epoch 80: Train Loss: 0.2243, Acc: 68.49% | Val Loss: 0.2289, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2361, Acc: 59.64% | Val Loss: 0.2290, Acc: 66.67%\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2948, Acc: 38.02% | Val Loss: 0.3619, Acc: 22.22%\n",
      "Epoch 10: Train Loss: 0.2855, Acc: 45.05% | Val Loss: 0.3451, Acc: 29.63%\n",
      "Epoch 20: Train Loss: 0.2762, Acc: 52.34% | Val Loss: 0.3383, Acc: 29.63%\n",
      "Epoch 30: Train Loss: 0.2920, Acc: 37.76% | Val Loss: 0.3382, Acc: 29.63%\n",
      "Epoch 40: Train Loss: 0.2772, Acc: 47.92% | Val Loss: 0.3368, Acc: 29.63%\n",
      "Epoch 50: Train Loss: 0.2806, Acc: 42.45% | Val Loss: 0.3351, Acc: 29.63%\n",
      "Epoch 60: Train Loss: 0.2935, Acc: 38.54% | Val Loss: 0.3323, Acc: 29.63%\n",
      "Epoch 70: Train Loss: 0.2941, Acc: 41.15% | Val Loss: 0.3326, Acc: 29.63%\n",
      "Epoch 80: Train Loss: 0.2941, Acc: 38.28% | Val Loss: 0.3308, Acc: 29.63%\n",
      "Epoch 90: Train Loss: 0.2775, Acc: 46.88% | Val Loss: 0.3278, Acc: 29.63%\n",
      "Final Validation Accuracy: 0.2963\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2963\n",
      "[3] <class 'src.activation_functions.Activation_Sigmoid'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 1e-05, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.4849, Acc: 33.59% | Val Loss: 0.4222, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.4761, Acc: 33.59% | Val Loss: 0.3932, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.4711, Acc: 33.59% | Val Loss: 0.3915, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.4566, Acc: 34.90% | Val Loss: 0.3895, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.4547, Acc: 34.90% | Val Loss: 0.3889, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.4780, Acc: 33.59% | Val Loss: 0.3884, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.4423, Acc: 36.20% | Val Loss: 0.3859, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.4638, Acc: 33.59% | Val Loss: 0.3862, Acc: 40.74%\n",
      "Early stopping at epoch 74\n",
      "Restoring model weights from epoch 44\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5407\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.01, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2540, Acc: 60.71% | Val Loss: 0.2917, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.2317, Acc: 66.07% | Val Loss: 0.2955, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2172, Acc: 67.86% | Val Loss: 0.2924, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2132, Acc: 69.64% | Val Loss: 0.2831, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2159, Acc: 70.54% | Val Loss: 0.2839, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.1962, Acc: 70.54% | Val Loss: 0.2708, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.1913, Acc: 71.43% | Val Loss: 0.2686, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.1890, Acc: 74.11% | Val Loss: 0.2634, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.1866, Acc: 72.32% | Val Loss: 0.2613, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.1888, Acc: 75.00% | Val Loss: 0.2599, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.1936, Acc: 72.32% | Val Loss: 0.2575, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.1800, Acc: 76.79% | Val Loss: 0.2578, Acc: 51.85%\n",
      "Epoch 120: Train Loss: 0.1815, Acc: 75.89% | Val Loss: 0.2511, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.1737, Acc: 75.89% | Val Loss: 0.2419, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.1776, Acc: 75.00% | Val Loss: 0.2388, Acc: 59.26%\n",
      "Epoch 150: Train Loss: 0.1709, Acc: 75.00% | Val Loss: 0.2340, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.1706, Acc: 69.64% | Val Loss: 0.2326, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.1750, Acc: 77.68% | Val Loss: 0.2255, Acc: 62.96%\n",
      "Epoch 180: Train Loss: 0.1584, Acc: 76.79% | Val Loss: 0.2206, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.1716, Acc: 71.43% | Val Loss: 0.2199, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.1716, Acc: 73.21% | Val Loss: 0.2165, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.1734, Acc: 73.21% | Val Loss: 0.2080, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.1484, Acc: 81.25% | Val Loss: 0.2097, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.1573, Acc: 81.25% | Val Loss: 0.2134, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.1604, Acc: 77.68% | Val Loss: 0.2138, Acc: 62.96%\n",
      "Epoch 250: Train Loss: 0.1705, Acc: 74.11% | Val Loss: 0.2111, Acc: 59.26%\n",
      "Early stopping at epoch 255\n",
      "Restoring model weights from epoch 225\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5926\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.01, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3278, Acc: 50.89% | Val Loss: 0.3370, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2318, Acc: 64.29% | Val Loss: 0.2713, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2268, Acc: 62.50% | Val Loss: 0.2525, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.1935, Acc: 68.75% | Val Loss: 0.2333, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.1955, Acc: 67.86% | Val Loss: 0.2236, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.1601, Acc: 83.04% | Val Loss: 0.2192, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.1743, Acc: 76.79% | Val Loss: 0.2146, Acc: 70.37%\n",
      "Epoch 70: Train Loss: 0.1611, Acc: 77.68% | Val Loss: 0.2123, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.1638, Acc: 78.57% | Val Loss: 0.2175, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.1537, Acc: 82.14% | Val Loss: 0.2148, Acc: 70.37%\n",
      "Epoch 100: Train Loss: 0.1676, Acc: 77.68% | Val Loss: 0.2055, Acc: 70.37%\n",
      "Epoch 110: Train Loss: 0.1498, Acc: 81.25% | Val Loss: 0.2057, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.1530, Acc: 76.79% | Val Loss: 0.2021, Acc: 70.37%\n",
      "Epoch 130: Train Loss: 0.1705, Acc: 76.79% | Val Loss: 0.1987, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.1831, Acc: 75.89% | Val Loss: 0.2032, Acc: 74.07%\n",
      "Epoch 150: Train Loss: 0.1641, Acc: 82.14% | Val Loss: 0.2017, Acc: 70.37%\n",
      "Epoch 160: Train Loss: 0.1630, Acc: 78.57% | Val Loss: 0.2011, Acc: 70.37%\n",
      "Early stopping at epoch 169\n",
      "Restoring model weights from epoch 139\n",
      "Final Validation Accuracy: 0.7037\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.7037\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.01, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2573, Acc: 62.50% | Val Loss: 0.2372, Acc: 70.37%\n",
      "Epoch 10: Train Loss: 0.2442, Acc: 57.14% | Val Loss: 0.2284, Acc: 70.37%\n",
      "Epoch 20: Train Loss: 0.2315, Acc: 65.18% | Val Loss: 0.2361, Acc: 70.37%\n",
      "Epoch 30: Train Loss: 0.2258, Acc: 63.39% | Val Loss: 0.2399, Acc: 66.67%\n",
      "Early stopping at epoch 37\n",
      "Restoring model weights from epoch 7\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.01, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3510, Acc: 46.43% | Val Loss: 0.3189, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.2618, Acc: 60.71% | Val Loss: 0.2896, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2490, Acc: 60.71% | Val Loss: 0.2466, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2085, Acc: 68.75% | Val Loss: 0.2253, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2085, Acc: 66.96% | Val Loss: 0.2048, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2111, Acc: 63.39% | Val Loss: 0.1845, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.1880, Acc: 73.21% | Val Loss: 0.1823, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.1934, Acc: 70.54% | Val Loss: 0.1821, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2019, Acc: 66.96% | Val Loss: 0.1816, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.1932, Acc: 73.21% | Val Loss: 0.1686, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.1962, Acc: 70.54% | Val Loss: 0.1781, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.1886, Acc: 74.11% | Val Loss: 0.1751, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.1772, Acc: 75.89% | Val Loss: 0.1709, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.1886, Acc: 73.21% | Val Loss: 0.1609, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.1902, Acc: 74.11% | Val Loss: 0.1610, Acc: 77.78%\n",
      "Epoch 150: Train Loss: 0.1826, Acc: 73.21% | Val Loss: 0.1587, Acc: 77.78%\n",
      "Epoch 160: Train Loss: 0.1991, Acc: 70.54% | Val Loss: 0.1595, Acc: 77.78%\n",
      "Epoch 170: Train Loss: 0.1913, Acc: 71.43% | Val Loss: 0.1606, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.1893, Acc: 67.86% | Val Loss: 0.1564, Acc: 77.78%\n",
      "Early stopping at epoch 187\n",
      "Restoring model weights from epoch 157\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[5] <class 'src.activation_functions.Activation_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.01, 'l1': 0.01, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 300, 'weight_decay': 0.05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2676, Acc: 58.93% | Val Loss: 0.2481, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2621, Acc: 61.61% | Val Loss: 0.2416, Acc: 66.67%\n",
      "Epoch 20: Train Loss: 0.2290, Acc: 65.18% | Val Loss: 0.2359, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2240, Acc: 61.61% | Val Loss: 0.2247, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2253, Acc: 65.18% | Val Loss: 0.2066, Acc: 70.37%\n",
      "Epoch 50: Train Loss: 0.2008, Acc: 66.96% | Val Loss: 0.1996, Acc: 70.37%\n",
      "Epoch 60: Train Loss: 0.1884, Acc: 73.21% | Val Loss: 0.1910, Acc: 70.37%\n",
      "Epoch 70: Train Loss: 0.1817, Acc: 70.54% | Val Loss: 0.1853, Acc: 74.07%\n",
      "Epoch 80: Train Loss: 0.1985, Acc: 69.64% | Val Loss: 0.1812, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.1818, Acc: 73.21% | Val Loss: 0.1738, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.1799, Acc: 73.21% | Val Loss: 0.1784, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.1644, Acc: 80.36% | Val Loss: 0.1765, Acc: 77.78%\n",
      "Epoch 120: Train Loss: 0.1767, Acc: 75.89% | Val Loss: 0.1745, Acc: 77.78%\n",
      "Epoch 130: Train Loss: 0.1920, Acc: 72.32% | Val Loss: 0.1730, Acc: 81.48%\n",
      "Epoch 140: Train Loss: 0.1784, Acc: 71.43% | Val Loss: 0.1708, Acc: 81.48%\n",
      "Epoch 150: Train Loss: 0.1720, Acc: 79.46% | Val Loss: 0.1717, Acc: 77.78%\n",
      "Epoch 160: Train Loss: 0.1735, Acc: 75.89% | Val Loss: 0.1690, Acc: 81.48%\n",
      "Epoch 170: Train Loss: 0.1706, Acc: 77.68% | Val Loss: 0.1672, Acc: 81.48%\n",
      "Epoch 180: Train Loss: 0.1676, Acc: 75.00% | Val Loss: 0.1681, Acc: 85.19%\n",
      "Epoch 190: Train Loss: 0.1713, Acc: 76.79% | Val Loss: 0.1678, Acc: 85.19%\n",
      "Epoch 200: Train Loss: 0.1752, Acc: 74.11% | Val Loss: 0.1723, Acc: 85.19%\n",
      "Early stopping at epoch 203\n",
      "Restoring model weights from epoch 173\n",
      "Final Validation Accuracy: 0.8148\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.8148\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.7037\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2472, Acc: 55.47% | Val Loss: 0.2930, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.2222, Acc: 69.27% | Val Loss: 0.2939, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2341, Acc: 68.49% | Val Loss: 0.2945, Acc: 51.85%\n",
      "Early stopping at epoch 21\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3029, Acc: 52.86% | Val Loss: 0.2356, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2959, Acc: 51.04% | Val Loss: 0.2299, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.3111, Acc: 52.60% | Val Loss: 0.2268, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.3091, Acc: 48.70% | Val Loss: 0.2247, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2750, Acc: 55.21% | Val Loss: 0.2233, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2814, Acc: 58.07% | Val Loss: 0.2224, Acc: 70.37%\n",
      "Epoch 60: Train Loss: 0.2757, Acc: 55.47% | Val Loss: 0.2214, Acc: 70.37%\n",
      "Epoch 70: Train Loss: 0.2571, Acc: 58.07% | Val Loss: 0.2207, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2787, Acc: 56.25% | Val Loss: 0.2205, Acc: 70.37%\n",
      "Epoch 90: Train Loss: 0.2628, Acc: 57.55% | Val Loss: 0.2202, Acc: 70.37%\n",
      "Epoch 100: Train Loss: 0.2635, Acc: 58.33% | Val Loss: 0.2198, Acc: 70.37%\n",
      "Epoch 110: Train Loss: 0.2659, Acc: 57.81% | Val Loss: 0.2197, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2550, Acc: 58.33% | Val Loss: 0.2198, Acc: 62.96%\n",
      "Early stopping at epoch 128\n",
      "Restoring model weights from epoch 108\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2591, Acc: 48.96% | Val Loss: 0.2323, Acc: 62.96%\n",
      "Epoch 10: Train Loss: 0.2324, Acc: 56.51% | Val Loss: 0.2277, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2326, Acc: 57.55% | Val Loss: 0.2275, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2277, Acc: 55.47% | Val Loss: 0.2280, Acc: 55.56%\n",
      "Early stopping at epoch 35\n",
      "Restoring model weights from epoch 15\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5556\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3141, Acc: 41.93% | Val Loss: 0.3443, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2839, Acc: 42.19% | Val Loss: 0.2790, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.2724, Acc: 49.48% | Val Loss: 0.2518, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2583, Acc: 53.39% | Val Loss: 0.2384, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2597, Acc: 49.48% | Val Loss: 0.2277, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2536, Acc: 52.08% | Val Loss: 0.2215, Acc: 62.96%\n",
      "Epoch 60: Train Loss: 0.2409, Acc: 56.77% | Val Loss: 0.2171, Acc: 70.37%\n",
      "Epoch 70: Train Loss: 0.2424, Acc: 52.86% | Val Loss: 0.2141, Acc: 70.37%\n",
      "Epoch 80: Train Loss: 0.2420, Acc: 55.73% | Val Loss: 0.2125, Acc: 70.37%\n",
      "Epoch 90: Train Loss: 0.2536, Acc: 51.82% | Val Loss: 0.2105, Acc: 70.37%\n",
      "Epoch 100: Train Loss: 0.2473, Acc: 53.39% | Val Loss: 0.2095, Acc: 70.37%\n",
      "Epoch 110: Train Loss: 0.2478, Acc: 57.03% | Val Loss: 0.2083, Acc: 70.37%\n",
      "Epoch 120: Train Loss: 0.2423, Acc: 58.33% | Val Loss: 0.2076, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.2454, Acc: 55.73% | Val Loss: 0.2073, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.2383, Acc: 60.42% | Val Loss: 0.2064, Acc: 74.07%\n",
      "Epoch 150: Train Loss: 0.2347, Acc: 61.20% | Val Loss: 0.2051, Acc: 74.07%\n",
      "Epoch 160: Train Loss: 0.2403, Acc: 59.90% | Val Loss: 0.2045, Acc: 74.07%\n",
      "Epoch 170: Train Loss: 0.2375, Acc: 59.90% | Val Loss: 0.2043, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.2351, Acc: 63.28% | Val Loss: 0.2034, Acc: 74.07%\n",
      "Epoch 190: Train Loss: 0.2392, Acc: 61.98% | Val Loss: 0.2025, Acc: 74.07%\n",
      "Epoch 200: Train Loss: 0.2299, Acc: 64.58% | Val Loss: 0.2023, Acc: 74.07%\n",
      "Epoch 210: Train Loss: 0.2248, Acc: 64.58% | Val Loss: 0.2017, Acc: 74.07%\n",
      "Epoch 220: Train Loss: 0.2315, Acc: 63.28% | Val Loss: 0.2013, Acc: 74.07%\n",
      "Epoch 230: Train Loss: 0.2403, Acc: 60.68% | Val Loss: 0.2005, Acc: 74.07%\n",
      "Epoch 240: Train Loss: 0.2247, Acc: 66.67% | Val Loss: 0.2002, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.001, 'dropout_rate': 0.0, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 20, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2559, Acc: 56.51% | Val Loss: 0.2827, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2435, Acc: 60.42% | Val Loss: 0.2707, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2362, Acc: 62.24% | Val Loss: 0.2660, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2233, Acc: 64.06% | Val Loss: 0.2636, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2282, Acc: 63.54% | Val Loss: 0.2624, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2262, Acc: 62.24% | Val Loss: 0.2616, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2362, Acc: 59.64% | Val Loss: 0.2611, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2276, Acc: 65.89% | Val Loss: 0.2607, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2214, Acc: 65.10% | Val Loss: 0.2604, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2346, Acc: 63.28% | Val Loss: 0.2600, Acc: 62.96%\n",
      "Epoch 100: Train Loss: 0.2233, Acc: 66.67% | Val Loss: 0.2598, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.2254, Acc: 64.58% | Val Loss: 0.2595, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.2148, Acc: 65.89% | Val Loss: 0.2594, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.2296, Acc: 65.89% | Val Loss: 0.2593, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2223, Acc: 65.89% | Val Loss: 0.2590, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2173, Acc: 66.41% | Val Loss: 0.2588, Acc: 62.96%\n",
      "Epoch 160: Train Loss: 0.2161, Acc: 66.41% | Val Loss: 0.2585, Acc: 62.96%\n",
      "Epoch 170: Train Loss: 0.2093, Acc: 69.01% | Val Loss: 0.2585, Acc: 62.96%\n",
      "Epoch 180: Train Loss: 0.2248, Acc: 65.10% | Val Loss: 0.2584, Acc: 62.96%\n",
      "Epoch 190: Train Loss: 0.2124, Acc: 66.41% | Val Loss: 0.2583, Acc: 62.96%\n",
      "Epoch 200: Train Loss: 0.2217, Acc: 63.80% | Val Loss: 0.2582, Acc: 62.96%\n",
      "Epoch 210: Train Loss: 0.2152, Acc: 65.62% | Val Loss: 0.2580, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.2130, Acc: 65.62% | Val Loss: 0.2579, Acc: 62.96%\n",
      "Epoch 230: Train Loss: 0.2093, Acc: 66.93% | Val Loss: 0.2578, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.2080, Acc: 68.23% | Val Loss: 0.2577, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6296\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6148\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3108, Acc: 66.96% | Val Loss: 0.4463, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3173, Acc: 38.39% | Val Loss: 0.3060, Acc: 33.33%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3333\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2645, Acc: 62.50% | Val Loss: 0.2469, Acc: 66.67%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6667\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2389, Acc: 60.71% | Val Loss: 0.1890, Acc: 77.78%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[6] <class 'src.activation_functions.Activation_Sigmoid'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.5457, Acc: 34.82% | Val Loss: 0.4989, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5407\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3367, Acc: 54.46% | Val Loss: 0.2542, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2803, Acc: 63.39% | Val Loss: 0.2695, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2432, Acc: 63.39% | Val Loss: 0.2560, Acc: 62.96%\n",
      "Epoch 30: Train Loss: 0.2327, Acc: 65.18% | Val Loss: 0.2493, Acc: 66.67%\n",
      "Epoch 40: Train Loss: 0.2406, Acc: 66.07% | Val Loss: 0.2503, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2015, Acc: 68.75% | Val Loss: 0.2614, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2048, Acc: 71.43% | Val Loss: 0.2696, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.1838, Acc: 74.11% | Val Loss: 0.2722, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.1879, Acc: 71.43% | Val Loss: 0.2754, Acc: 55.56%\n",
      "Early stopping at epoch 88\n",
      "Restoring model weights from epoch 38\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5556\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3195, Acc: 49.11% | Val Loss: 0.2839, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2675, Acc: 56.25% | Val Loss: 0.2533, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2351, Acc: 65.18% | Val Loss: 0.2609, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.2223, Acc: 67.86% | Val Loss: 0.2654, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2165, Acc: 68.75% | Val Loss: 0.2697, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.1930, Acc: 71.43% | Val Loss: 0.2738, Acc: 48.15%\n",
      "Early stopping at epoch 56\n",
      "Restoring model weights from epoch 6\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3183, Acc: 57.14% | Val Loss: 0.2920, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2855, Acc: 59.82% | Val Loss: 0.2748, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2596, Acc: 62.50% | Val Loss: 0.2720, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2431, Acc: 64.29% | Val Loss: 0.2730, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2207, Acc: 65.18% | Val Loss: 0.2734, Acc: 62.96%\n",
      "Epoch 50: Train Loss: 0.2216, Acc: 64.29% | Val Loss: 0.2737, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2183, Acc: 67.86% | Val Loss: 0.2714, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.1956, Acc: 68.75% | Val Loss: 0.2690, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.1961, Acc: 65.18% | Val Loss: 0.2646, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.1901, Acc: 69.64% | Val Loss: 0.2645, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.1783, Acc: 73.21% | Val Loss: 0.2615, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2006, Acc: 68.75% | Val Loss: 0.2572, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.1707, Acc: 77.68% | Val Loss: 0.2527, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.1808, Acc: 72.32% | Val Loss: 0.2466, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.1819, Acc: 75.89% | Val Loss: 0.2425, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5926\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3060, Acc: 50.89% | Val Loss: 0.2448, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2853, Acc: 54.46% | Val Loss: 0.2167, Acc: 62.96%\n",
      "Epoch 20: Train Loss: 0.2547, Acc: 61.61% | Val Loss: 0.2009, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2279, Acc: 63.39% | Val Loss: 0.1946, Acc: 77.78%\n",
      "Epoch 40: Train Loss: 0.2347, Acc: 63.39% | Val Loss: 0.1909, Acc: 70.37%\n",
      "Epoch 50: Train Loss: 0.2114, Acc: 71.43% | Val Loss: 0.1911, Acc: 70.37%\n",
      "Epoch 60: Train Loss: 0.2178, Acc: 64.29% | Val Loss: 0.1935, Acc: 70.37%\n",
      "Epoch 70: Train Loss: 0.2141, Acc: 64.29% | Val Loss: 0.1914, Acc: 77.78%\n",
      "Epoch 80: Train Loss: 0.2216, Acc: 67.86% | Val Loss: 0.1963, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2131, Acc: 68.75% | Val Loss: 0.1959, Acc: 66.67%\n",
      "Epoch 100: Train Loss: 0.1943, Acc: 71.43% | Val Loss: 0.2025, Acc: 62.96%\n",
      "Early stopping at epoch 102\n",
      "Restoring model weights from epoch 52\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_Tanh'> [0.1] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 1e-05, 'dropout_rate': 0.1, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0.0001, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.4001, Acc: 40.18% | Val Loss: 0.3660, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3057, Acc: 57.14% | Val Loss: 0.3335, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2540, Acc: 66.96% | Val Loss: 0.3092, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2604, Acc: 65.18% | Val Loss: 0.2855, Acc: 62.96%\n",
      "Epoch 40: Train Loss: 0.2372, Acc: 68.75% | Val Loss: 0.2688, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2428, Acc: 69.64% | Val Loss: 0.2576, Acc: 66.67%\n",
      "Epoch 60: Train Loss: 0.2081, Acc: 70.54% | Val Loss: 0.2524, Acc: 66.67%\n",
      "Epoch 70: Train Loss: 0.2401, Acc: 60.71% | Val Loss: 0.2457, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.1966, Acc: 68.75% | Val Loss: 0.2369, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2104, Acc: 68.75% | Val Loss: 0.2263, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.1880, Acc: 69.64% | Val Loss: 0.2178, Acc: 62.96%\n",
      "Epoch 110: Train Loss: 0.1850, Acc: 68.75% | Val Loss: 0.2107, Acc: 62.96%\n",
      "Epoch 120: Train Loss: 0.1901, Acc: 69.64% | Val Loss: 0.2025, Acc: 62.96%\n",
      "Epoch 130: Train Loss: 0.1928, Acc: 67.86% | Val Loss: 0.1973, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2125, Acc: 64.29% | Val Loss: 0.1916, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.7037\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.7037\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6000\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2557, Acc: 59.23% | Val Loss: 0.2464, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2459, Acc: 59.23% | Val Loss: 0.2452, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2400, Acc: 60.71% | Val Loss: 0.2455, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2376, Acc: 61.31% | Val Loss: 0.2461, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2341, Acc: 60.12% | Val Loss: 0.2466, Acc: 62.96%\n",
      "Early stopping at epoch 40\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.6296\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3959, Acc: 36.01% | Val Loss: 0.3624, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.3462, Acc: 36.31% | Val Loss: 0.3225, Acc: 37.04%\n",
      "Epoch 20: Train Loss: 0.3200, Acc: 35.12% | Val Loss: 0.3005, Acc: 37.04%\n",
      "Epoch 30: Train Loss: 0.3044, Acc: 34.82% | Val Loss: 0.2865, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.2901, Acc: 36.61% | Val Loss: 0.2768, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.2834, Acc: 38.39% | Val Loss: 0.2699, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.2764, Acc: 39.58% | Val Loss: 0.2647, Acc: 44.44%\n",
      "Epoch 70: Train Loss: 0.2706, Acc: 41.37% | Val Loss: 0.2607, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.2669, Acc: 43.75% | Val Loss: 0.2574, Acc: 33.33%\n",
      "Epoch 90: Train Loss: 0.2645, Acc: 41.96% | Val Loss: 0.2548, Acc: 37.04%\n",
      "Epoch 100: Train Loss: 0.2619, Acc: 45.83% | Val Loss: 0.2526, Acc: 37.04%\n",
      "Epoch 110: Train Loss: 0.2588, Acc: 47.02% | Val Loss: 0.2507, Acc: 37.04%\n",
      "Epoch 120: Train Loss: 0.2568, Acc: 47.02% | Val Loss: 0.2491, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.2543, Acc: 47.62% | Val Loss: 0.2477, Acc: 44.44%\n",
      "Epoch 140: Train Loss: 0.2537, Acc: 46.13% | Val Loss: 0.2465, Acc: 40.74%\n",
      "Epoch 150: Train Loss: 0.2520, Acc: 45.54% | Val Loss: 0.2454, Acc: 40.74%\n",
      "Epoch 160: Train Loss: 0.2506, Acc: 52.68% | Val Loss: 0.2445, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2493, Acc: 52.38% | Val Loss: 0.2437, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.2491, Acc: 52.68% | Val Loss: 0.2429, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2487, Acc: 52.68% | Val Loss: 0.2422, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.2465, Acc: 55.95% | Val Loss: 0.2416, Acc: 59.26%\n",
      "Epoch 210: Train Loss: 0.2470, Acc: 53.57% | Val Loss: 0.2410, Acc: 62.96%\n",
      "Epoch 220: Train Loss: 0.2456, Acc: 56.85% | Val Loss: 0.2405, Acc: 59.26%\n",
      "Epoch 230: Train Loss: 0.2451, Acc: 57.14% | Val Loss: 0.2401, Acc: 62.96%\n",
      "Epoch 240: Train Loss: 0.2446, Acc: 58.04% | Val Loss: 0.2396, Acc: 70.37%\n",
      "Final Validation Accuracy: 0.7037\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.7037\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4230, Acc: 37.50% | Val Loss: 0.4330, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.4004, Acc: 36.31% | Val Loss: 0.4124, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.3760, Acc: 44.05% | Val Loss: 0.3967, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.3608, Acc: 44.64% | Val Loss: 0.3861, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.3526, Acc: 43.45% | Val Loss: 0.3784, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.3454, Acc: 43.75% | Val Loss: 0.3731, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.3381, Acc: 44.35% | Val Loss: 0.3688, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.3328, Acc: 44.05% | Val Loss: 0.3649, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.3287, Acc: 46.13% | Val Loss: 0.3614, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.3238, Acc: 46.73% | Val Loss: 0.3581, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.3225, Acc: 46.73% | Val Loss: 0.3554, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.3167, Acc: 47.92% | Val Loss: 0.3527, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.3119, Acc: 48.21% | Val Loss: 0.3502, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.3078, Acc: 48.51% | Val Loss: 0.3479, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.3094, Acc: 47.92% | Val Loss: 0.3459, Acc: 55.56%\n",
      "Epoch 150: Train Loss: 0.3041, Acc: 51.49% | Val Loss: 0.3439, Acc: 55.56%\n",
      "Epoch 160: Train Loss: 0.3049, Acc: 51.19% | Val Loss: 0.3416, Acc: 55.56%\n",
      "Epoch 170: Train Loss: 0.3022, Acc: 50.60% | Val Loss: 0.3395, Acc: 55.56%\n",
      "Epoch 180: Train Loss: 0.3011, Acc: 50.60% | Val Loss: 0.3376, Acc: 55.56%\n",
      "Epoch 190: Train Loss: 0.2986, Acc: 50.60% | Val Loss: 0.3358, Acc: 55.56%\n",
      "Epoch 200: Train Loss: 0.2965, Acc: 50.00% | Val Loss: 0.3341, Acc: 55.56%\n",
      "Epoch 210: Train Loss: 0.2927, Acc: 49.11% | Val Loss: 0.3325, Acc: 55.56%\n",
      "Epoch 220: Train Loss: 0.2945, Acc: 48.81% | Val Loss: 0.3310, Acc: 55.56%\n",
      "Epoch 230: Train Loss: 0.2911, Acc: 49.70% | Val Loss: 0.3295, Acc: 55.56%\n",
      "Epoch 240: Train Loss: 0.2891, Acc: 49.11% | Val Loss: 0.3282, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5556\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3338, Acc: 50.30% | Val Loss: 0.4357, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.3229, Acc: 57.74% | Val Loss: 0.4264, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3172, Acc: 60.42% | Val Loss: 0.4209, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.3149, Acc: 61.61% | Val Loss: 0.4157, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.3180, Acc: 60.42% | Val Loss: 0.4120, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.3134, Acc: 60.71% | Val Loss: 0.4086, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.3072, Acc: 62.20% | Val Loss: 0.4056, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.3080, Acc: 61.01% | Val Loss: 0.4028, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.3085, Acc: 61.31% | Val Loss: 0.4003, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.3039, Acc: 60.71% | Val Loss: 0.3978, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.3063, Acc: 62.20% | Val Loss: 0.3957, Acc: 51.85%\n",
      "Epoch 110: Train Loss: 0.3054, Acc: 62.50% | Val Loss: 0.3939, Acc: 51.85%\n",
      "Epoch 120: Train Loss: 0.3033, Acc: 62.20% | Val Loss: 0.3922, Acc: 51.85%\n",
      "Epoch 130: Train Loss: 0.3035, Acc: 62.20% | Val Loss: 0.3906, Acc: 51.85%\n",
      "Epoch 140: Train Loss: 0.2988, Acc: 62.80% | Val Loss: 0.3892, Acc: 51.85%\n",
      "Epoch 150: Train Loss: 0.3044, Acc: 61.90% | Val Loss: 0.3878, Acc: 51.85%\n",
      "Epoch 160: Train Loss: 0.3010, Acc: 61.90% | Val Loss: 0.3865, Acc: 51.85%\n",
      "Epoch 170: Train Loss: 0.3008, Acc: 61.61% | Val Loss: 0.3854, Acc: 51.85%\n",
      "Epoch 180: Train Loss: 0.3014, Acc: 60.71% | Val Loss: 0.3844, Acc: 51.85%\n",
      "Epoch 190: Train Loss: 0.3005, Acc: 61.31% | Val Loss: 0.3835, Acc: 51.85%\n",
      "Epoch 200: Train Loss: 0.3009, Acc: 61.31% | Val Loss: 0.3827, Acc: 51.85%\n",
      "Epoch 210: Train Loss: 0.3038, Acc: 60.71% | Val Loss: 0.3820, Acc: 51.85%\n",
      "Epoch 220: Train Loss: 0.2975, Acc: 61.90% | Val Loss: 0.3814, Acc: 51.85%\n",
      "Epoch 230: Train Loss: 0.2992, Acc: 61.01% | Val Loss: 0.3807, Acc: 51.85%\n",
      "Epoch 240: Train Loss: 0.2966, Acc: 61.90% | Val Loss: 0.3801, Acc: 51.85%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.0, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3191, Acc: 41.07% | Val Loss: 0.2990, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2906, Acc: 41.67% | Val Loss: 0.2786, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2798, Acc: 44.64% | Val Loss: 0.2676, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2686, Acc: 47.92% | Val Loss: 0.2612, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2608, Acc: 54.46% | Val Loss: 0.2569, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2587, Acc: 56.25% | Val Loss: 0.2539, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.2555, Acc: 55.65% | Val Loss: 0.2515, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2532, Acc: 58.33% | Val Loss: 0.2495, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2515, Acc: 59.52% | Val Loss: 0.2479, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2510, Acc: 60.12% | Val Loss: 0.2466, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2465, Acc: 61.90% | Val Loss: 0.2455, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2491, Acc: 61.31% | Val Loss: 0.2445, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2469, Acc: 61.31% | Val Loss: 0.2436, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.2432, Acc: 61.61% | Val Loss: 0.2428, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2439, Acc: 61.31% | Val Loss: 0.2422, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.2445, Acc: 61.01% | Val Loss: 0.2416, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.2418, Acc: 61.01% | Val Loss: 0.2411, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2431, Acc: 61.01% | Val Loss: 0.2406, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.2428, Acc: 61.31% | Val Loss: 0.2402, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2415, Acc: 61.61% | Val Loss: 0.2398, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2448, Acc: 61.31% | Val Loss: 0.2394, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.2418, Acc: 61.31% | Val Loss: 0.2391, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.2399, Acc: 61.31% | Val Loss: 0.2388, Acc: 48.15%\n",
      "Epoch 230: Train Loss: 0.2408, Acc: 61.90% | Val Loss: 0.2385, Acc: 48.15%\n",
      "Epoch 240: Train Loss: 0.2397, Acc: 61.61% | Val Loss: 0.2382, Acc: 48.15%\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4815\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5778\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3053, Acc: 63.39% | Val Loss: 0.3711, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2893, Acc: 63.39% | Val Loss: 0.3668, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2913, Acc: 58.93% | Val Loss: 0.3533, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2627, Acc: 66.96% | Val Loss: 0.3508, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2826, Acc: 63.39% | Val Loss: 0.3435, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2604, Acc: 70.54% | Val Loss: 0.3372, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2554, Acc: 62.50% | Val Loss: 0.3295, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2524, Acc: 65.18% | Val Loss: 0.3237, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2480, Acc: 66.96% | Val Loss: 0.3091, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2455, Acc: 66.07% | Val Loss: 0.3079, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2267, Acc: 67.86% | Val Loss: 0.3049, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2398, Acc: 64.29% | Val Loss: 0.2912, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2339, Acc: 66.96% | Val Loss: 0.2945, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2197, Acc: 67.86% | Val Loss: 0.2883, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.2260, Acc: 69.64% | Val Loss: 0.2884, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2132, Acc: 72.32% | Val Loss: 0.2942, Acc: 55.56%\n",
      "Epoch 160: Train Loss: 0.2224, Acc: 65.18% | Val Loss: 0.2873, Acc: 55.56%\n",
      "Epoch 170: Train Loss: 0.1933, Acc: 72.32% | Val Loss: 0.2823, Acc: 51.85%\n",
      "Epoch 180: Train Loss: 0.1939, Acc: 73.21% | Val Loss: 0.2857, Acc: 55.56%\n",
      "Epoch 190: Train Loss: 0.1992, Acc: 73.21% | Val Loss: 0.2875, Acc: 51.85%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2989, Acc: 42.86% | Val Loss: 0.3158, Acc: 37.04%\n",
      "Epoch 10: Train Loss: 0.2769, Acc: 41.07% | Val Loss: 0.2868, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2540, Acc: 55.36% | Val Loss: 0.2726, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2447, Acc: 51.79% | Val Loss: 0.2657, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2379, Acc: 57.14% | Val Loss: 0.2641, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2268, Acc: 62.50% | Val Loss: 0.2618, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2158, Acc: 67.86% | Val Loss: 0.2607, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2163, Acc: 65.18% | Val Loss: 0.2599, Acc: 55.56%\n",
      "Early stopping at epoch 77\n",
      "Restoring model weights from epoch 57\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5556\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3175, Acc: 57.14% | Val Loss: 0.3375, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2818, Acc: 51.79% | Val Loss: 0.3237, Acc: 51.85%\n",
      "Epoch 20: Train Loss: 0.2723, Acc: 56.25% | Val Loss: 0.3259, Acc: 48.15%\n",
      "Epoch 30: Train Loss: 0.2587, Acc: 60.71% | Val Loss: 0.3248, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2517, Acc: 60.71% | Val Loss: 0.3222, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.2184, Acc: 68.75% | Val Loss: 0.3256, Acc: 48.15%\n",
      "Early stopping at epoch 52\n",
      "Restoring model weights from epoch 32\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.4815\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2570, Acc: 57.14% | Val Loss: 0.2037, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.2417, Acc: 60.71% | Val Loss: 0.1894, Acc: 70.37%\n",
      "Epoch 20: Train Loss: 0.2678, Acc: 56.25% | Val Loss: 0.1888, Acc: 66.67%\n",
      "Epoch 30: Train Loss: 0.2504, Acc: 57.14% | Val Loss: 0.1850, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.2340, Acc: 64.29% | Val Loss: 0.1944, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2445, Acc: 57.14% | Val Loss: 0.1939, Acc: 62.96%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 30\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.6296\n",
      "[6] <class 'src.activation_functions.Activation_ReLU'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [6], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.0001, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0, 'patience': 20, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3331, Acc: 57.14% | Val Loss: 0.3497, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.3033, Acc: 64.29% | Val Loss: 0.3173, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.3002, Acc: 64.29% | Val Loss: 0.3079, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.3098, Acc: 63.39% | Val Loss: 0.2994, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2908, Acc: 57.14% | Val Loss: 0.2860, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2710, Acc: 56.25% | Val Loss: 0.2671, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2716, Acc: 56.25% | Val Loss: 0.2521, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.2539, Acc: 58.04% | Val Loss: 0.2420, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2406, Acc: 63.39% | Val Loss: 0.2335, Acc: 66.67%\n",
      "Epoch 90: Train Loss: 0.2366, Acc: 65.18% | Val Loss: 0.2327, Acc: 70.37%\n",
      "Epoch 100: Train Loss: 0.2417, Acc: 64.29% | Val Loss: 0.2294, Acc: 70.37%\n",
      "Epoch 110: Train Loss: 0.2290, Acc: 66.96% | Val Loss: 0.2293, Acc: 70.37%\n",
      "Epoch 120: Train Loss: 0.2314, Acc: 66.07% | Val Loss: 0.2298, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.2321, Acc: 66.07% | Val Loss: 0.2310, Acc: 66.67%\n",
      "Early stopping at epoch 137\n",
      "Restoring model weights from epoch 117\n",
      "Final Validation Accuracy: 0.6667\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6667\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5704\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.0001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3437, Acc: 48.81% | Val Loss: 0.4183, Acc: 44.44%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4444\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.0001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3231, Acc: 54.76% | Val Loss: 0.4645, Acc: 33.33%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.3333\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3333\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.0001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3177, Acc: 54.46% | Val Loss: 0.2013, Acc: 70.37%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7037\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.7037\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.0001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3179, Acc: 58.04% | Val Loss: 0.3087, Acc: 59.26%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5926\n",
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.0001, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.4641, Acc: 41.67% | Val Loss: 0.5267, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4963\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2498, Acc: 52.60% | Val Loss: 0.2837, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4074\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3549, Acc: 37.50% | Val Loss: 0.3069, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2995, Acc: 43.75% | Val Loss: 0.3738, Acc: 29.63%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2963\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2963\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2936, Acc: 57.55% | Val Loss: 0.2005, Acc: 74.07%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0001, 'l1': 0.0001, 'l2': 0.0001, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 250, 'weight_decay': 1e-05, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3648, Acc: 45.83% | Val Loss: 0.2811, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5185\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4889\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2511, Acc: 58.04% | Val Loss: 0.2475, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2497, Acc: 59.82% | Val Loss: 0.2474, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2490, Acc: 58.93% | Val Loss: 0.2474, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2490, Acc: 58.04% | Val Loss: 0.2474, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2481, Acc: 60.71% | Val Loss: 0.2474, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2479, Acc: 60.71% | Val Loss: 0.2474, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2482, Acc: 58.93% | Val Loss: 0.2474, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.2490, Acc: 58.93% | Val Loss: 0.2473, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2479, Acc: 60.71% | Val Loss: 0.2473, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2481, Acc: 58.93% | Val Loss: 0.2473, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2489, Acc: 58.93% | Val Loss: 0.2473, Acc: 51.85%\n",
      "Epoch 110: Train Loss: 0.2481, Acc: 60.71% | Val Loss: 0.2473, Acc: 51.85%\n",
      "Epoch 120: Train Loss: 0.2476, Acc: 61.61% | Val Loss: 0.2473, Acc: 51.85%\n",
      "Early stopping at epoch 127\n",
      "Restoring model weights from epoch 77\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2498, Acc: 41.07% | Val Loss: 0.2551, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2479, Acc: 48.21% | Val Loss: 0.2548, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2497, Acc: 47.32% | Val Loss: 0.2547, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.2447, Acc: 50.00% | Val Loss: 0.2547, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.2497, Acc: 46.43% | Val Loss: 0.2546, Acc: 40.74%\n",
      "Epoch 50: Train Loss: 0.2498, Acc: 46.43% | Val Loss: 0.2546, Acc: 40.74%\n",
      "Epoch 60: Train Loss: 0.2477, Acc: 48.21% | Val Loss: 0.2546, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.2492, Acc: 48.21% | Val Loss: 0.2546, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.2489, Acc: 49.11% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 90: Train Loss: 0.2496, Acc: 48.21% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 100: Train Loss: 0.2470, Acc: 50.89% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.2477, Acc: 50.00% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.2473, Acc: 50.00% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.2500, Acc: 48.21% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 140: Train Loss: 0.2470, Acc: 49.11% | Val Loss: 0.2545, Acc: 40.74%\n",
      "Epoch 150: Train Loss: 0.2476, Acc: 49.11% | Val Loss: 0.2544, Acc: 40.74%\n",
      "Epoch 160: Train Loss: 0.2452, Acc: 50.89% | Val Loss: 0.2544, Acc: 40.74%\n",
      "Epoch 170: Train Loss: 0.2460, Acc: 50.00% | Val Loss: 0.2544, Acc: 40.74%\n",
      "Epoch 180: Train Loss: 0.2464, Acc: 50.89% | Val Loss: 0.2544, Acc: 40.74%\n",
      "Epoch 190: Train Loss: 0.2437, Acc: 52.68% | Val Loss: 0.2544, Acc: 40.74%\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4074\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2618, Acc: 56.25% | Val Loss: 0.2172, Acc: 74.07%\n",
      "Epoch 10: Train Loss: 0.2584, Acc: 59.82% | Val Loss: 0.2169, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.2568, Acc: 58.93% | Val Loss: 0.2168, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.2560, Acc: 61.61% | Val Loss: 0.2168, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.2551, Acc: 60.71% | Val Loss: 0.2167, Acc: 74.07%\n",
      "Epoch 50: Train Loss: 0.2632, Acc: 59.82% | Val Loss: 0.2167, Acc: 74.07%\n",
      "Epoch 60: Train Loss: 0.2600, Acc: 58.93% | Val Loss: 0.2167, Acc: 74.07%\n",
      "Epoch 70: Train Loss: 0.2548, Acc: 60.71% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 80: Train Loss: 0.2577, Acc: 59.82% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 90: Train Loss: 0.2598, Acc: 59.82% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 100: Train Loss: 0.2536, Acc: 61.61% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 110: Train Loss: 0.2564, Acc: 60.71% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 120: Train Loss: 0.2590, Acc: 59.82% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 130: Train Loss: 0.2594, Acc: 59.82% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 140: Train Loss: 0.2584, Acc: 60.71% | Val Loss: 0.2166, Acc: 74.07%\n",
      "Epoch 150: Train Loss: 0.2576, Acc: 60.71% | Val Loss: 0.2165, Acc: 74.07%\n",
      "Epoch 160: Train Loss: 0.2582, Acc: 60.71% | Val Loss: 0.2165, Acc: 74.07%\n",
      "Epoch 170: Train Loss: 0.2637, Acc: 58.93% | Val Loss: 0.2165, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.2546, Acc: 60.71% | Val Loss: 0.2165, Acc: 74.07%\n",
      "Epoch 190: Train Loss: 0.2550, Acc: 61.61% | Val Loss: 0.2165, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.7407\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2519, Acc: 61.61% | Val Loss: 0.1839, Acc: 74.07%\n",
      "Epoch 10: Train Loss: 0.2514, Acc: 61.61% | Val Loss: 0.1848, Acc: 74.07%\n",
      "Epoch 20: Train Loss: 0.2525, Acc: 61.61% | Val Loss: 0.1851, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.2597, Acc: 59.82% | Val Loss: 0.1853, Acc: 74.07%\n",
      "Epoch 40: Train Loss: 0.2644, Acc: 58.93% | Val Loss: 0.1854, Acc: 74.07%\n",
      "Epoch 50: Train Loss: 0.2558, Acc: 60.71% | Val Loss: 0.1856, Acc: 74.07%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[3] <class 'src.activation_functions.Activation_ReLU'> [0.0] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 200, 'weight_decay': 0.05, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2336, Acc: 66.07% | Val Loss: 0.2414, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2327, Acc: 64.29% | Val Loss: 0.2411, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2337, Acc: 65.18% | Val Loss: 0.2410, Acc: 59.26%\n",
      "Epoch 30: Train Loss: 0.2320, Acc: 65.18% | Val Loss: 0.2409, Acc: 59.26%\n",
      "Epoch 40: Train Loss: 0.2349, Acc: 65.18% | Val Loss: 0.2409, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2343, Acc: 65.18% | Val Loss: 0.2408, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2341, Acc: 64.29% | Val Loss: 0.2408, Acc: 59.26%\n",
      "Epoch 70: Train Loss: 0.2323, Acc: 65.18% | Val Loss: 0.2408, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2330, Acc: 64.29% | Val Loss: 0.2407, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2318, Acc: 65.18% | Val Loss: 0.2407, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.2363, Acc: 63.39% | Val Loss: 0.2407, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2317, Acc: 66.07% | Val Loss: 0.2407, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.2365, Acc: 63.39% | Val Loss: 0.2407, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2319, Acc: 65.18% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 140: Train Loss: 0.2328, Acc: 65.18% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 150: Train Loss: 0.2368, Acc: 64.29% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.2320, Acc: 64.29% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.2319, Acc: 65.18% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 180: Train Loss: 0.2330, Acc: 65.18% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.2367, Acc: 63.39% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5926\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6000\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2514, Acc: 57.14% | Val Loss: 0.2477, Acc: 59.26%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5926\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2899, Acc: 46.43% | Val Loss: 0.2463, Acc: 62.96%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.6296\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3172, Acc: 45.54% | Val Loss: 0.3137, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2920, Acc: 56.25% | Val Loss: 0.2627, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.5185\n",
      "[3] <class 'src.activation_functions.Activation_Tanh'> [0.0] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [3], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.0001, 'l1': 0.001, 'l2': 0.01, 'dropout_rate': 0.0, 'batch_size': 8, 'n_epochs': 250, 'weight_decay': 0.001, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2598, Acc: 49.11% | Val Loss: 0.2631, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4815\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5481\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3068, Acc: 51.79% | Val Loss: 0.3221, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.3185, Acc: 45.54% | Val Loss: 0.2784, Acc: 48.15%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4815\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4815\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2901, Acc: 56.25% | Val Loss: 0.2146, Acc: 62.96%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6296\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.2973, Acc: 60.71% | Val Loss: 0.1910, Acc: 77.78%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[8] <class 'src.activation_functions.Activation_Sigmoid'> [0.3] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': [True], 'learning_rate': 1e-06, 'l1': 0.01, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 8, 'n_epochs': 150, 'weight_decay': 0, 'patience': 0, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.5542, Acc: 34.82% | Val Loss: 0.5520, Acc: 40.74%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4074\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4074\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.5630\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2472, Acc: 54.69% | Val Loss: 0.2786, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2441, Acc: 59.90% | Val Loss: 0.2781, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2556, Acc: 65.36% | Val Loss: 0.2777, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2505, Acc: 64.32% | Val Loss: 0.2772, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2576, Acc: 58.85% | Val Loss: 0.2766, Acc: 44.44%\n",
      "Epoch 50: Train Loss: 0.2432, Acc: 61.72% | Val Loss: 0.2760, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.2467, Acc: 61.72% | Val Loss: 0.2758, Acc: 44.44%\n",
      "Epoch 70: Train Loss: 0.2439, Acc: 56.51% | Val Loss: 0.2754, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2434, Acc: 62.76% | Val Loss: 0.2749, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.2342, Acc: 65.62% | Val Loss: 0.2747, Acc: 48.15%\n",
      "Epoch 100: Train Loss: 0.2489, Acc: 58.07% | Val Loss: 0.2745, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2299, Acc: 63.54% | Val Loss: 0.2743, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2352, Acc: 64.06% | Val Loss: 0.2741, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.2231, Acc: 66.67% | Val Loss: 0.2739, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2421, Acc: 62.24% | Val Loss: 0.2738, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.2311, Acc: 68.23% | Val Loss: 0.2734, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.2386, Acc: 59.11% | Val Loss: 0.2730, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2261, Acc: 65.62% | Val Loss: 0.2723, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.2251, Acc: 67.45% | Val Loss: 0.2719, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2407, Acc: 56.25% | Val Loss: 0.2716, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2252, Acc: 66.67% | Val Loss: 0.2712, Acc: 48.15%\n",
      "Epoch 210: Train Loss: 0.2248, Acc: 63.54% | Val Loss: 0.2710, Acc: 48.15%\n",
      "Epoch 220: Train Loss: 0.2232, Acc: 61.98% | Val Loss: 0.2709, Acc: 51.85%\n",
      "Epoch 230: Train Loss: 0.2323, Acc: 67.71% | Val Loss: 0.2708, Acc: 51.85%\n",
      "Epoch 240: Train Loss: 0.2121, Acc: 71.88% | Val Loss: 0.2705, Acc: 51.85%\n",
      "Epoch 250: Train Loss: 0.2318, Acc: 65.36% | Val Loss: 0.2704, Acc: 51.85%\n",
      "Epoch 260: Train Loss: 0.2280, Acc: 59.11% | Val Loss: 0.2701, Acc: 55.56%\n",
      "Epoch 270: Train Loss: 0.2198, Acc: 67.97% | Val Loss: 0.2699, Acc: 55.56%\n",
      "Epoch 280: Train Loss: 0.2214, Acc: 66.15% | Val Loss: 0.2698, Acc: 55.56%\n",
      "Epoch 290: Train Loss: 0.2202, Acc: 69.27% | Val Loss: 0.2696, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2698, Acc: 55.47% | Val Loss: 0.2917, Acc: 44.44%\n",
      "Epoch 10: Train Loss: 0.2684, Acc: 47.66% | Val Loss: 0.2877, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2678, Acc: 51.30% | Val Loss: 0.2834, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2644, Acc: 47.40% | Val Loss: 0.2798, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2742, Acc: 46.35% | Val Loss: 0.2766, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2583, Acc: 48.44% | Val Loss: 0.2729, Acc: 48.15%\n",
      "Epoch 60: Train Loss: 0.2647, Acc: 46.09% | Val Loss: 0.2702, Acc: 48.15%\n",
      "Epoch 70: Train Loss: 0.2751, Acc: 51.30% | Val Loss: 0.2679, Acc: 48.15%\n",
      "Epoch 80: Train Loss: 0.2652, Acc: 47.40% | Val Loss: 0.2655, Acc: 48.15%\n",
      "Epoch 90: Train Loss: 0.2611, Acc: 54.95% | Val Loss: 0.2633, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2534, Acc: 48.70% | Val Loss: 0.2609, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2529, Acc: 54.69% | Val Loss: 0.2591, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2466, Acc: 54.17% | Val Loss: 0.2573, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.2415, Acc: 56.25% | Val Loss: 0.2552, Acc: 51.85%\n",
      "Epoch 140: Train Loss: 0.2432, Acc: 57.29% | Val Loss: 0.2533, Acc: 51.85%\n",
      "Epoch 150: Train Loss: 0.2443, Acc: 56.51% | Val Loss: 0.2516, Acc: 51.85%\n",
      "Epoch 160: Train Loss: 0.2409, Acc: 56.77% | Val Loss: 0.2499, Acc: 51.85%\n",
      "Epoch 170: Train Loss: 0.2431, Acc: 49.48% | Val Loss: 0.2482, Acc: 51.85%\n",
      "Epoch 180: Train Loss: 0.2330, Acc: 59.38% | Val Loss: 0.2468, Acc: 51.85%\n",
      "Epoch 190: Train Loss: 0.2415, Acc: 57.29% | Val Loss: 0.2453, Acc: 51.85%\n",
      "Epoch 200: Train Loss: 0.2437, Acc: 55.21% | Val Loss: 0.2440, Acc: 51.85%\n",
      "Epoch 210: Train Loss: 0.2373, Acc: 53.65% | Val Loss: 0.2428, Acc: 59.26%\n",
      "Epoch 220: Train Loss: 0.2247, Acc: 63.02% | Val Loss: 0.2419, Acc: 59.26%\n",
      "Epoch 230: Train Loss: 0.2379, Acc: 57.29% | Val Loss: 0.2408, Acc: 59.26%\n",
      "Epoch 240: Train Loss: 0.2261, Acc: 65.36% | Val Loss: 0.2396, Acc: 59.26%\n",
      "Epoch 250: Train Loss: 0.2383, Acc: 55.99% | Val Loss: 0.2384, Acc: 59.26%\n",
      "Epoch 260: Train Loss: 0.2429, Acc: 56.25% | Val Loss: 0.2374, Acc: 59.26%\n",
      "Epoch 270: Train Loss: 0.2236, Acc: 64.84% | Val Loss: 0.2364, Acc: 59.26%\n",
      "Epoch 280: Train Loss: 0.2338, Acc: 61.46% | Val Loss: 0.2357, Acc: 59.26%\n",
      "Epoch 290: Train Loss: 0.2346, Acc: 60.94% | Val Loss: 0.2351, Acc: 59.26%\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5926\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3185, Acc: 47.40% | Val Loss: 0.3168, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2731, Acc: 57.55% | Val Loss: 0.3130, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2889, Acc: 50.26% | Val Loss: 0.3093, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2646, Acc: 52.08% | Val Loss: 0.3053, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2860, Acc: 51.56% | Val Loss: 0.3016, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2852, Acc: 50.78% | Val Loss: 0.2985, Acc: 51.85%\n",
      "Epoch 60: Train Loss: 0.2793, Acc: 51.04% | Val Loss: 0.2961, Acc: 51.85%\n",
      "Epoch 70: Train Loss: 0.2593, Acc: 55.21% | Val Loss: 0.2934, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2746, Acc: 48.44% | Val Loss: 0.2909, Acc: 51.85%\n",
      "Epoch 90: Train Loss: 0.2663, Acc: 51.30% | Val Loss: 0.2884, Acc: 51.85%\n",
      "Epoch 100: Train Loss: 0.2459, Acc: 52.86% | Val Loss: 0.2862, Acc: 48.15%\n",
      "Epoch 110: Train Loss: 0.2411, Acc: 63.02% | Val Loss: 0.2842, Acc: 48.15%\n",
      "Epoch 120: Train Loss: 0.2700, Acc: 50.52% | Val Loss: 0.2824, Acc: 48.15%\n",
      "Epoch 130: Train Loss: 0.2371, Acc: 63.28% | Val Loss: 0.2805, Acc: 48.15%\n",
      "Epoch 140: Train Loss: 0.2564, Acc: 51.04% | Val Loss: 0.2787, Acc: 48.15%\n",
      "Epoch 150: Train Loss: 0.2693, Acc: 52.60% | Val Loss: 0.2771, Acc: 48.15%\n",
      "Epoch 160: Train Loss: 0.2498, Acc: 57.81% | Val Loss: 0.2757, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.2331, Acc: 59.90% | Val Loss: 0.2742, Acc: 48.15%\n",
      "Epoch 180: Train Loss: 0.2415, Acc: 64.32% | Val Loss: 0.2728, Acc: 48.15%\n",
      "Epoch 190: Train Loss: 0.2611, Acc: 53.91% | Val Loss: 0.2715, Acc: 48.15%\n",
      "Epoch 200: Train Loss: 0.2262, Acc: 61.46% | Val Loss: 0.2701, Acc: 51.85%\n",
      "Epoch 210: Train Loss: 0.2462, Acc: 64.32% | Val Loss: 0.2690, Acc: 55.56%\n",
      "Epoch 220: Train Loss: 0.2330, Acc: 62.76% | Val Loss: 0.2678, Acc: 55.56%\n",
      "Epoch 230: Train Loss: 0.2631, Acc: 54.69% | Val Loss: 0.2665, Acc: 55.56%\n",
      "Epoch 240: Train Loss: 0.2548, Acc: 55.47% | Val Loss: 0.2653, Acc: 59.26%\n",
      "Epoch 250: Train Loss: 0.2315, Acc: 67.97% | Val Loss: 0.2641, Acc: 62.96%\n",
      "Epoch 260: Train Loss: 0.2341, Acc: 57.55% | Val Loss: 0.2628, Acc: 62.96%\n",
      "Epoch 270: Train Loss: 0.2392, Acc: 65.10% | Val Loss: 0.2613, Acc: 62.96%\n",
      "Epoch 280: Train Loss: 0.2407, Acc: 61.20% | Val Loss: 0.2601, Acc: 62.96%\n",
      "Epoch 290: Train Loss: 0.2262, Acc: 64.58% | Val Loss: 0.2589, Acc: 62.96%\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.6296\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3159, Acc: 48.18% | Val Loss: 0.3013, Acc: 40.74%\n",
      "Epoch 10: Train Loss: 0.2765, Acc: 60.42% | Val Loss: 0.2916, Acc: 40.74%\n",
      "Epoch 20: Train Loss: 0.2938, Acc: 51.04% | Val Loss: 0.2833, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2754, Acc: 57.81% | Val Loss: 0.2757, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2533, Acc: 58.33% | Val Loss: 0.2687, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2473, Acc: 59.90% | Val Loss: 0.2627, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2477, Acc: 56.51% | Val Loss: 0.2582, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2390, Acc: 58.85% | Val Loss: 0.2540, Acc: 51.85%\n",
      "Epoch 80: Train Loss: 0.2409, Acc: 60.94% | Val Loss: 0.2512, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2541, Acc: 55.47% | Val Loss: 0.2475, Acc: 55.56%\n",
      "Epoch 100: Train Loss: 0.2333, Acc: 63.80% | Val Loss: 0.2435, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2334, Acc: 62.24% | Val Loss: 0.2408, Acc: 59.26%\n",
      "Epoch 120: Train Loss: 0.2378, Acc: 62.50% | Val Loss: 0.2383, Acc: 59.26%\n",
      "Epoch 130: Train Loss: 0.2519, Acc: 56.25% | Val Loss: 0.2357, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.2689, Acc: 55.21% | Val Loss: 0.2342, Acc: 62.96%\n",
      "Epoch 150: Train Loss: 0.2430, Acc: 57.81% | Val Loss: 0.2326, Acc: 62.96%\n",
      "Epoch 160: Train Loss: 0.2387, Acc: 62.76% | Val Loss: 0.2306, Acc: 62.96%\n",
      "Epoch 170: Train Loss: 0.2458, Acc: 59.11% | Val Loss: 0.2290, Acc: 62.96%\n",
      "Epoch 180: Train Loss: 0.2407, Acc: 59.64% | Val Loss: 0.2272, Acc: 66.67%\n",
      "Epoch 190: Train Loss: 0.2405, Acc: 61.72% | Val Loss: 0.2256, Acc: 66.67%\n",
      "Epoch 200: Train Loss: 0.2373, Acc: 64.06% | Val Loss: 0.2243, Acc: 66.67%\n",
      "Epoch 210: Train Loss: 0.2354, Acc: 57.29% | Val Loss: 0.2231, Acc: 66.67%\n",
      "Epoch 220: Train Loss: 0.2445, Acc: 61.72% | Val Loss: 0.2223, Acc: 70.37%\n",
      "Epoch 230: Train Loss: 0.2470, Acc: 58.85% | Val Loss: 0.2214, Acc: 70.37%\n",
      "Epoch 240: Train Loss: 0.2419, Acc: 62.50% | Val Loss: 0.2210, Acc: 70.37%\n",
      "Epoch 250: Train Loss: 0.2489, Acc: 56.51% | Val Loss: 0.2204, Acc: 70.37%\n",
      "Epoch 260: Train Loss: 0.2482, Acc: 59.38% | Val Loss: 0.2203, Acc: 70.37%\n",
      "Epoch 270: Train Loss: 0.2446, Acc: 60.68% | Val Loss: 0.2194, Acc: 70.37%\n",
      "Epoch 280: Train Loss: 0.2360, Acc: 61.46% | Val Loss: 0.2191, Acc: 70.37%\n",
      "Epoch 290: Train Loss: 0.2386, Acc: 62.76% | Val Loss: 0.2186, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7778\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7778\n",
      "[5] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.0002, 'l1': 0.01, 'l2': 1e-05, 'dropout_rate': 0.3, 'batch_size': 32, 'n_epochs': 300, 'weight_decay': 0, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2708, Acc: 62.24% | Val Loss: 0.2878, Acc: 55.56%\n",
      "Epoch 10: Train Loss: 0.2768, Acc: 59.64% | Val Loss: 0.2840, Acc: 55.56%\n",
      "Epoch 20: Train Loss: 0.2668, Acc: 64.84% | Val Loss: 0.2806, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2625, Acc: 61.20% | Val Loss: 0.2781, Acc: 55.56%\n",
      "Epoch 40: Train Loss: 0.2377, Acc: 66.93% | Val Loss: 0.2752, Acc: 55.56%\n",
      "Epoch 50: Train Loss: 0.2769, Acc: 58.85% | Val Loss: 0.2737, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2537, Acc: 67.71% | Val Loss: 0.2717, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2853, Acc: 55.99% | Val Loss: 0.2696, Acc: 55.56%\n",
      "Epoch 80: Train Loss: 0.2509, Acc: 60.94% | Val Loss: 0.2675, Acc: 55.56%\n",
      "Epoch 90: Train Loss: 0.2521, Acc: 65.62% | Val Loss: 0.2660, Acc: 55.56%\n",
      "Epoch 100: Train Loss: 0.2600, Acc: 60.94% | Val Loss: 0.2641, Acc: 55.56%\n",
      "Epoch 110: Train Loss: 0.2566, Acc: 66.15% | Val Loss: 0.2624, Acc: 55.56%\n",
      "Epoch 120: Train Loss: 0.2595, Acc: 63.80% | Val Loss: 0.2610, Acc: 55.56%\n",
      "Epoch 130: Train Loss: 0.2333, Acc: 69.79% | Val Loss: 0.2600, Acc: 55.56%\n",
      "Epoch 140: Train Loss: 0.2381, Acc: 66.41% | Val Loss: 0.2585, Acc: 59.26%\n",
      "Epoch 150: Train Loss: 0.2483, Acc: 64.06% | Val Loss: 0.2578, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.2451, Acc: 67.97% | Val Loss: 0.2566, Acc: 59.26%\n",
      "Epoch 170: Train Loss: 0.2469, Acc: 69.01% | Val Loss: 0.2559, Acc: 59.26%\n",
      "Epoch 180: Train Loss: 0.2488, Acc: 66.15% | Val Loss: 0.2550, Acc: 59.26%\n",
      "Epoch 190: Train Loss: 0.2506, Acc: 66.93% | Val Loss: 0.2544, Acc: 59.26%\n",
      "Epoch 200: Train Loss: 0.2369, Acc: 68.49% | Val Loss: 0.2529, Acc: 59.26%\n",
      "Epoch 210: Train Loss: 0.2295, Acc: 70.83% | Val Loss: 0.2520, Acc: 59.26%\n",
      "Epoch 220: Train Loss: 0.2509, Acc: 59.38% | Val Loss: 0.2515, Acc: 59.26%\n",
      "Epoch 230: Train Loss: 0.2362, Acc: 64.32% | Val Loss: 0.2504, Acc: 59.26%\n",
      "Epoch 240: Train Loss: 0.2537, Acc: 64.06% | Val Loss: 0.2498, Acc: 55.56%\n",
      "Epoch 250: Train Loss: 0.2232, Acc: 70.31% | Val Loss: 0.2492, Acc: 55.56%\n",
      "Epoch 260: Train Loss: 0.2567, Acc: 64.58% | Val Loss: 0.2487, Acc: 55.56%\n",
      "Epoch 270: Train Loss: 0.2288, Acc: 64.58% | Val Loss: 0.2484, Acc: 55.56%\n",
      "Epoch 280: Train Loss: 0.2393, Acc: 64.06% | Val Loss: 0.2481, Acc: 55.56%\n",
      "Epoch 290: Train Loss: 0.2336, Acc: 68.75% | Val Loss: 0.2478, Acc: 55.56%\n",
      "Final Validation Accuracy: 0.5556\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5556\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6148\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.2425, Acc: 56.55% | Val Loss: 0.2932, Acc: 44.44%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.4444\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.4444\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3346, Acc: 44.94% | Val Loss: 0.3278, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5185\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.4414, Acc: 42.86% | Val Loss: 0.5548, Acc: 25.93%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.2593\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2593\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3004, Acc: 58.33% | Val Loss: 0.1998, Acc: 74.07%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.3] [False]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [False], 'learning_rate': 1e-06, 'l1': 1e-06, 'l2': 1e-06, 'dropout_rate': 0.3, 'batch_size': 16, 'n_epochs': 250, 'weight_decay': 0.01, 'patience': 0, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.3588, Acc: 49.11% | Val Loss: 0.3156, Acc: 51.85%\n",
      "Early stopping at epoch 0\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.5185\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.4963\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.2696, Acc: 57.44% | Val Loss: 0.2957, Acc: 33.33%\n",
      "Epoch 10: Train Loss: 0.2532, Acc: 52.38% | Val Loss: 0.2962, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2283, Acc: 62.20% | Val Loss: 0.2892, Acc: 40.74%\n",
      "Epoch 30: Train Loss: 0.2359, Acc: 59.52% | Val Loss: 0.2844, Acc: 40.74%\n",
      "Epoch 40: Train Loss: 0.2269, Acc: 63.69% | Val Loss: 0.2805, Acc: 48.15%\n",
      "Epoch 50: Train Loss: 0.2075, Acc: 65.48% | Val Loss: 0.2782, Acc: 44.44%\n",
      "Epoch 60: Train Loss: 0.2172, Acc: 67.26% | Val Loss: 0.2766, Acc: 40.74%\n",
      "Epoch 70: Train Loss: 0.2186, Acc: 68.15% | Val Loss: 0.2773, Acc: 40.74%\n",
      "Epoch 80: Train Loss: 0.2052, Acc: 69.94% | Val Loss: 0.2753, Acc: 40.74%\n",
      "Epoch 90: Train Loss: 0.2045, Acc: 72.02% | Val Loss: 0.2734, Acc: 40.74%\n",
      "Epoch 100: Train Loss: 0.2130, Acc: 70.83% | Val Loss: 0.2728, Acc: 40.74%\n",
      "Epoch 110: Train Loss: 0.2022, Acc: 67.86% | Val Loss: 0.2745, Acc: 40.74%\n",
      "Epoch 120: Train Loss: 0.1929, Acc: 75.30% | Val Loss: 0.2712, Acc: 40.74%\n",
      "Epoch 130: Train Loss: 0.1978, Acc: 70.24% | Val Loss: 0.2685, Acc: 40.74%\n",
      "Epoch 140: Train Loss: 0.2000, Acc: 69.64% | Val Loss: 0.2688, Acc: 51.85%\n",
      "Epoch 150: Train Loss: 0.1859, Acc: 77.38% | Val Loss: 0.2663, Acc: 51.85%\n",
      "Epoch 160: Train Loss: 0.2003, Acc: 73.51% | Val Loss: 0.2677, Acc: 48.15%\n",
      "Epoch 170: Train Loss: 0.1890, Acc: 71.13% | Val Loss: 0.2656, Acc: 51.85%\n",
      "Epoch 180: Train Loss: 0.1946, Acc: 70.54% | Val Loss: 0.2688, Acc: 51.85%\n",
      "Epoch 190: Train Loss: 0.1838, Acc: 75.00% | Val Loss: 0.2671, Acc: 51.85%\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.5185\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3254, Acc: 52.38% | Val Loss: 0.3762, Acc: 48.15%\n",
      "Epoch 10: Train Loss: 0.3280, Acc: 49.11% | Val Loss: 0.3548, Acc: 44.44%\n",
      "Epoch 20: Train Loss: 0.2836, Acc: 54.46% | Val Loss: 0.3365, Acc: 44.44%\n",
      "Epoch 30: Train Loss: 0.2614, Acc: 57.14% | Val Loss: 0.3183, Acc: 44.44%\n",
      "Epoch 40: Train Loss: 0.2639, Acc: 55.36% | Val Loss: 0.3023, Acc: 51.85%\n",
      "Epoch 50: Train Loss: 0.2299, Acc: 63.99% | Val Loss: 0.2855, Acc: 55.56%\n",
      "Epoch 60: Train Loss: 0.2300, Acc: 60.42% | Val Loss: 0.2693, Acc: 55.56%\n",
      "Epoch 70: Train Loss: 0.2177, Acc: 69.05% | Val Loss: 0.2594, Acc: 59.26%\n",
      "Epoch 80: Train Loss: 0.2167, Acc: 63.39% | Val Loss: 0.2525, Acc: 59.26%\n",
      "Epoch 90: Train Loss: 0.2190, Acc: 66.07% | Val Loss: 0.2483, Acc: 59.26%\n",
      "Epoch 100: Train Loss: 0.1968, Acc: 72.32% | Val Loss: 0.2446, Acc: 59.26%\n",
      "Epoch 110: Train Loss: 0.2027, Acc: 68.15% | Val Loss: 0.2400, Acc: 66.67%\n",
      "Epoch 120: Train Loss: 0.1962, Acc: 71.43% | Val Loss: 0.2407, Acc: 66.67%\n",
      "Epoch 130: Train Loss: 0.1963, Acc: 67.56% | Val Loss: 0.2384, Acc: 62.96%\n",
      "Epoch 140: Train Loss: 0.1894, Acc: 71.13% | Val Loss: 0.2348, Acc: 70.37%\n",
      "Epoch 150: Train Loss: 0.2111, Acc: 64.88% | Val Loss: 0.2361, Acc: 59.26%\n",
      "Epoch 160: Train Loss: 0.1784, Acc: 73.21% | Val Loss: 0.2394, Acc: 59.26%\n",
      "Early stopping at epoch 169\n",
      "Restoring model weights from epoch 139\n",
      "Final Validation Accuracy: 0.5926\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.5926\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.4056, Acc: 38.10% | Val Loss: 0.2545, Acc: 66.67%\n",
      "Epoch 10: Train Loss: 0.3660, Acc: 44.64% | Val Loss: 0.3032, Acc: 48.15%\n",
      "Epoch 20: Train Loss: 0.3228, Acc: 46.13% | Val Loss: 0.3004, Acc: 51.85%\n",
      "Epoch 30: Train Loss: 0.3116, Acc: 46.73% | Val Loss: 0.2930, Acc: 51.85%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation Accuracy: 0.5185\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.5185\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3287, Acc: 50.00% | Val Loss: 0.2845, Acc: 51.85%\n",
      "Epoch 10: Train Loss: 0.2902, Acc: 56.25% | Val Loss: 0.2890, Acc: 59.26%\n",
      "Epoch 20: Train Loss: 0.2866, Acc: 56.25% | Val Loss: 0.2741, Acc: 55.56%\n",
      "Epoch 30: Train Loss: 0.2600, Acc: 56.55% | Val Loss: 0.2564, Acc: 51.85%\n",
      "Epoch 40: Train Loss: 0.2629, Acc: 55.95% | Val Loss: 0.2406, Acc: 59.26%\n",
      "Epoch 50: Train Loss: 0.2643, Acc: 56.55% | Val Loss: 0.2302, Acc: 59.26%\n",
      "Epoch 60: Train Loss: 0.2481, Acc: 58.93% | Val Loss: 0.2215, Acc: 62.96%\n",
      "Epoch 70: Train Loss: 0.2424, Acc: 62.50% | Val Loss: 0.2139, Acc: 62.96%\n",
      "Epoch 80: Train Loss: 0.2309, Acc: 60.71% | Val Loss: 0.2113, Acc: 62.96%\n",
      "Epoch 90: Train Loss: 0.2304, Acc: 64.58% | Val Loss: 0.2066, Acc: 70.37%\n",
      "Epoch 100: Train Loss: 0.2286, Acc: 63.39% | Val Loss: 0.2020, Acc: 66.67%\n",
      "Epoch 110: Train Loss: 0.2156, Acc: 65.77% | Val Loss: 0.2027, Acc: 70.37%\n",
      "Epoch 120: Train Loss: 0.2208, Acc: 59.82% | Val Loss: 0.2014, Acc: 70.37%\n",
      "Epoch 130: Train Loss: 0.2145, Acc: 58.93% | Val Loss: 0.2006, Acc: 66.67%\n",
      "Epoch 140: Train Loss: 0.2167, Acc: 61.61% | Val Loss: 0.1994, Acc: 66.67%\n",
      "Epoch 150: Train Loss: 0.2147, Acc: 66.07% | Val Loss: 0.1993, Acc: 70.37%\n",
      "Epoch 160: Train Loss: 0.2194, Acc: 61.90% | Val Loss: 0.1966, Acc: 74.07%\n",
      "Epoch 170: Train Loss: 0.2024, Acc: 67.26% | Val Loss: 0.1948, Acc: 74.07%\n",
      "Epoch 180: Train Loss: 0.2246, Acc: 64.88% | Val Loss: 0.1940, Acc: 74.07%\n",
      "Epoch 190: Train Loss: 0.2170, Acc: 63.99% | Val Loss: 0.1925, Acc: 74.07%\n",
      "Final Validation Accuracy: 0.7407\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.7407\n",
      "[5] <class 'src.activation_functions.Activation_Tanh'> [0.1] [True]\n",
      "Data shapes:\n",
      "X_train: (108, 17), y_train: (108, 1)\n",
      "Hyperparams: {'hidden_size': [5], 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': [True], 'learning_rate': 0.001, 'l1': 0.0001, 'l2': 0.01, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 200, 'weight_decay': 0.001, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.3216, Acc: 47.32% | Val Loss: 0.2661, Acc: 59.26%\n",
      "Epoch 10: Train Loss: 0.2967, Acc: 52.08% | Val Loss: 0.2298, Acc: 70.37%\n",
      "Epoch 20: Train Loss: 0.2563, Acc: 55.36% | Val Loss: 0.2238, Acc: 74.07%\n",
      "Epoch 30: Train Loss: 0.2612, Acc: 58.33% | Val Loss: 0.2230, Acc: 70.37%\n",
      "Epoch 40: Train Loss: 0.2385, Acc: 60.12% | Val Loss: 0.2222, Acc: 66.67%\n",
      "Epoch 50: Train Loss: 0.2415, Acc: 60.42% | Val Loss: 0.2241, Acc: 66.67%\n",
      "Early stopping at epoch 55\n",
      "Restoring model weights from epoch 25\n",
      "Final Validation Accuracy: 0.6296\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.6296\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.6000\n",
      "{'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random', 'val_accuracy': np.float64(0.7925925925925926)}\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams, best_performance = random_search(X_train=X_train, y_train=y_train, param_distributions=param_distributions, n_iters=50)  # adjust n_iters as needed\n",
    "\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random', 'val_accuracy': np.float64(0.7925925925925926)}\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n"
     ]
    }
   ],
   "source": [
    "if best_hyperparams['CC']:\n",
    "    model = CascadeCorrelation(input_size = 17, output_size= 1, activation=Activation_Leaky_ReLU, output_activation = Activation_Sigmoid)\n",
    "else:\n",
    "    model = NN(\n",
    "        l1=best_hyperparams['l1'],\n",
    "        l2=best_hyperparams['l2'],\n",
    "        input_size=17,\n",
    "        hidden_sizes=best_hyperparams['hidden_size'],\n",
    "        output_size=1,\n",
    "        hidden_activation=best_hyperparams['hidden_activation'],\n",
    "        dropout_rates=[best_hyperparams['dropout_rate']],\n",
    "        use_batch_norm=best_hyperparams['batch_norm']\n",
    "    )\n",
    "batch_size = best_hyperparams['batch_size']\n",
    "learning_rate = best_hyperparams['learning_rate']\n",
    "n_epochs = best_hyperparams['n_epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X_train: (135, 17), y_train: (135, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random', 'val_accuracy': np.float64(0.7925925925925926)}\n",
      "Epoch 0: Train Loss: 0.3398, Acc: 53.37% | Val Loss: 0.3670, Acc: 50.00%\n",
      "Epoch 10: Train Loss: 0.3358, Acc: 53.37% | Val Loss: 0.3450, Acc: 47.06%\n",
      "Epoch 20: Train Loss: 0.2869, Acc: 58.43% | Val Loss: 0.3282, Acc: 55.88%\n",
      "Epoch 30: Train Loss: 0.2693, Acc: 62.10% | Val Loss: 0.3151, Acc: 52.94%\n",
      "Epoch 40: Train Loss: 0.2739, Acc: 62.80% | Val Loss: 0.3071, Acc: 50.00%\n",
      "Epoch 50: Train Loss: 0.2790, Acc: 59.82% | Val Loss: 0.3016, Acc: 47.06%\n",
      "Epoch 60: Train Loss: 0.2716, Acc: 59.82% | Val Loss: 0.2971, Acc: 47.06%\n",
      "Epoch 70: Train Loss: 0.2402, Acc: 63.00% | Val Loss: 0.2948, Acc: 47.06%\n",
      "Epoch 80: Train Loss: 0.2330, Acc: 64.38% | Val Loss: 0.2920, Acc: 50.00%\n",
      "Epoch 90: Train Loss: 0.2555, Acc: 61.71% | Val Loss: 0.2893, Acc: 50.00%\n",
      "Epoch 100: Train Loss: 0.2332, Acc: 63.10% | Val Loss: 0.2870, Acc: 50.00%\n",
      "Epoch 110: Train Loss: 0.2490, Acc: 63.59% | Val Loss: 0.2852, Acc: 50.00%\n",
      "Epoch 120: Train Loss: 0.2362, Acc: 62.80% | Val Loss: 0.2835, Acc: 50.00%\n",
      "Epoch 130: Train Loss: 0.2240, Acc: 64.68% | Val Loss: 0.2827, Acc: 50.00%\n",
      "Epoch 140: Train Loss: 0.2260, Acc: 63.79% | Val Loss: 0.2819, Acc: 47.06%\n",
      "Epoch 150: Train Loss: 0.2256, Acc: 63.29% | Val Loss: 0.2814, Acc: 47.06%\n",
      "Epoch 160: Train Loss: 0.2152, Acc: 65.58% | Val Loss: 0.2801, Acc: 50.00%\n",
      "Epoch 170: Train Loss: 0.2254, Acc: 63.99% | Val Loss: 0.2789, Acc: 50.00%\n",
      "Epoch 180: Train Loss: 0.2233, Acc: 65.38% | Val Loss: 0.2782, Acc: 50.00%\n",
      "Epoch 190: Train Loss: 0.2104, Acc: 67.16% | Val Loss: 0.2772, Acc: 50.00%\n",
      "Epoch 200: Train Loss: 0.2074, Acc: 65.67% | Val Loss: 0.2762, Acc: 52.94%\n",
      "Epoch 210: Train Loss: 0.2129, Acc: 67.86% | Val Loss: 0.2747, Acc: 55.88%\n",
      "Epoch 220: Train Loss: 0.2141, Acc: 67.86% | Val Loss: 0.2729, Acc: 55.88%\n",
      "Epoch 230: Train Loss: 0.2158, Acc: 67.66% | Val Loss: 0.2713, Acc: 55.88%\n",
      "Epoch 240: Train Loss: 0.2098, Acc: 67.66% | Val Loss: 0.2697, Acc: 58.82%\n",
      "Epoch 250: Train Loss: 0.2012, Acc: 66.77% | Val Loss: 0.2678, Acc: 55.88%\n",
      "Epoch 260: Train Loss: 0.2068, Acc: 69.74% | Val Loss: 0.2663, Acc: 58.82%\n",
      "Epoch 270: Train Loss: 0.1941, Acc: 69.25% | Val Loss: 0.2643, Acc: 55.88%\n",
      "Epoch 280: Train Loss: 0.2078, Acc: 66.57% | Val Loss: 0.2622, Acc: 55.88%\n",
      "Epoch 290: Train Loss: 0.2060, Acc: 65.87% | Val Loss: 0.2607, Acc: 58.82%\n",
      "Final Validation Accuracy: 0.6176\n",
      "Test Accuracy: 0.6829\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "loss_function = MSE()\n",
    "optimizer = Optimizer_Adam(learning_rate=learning_rate, decay=best_hyperparams['weight_decay'])\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=30, min_delta_loss=1e-5, min_delta_accuracy=0.001)\n",
    "\n",
    "# Before training loop:\n",
    "print(\"Data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Hyperparams: {best_hyperparams}\")\n",
    "# print(f\"Sample prediction: {model.forward(X_train[:1])}\")\n",
    "# print(f\"Initial loss: {loss_function.forward(model.output, y_train[:1])}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    batch_losses = []\n",
    "    batch_accuracies = []\n",
    "\n",
    "    for X_batch, y_batch in create_batches(X_train, y_train, batch_size):\n",
    "        # Forward pass\n",
    "        model.forward(X_batch, training=True)\n",
    "\n",
    "        # Loss and accuracy\n",
    "        loss = loss_function.forward(model.output, y_batch)\n",
    "        predictions = np.round(model.output.squeeze())\n",
    "        accuracy = np.mean(predictions == y_batch.squeeze())\n",
    "\n",
    "        # Backward pass\n",
    "        loss_function.backward(model.output, y_batch)\n",
    "        dvalues = loss_function.dinputs\n",
    "\n",
    "        assert dvalues.shape == model.output.shape, \\\n",
    "            f\"Gradient shape mismatch: {dvalues.shape} vs {model.output.shape}\"\n",
    "        \n",
    "        i = 0\n",
    "        for layer in reversed(model.layers):\n",
    "            i=-1\n",
    "            layer.backward(dvalues)\n",
    "            dvalues = np.array(layer.dinputs)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.pre_update_params()\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, Layer_Dense):\n",
    "                optimizer.update_params(layer)\n",
    "        optimizer.post_update_params()\n",
    "\n",
    "        batch_losses.append(loss)\n",
    "        batch_accuracies.append(accuracy)\n",
    "\n",
    "    # Epoch summary\n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "    epoch_acc = np.mean(batch_accuracies)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    X_val_input = X_val.values if isinstance(X_val, pd.DataFrame) else X_val\n",
    "    y_val_input = y_val.values if isinstance(y_val, (pd.Series, pd.DataFrame)) else y_val\n",
    "\n",
    "    model.forward(X_val_input, training=False)\n",
    "    val_loss = loss_function.forward(model.output, y_val_input)\n",
    "    val_predictions = np.round(model.output.squeeze())\n",
    "    val_accuracy = np.mean(val_predictions == y_val.squeeze())\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: \", end=\"\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Acc: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "    # Early stopping check\n",
    "    early_stopping.on_epoch_end(\n",
    "        current_loss=val_loss,\n",
    "        current_accuracy=val_accuracy,\n",
    "        model=model,\n",
    "        epoch=epoch\n",
    "    )\n",
    "\n",
    "    if early_stopping.stop_training:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        # Restore best weights\n",
    "        print(f\"Restoring model weights from epoch {early_stopping.best_epoch}\")\n",
    "        early_stopping.restore_weights(model)\n",
    "        # Cascade correlation\n",
    "        if isinstance(model, CascadeCorrelation):\n",
    "            if model.is_limit_reached():\n",
    "                break\n",
    "            \n",
    "            model.add_neuron()\n",
    "            early_stopping.wait = 0\n",
    "            early_stopping.patience -= int(early_stopping.patience / 10)\n",
    "            early_stopping.stop_training = False\n",
    "            print(f\"Added new neuron at epoch {epoch} wiht val_loss {val_losses[-1]:.4f}\")\n",
    "            continue\n",
    "        break\n",
    "\n",
    "# Final evaluation\n",
    "model.forward(X_val_input, training=False)\n",
    "final_val_loss = loss_function.forward(model.output, y_val_input)\n",
    "final_val_accuracy = np.mean(np.round(model.output.squeeze()) == y_val.squeeze())\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Test set evaluation\n",
    "model.forward(X_test, training=False)\n",
    "test_loss = loss_function.forward(model.output.squeeze(), y_test)\n",
    "\n",
    "predictions = np.round(model.output.squeeze())\n",
    "# y_true = np.argmax(y_test, axis=1) if y_test.ndim > 1 else y_test\n",
    "test_accuracy = np.mean(predictions == y_test.squeeze())\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(predictions[:10].squeeze(), y_test[:10].squeeze())\n",
    "# Plot training progress\n",
    "plot_losses(train_losses, val_losses, test_loss,\n",
    "            label1=\"Training Loss\", label2=\"Validation Loss\",\n",
    "            title=\"Loss Over Epochs\")\n",
    "\n",
    "plot_accuracies(train_accuracies, val_accuracies, test_accuracy,\n",
    "                label1=\"Training Accuracies\", label2=\"Validation Accuracies\",\n",
    "                title=\"Accuracy Over Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.3398489716924185), np.float64(0.3223457424042728), np.float64(0.34440461381112797), np.float64(0.31392417824695174), np.float64(0.3360933550499354), np.float64(0.31874702912131186), np.float64(0.3100350228335478), np.float64(0.3227084066746971), np.float64(0.33351366716862374), np.float64(0.3015379887762332), np.float64(0.3357938627392547), np.float64(0.29058363767960743), np.float64(0.3071266944199474), np.float64(0.2951854157305734), np.float64(0.3007386240672425), np.float64(0.3057908267109718), np.float64(0.30377292214149537), np.float64(0.2912677131198914), np.float64(0.28324417993153744), np.float64(0.30711600540327244), np.float64(0.28688871936161536), np.float64(0.2877513172309813), np.float64(0.30472977577153326), np.float64(0.30171866147824894), np.float64(0.3046930292394523), np.float64(0.2940159967133824), np.float64(0.2711737525855775), np.float64(0.3001765179571719), np.float64(0.30351068379332363), np.float64(0.2961673897328168), np.float64(0.2693142401547741), np.float64(0.28895262650088416), np.float64(0.30031909610312535), np.float64(0.2718714227303281), np.float64(0.27612657588968154), np.float64(0.2805109266050846), np.float64(0.2942084466605909), np.float64(0.2781837788813875), np.float64(0.2700420334292055), np.float64(0.2839949183133321), np.float64(0.27393234526823856), np.float64(0.2801157561416345), np.float64(0.2788665127583543), np.float64(0.27819028697740145), np.float64(0.24702703290918715), np.float64(0.2652610880329988), np.float64(0.2399766867183074), np.float64(0.2583864545628558), np.float64(0.2670983352899725), np.float64(0.2690395071123393), np.float64(0.27900846562953785), np.float64(0.2516798868731717), np.float64(0.25643829282856223), np.float64(0.24175459597922228), np.float64(0.2683755851425794), np.float64(0.25132104023379226), np.float64(0.26596875188454283), np.float64(0.26259766737863877), np.float64(0.24294600762997756), np.float64(0.24136002905574325), np.float64(0.27160530143511935), np.float64(0.25528370964111335), np.float64(0.2704152311764261), np.float64(0.24559114761503864), np.float64(0.2377409405883368), np.float64(0.26282450480624137), np.float64(0.2591832558292725), np.float64(0.24800699795691752), np.float64(0.24885018038088402), np.float64(0.2529083010624611), np.float64(0.24019751204302034), np.float64(0.25067374323972796), np.float64(0.2610614811354224), np.float64(0.25232942838006484), np.float64(0.24534974408370333), np.float64(0.24103174186547058), np.float64(0.26827899883174133), np.float64(0.2492079523158848), np.float64(0.25526948490116497), np.float64(0.2501770857514128), np.float64(0.23298777188883035), np.float64(0.2362658049305918), np.float64(0.2522738345297327), np.float64(0.24587473811401622), np.float64(0.24321906827597178), np.float64(0.2381074194664177), np.float64(0.25033187158494213), np.float64(0.235688425514537), np.float64(0.23163509524574108), np.float64(0.23717030108291592), np.float64(0.2554947124706779), np.float64(0.255964624830706), np.float64(0.2368473627612122), np.float64(0.24206734372890365), np.float64(0.24280420770439332), np.float64(0.23619504897864171), np.float64(0.23641830926454846), np.float64(0.24563915452622734), np.float64(0.2349238639005894), np.float64(0.253661945462874), np.float64(0.2331536770893342), np.float64(0.24214876071344835), np.float64(0.22924632438765213), np.float64(0.23405286495851035), np.float64(0.22323586261762415), np.float64(0.23912668260145484), np.float64(0.25418100251687004), np.float64(0.2336280813284347), np.float64(0.2440353562075327), np.float64(0.22769664624579367), np.float64(0.24900217904547894), np.float64(0.24220098452971894), np.float64(0.2313622866064067), np.float64(0.2164491869988495), np.float64(0.24037090193182997), np.float64(0.24405580878949365), np.float64(0.2557634553778676), np.float64(0.23679586837080796), np.float64(0.238058165324157), np.float64(0.22622566292663762), np.float64(0.2361602598582018), np.float64(0.23480653962421064), np.float64(0.23181521730496735), np.float64(0.23584096550047734), np.float64(0.214297141426533), np.float64(0.23071356187224945), np.float64(0.23621572138527855), np.float64(0.228629898151553), np.float64(0.22571506814333395), np.float64(0.23199961988557302), np.float64(0.22403726172544372), np.float64(0.2314607900604335), np.float64(0.2374744979825987), np.float64(0.2302370439883045), np.float64(0.2396028075092865), np.float64(0.22586227164054412), np.float64(0.23811909558560698), np.float64(0.22849973195970094), np.float64(0.2359989942770697), np.float64(0.22715281078599242), np.float64(0.22598867453803914), np.float64(0.22471686480955955), np.float64(0.22472763013699149), np.float64(0.23555703861876054), np.float64(0.23108660060475752), np.float64(0.22595067808548647), np.float64(0.2213867577375382), np.float64(0.23846812074953005), np.float64(0.2282682011760807), np.float64(0.2207044867714147), np.float64(0.22556899755522009), np.float64(0.22557674409759368), np.float64(0.224996962847287), np.float64(0.2170336695090166), np.float64(0.21534363728253417), np.float64(0.22423214410799255), np.float64(0.23337859450651008), np.float64(0.23121788584680406), np.float64(0.22700751047820228), np.float64(0.2191476620749319), np.float64(0.21523415007579655), np.float64(0.21126501677075096), np.float64(0.2106225468256137), np.float64(0.21255809798617264), np.float64(0.21781107760538304), np.float64(0.212345508255321), np.float64(0.21313524025525632), np.float64(0.2302598130619257), np.float64(0.2132974254556014), np.float64(0.2180326645277172), np.float64(0.22540189678555725), np.float64(0.21763362786882434), np.float64(0.22803727809074464), np.float64(0.21639225526421202), np.float64(0.21600357635455447), np.float64(0.219959221125656), np.float64(0.22100062358169903), np.float64(0.20532415809452828), np.float64(0.21741139802743964), np.float64(0.22438751924891814), np.float64(0.22334294821490466), np.float64(0.21974610001849604), np.float64(0.21688441699597727), np.float64(0.22675604435743013), np.float64(0.21639135764840609), np.float64(0.21668666163177772), np.float64(0.2157872071974383), np.float64(0.20885377334875382), np.float64(0.2065799570804366), np.float64(0.2112423503476184), np.float64(0.21042286914077463), np.float64(0.21437800849733407), np.float64(0.21877126886686496), np.float64(0.21366657359671615), np.float64(0.21410226552326334), np.float64(0.20209879165618627), np.float64(0.2016881181061843), np.float64(0.21834170918774054), np.float64(0.20406621068392916), np.float64(0.2083211645565049), np.float64(0.20744916292613252), np.float64(0.2161675033223975), np.float64(0.23503108290963265), np.float64(0.2134250467750723), np.float64(0.20217058962021517), np.float64(0.2152079005735176), np.float64(0.19887516658549728), np.float64(0.2221396322067408), np.float64(0.21538772584876323), np.float64(0.2018666841253555), np.float64(0.21289018134923515), np.float64(0.2105228350019584), np.float64(0.2205996453349695), np.float64(0.21794618067318017), np.float64(0.21106261791459424), np.float64(0.21215627209463253), np.float64(0.21210911129952534), np.float64(0.20895311449168166), np.float64(0.2170850878074157), np.float64(0.19071757212844628), np.float64(0.21407521219562078), np.float64(0.21290009422011702), np.float64(0.21763385736559138), np.float64(0.20965249654827295), np.float64(0.20143623962896326), np.float64(0.209037167374001), np.float64(0.20300211225555437), np.float64(0.21496288507644862), np.float64(0.21943712407732516), np.float64(0.1981613815190393), np.float64(0.21575169158894758), np.float64(0.2064367275769042), np.float64(0.1961201983779538), np.float64(0.20614171232811598), np.float64(0.20821750972170897), np.float64(0.2036202498684463), np.float64(0.21498618040095246), np.float64(0.20030703351381657), np.float64(0.21708748941706324), np.float64(0.21310940016394586), np.float64(0.20976356947514166), np.float64(0.20087224577100138), np.float64(0.2069766970321766), np.float64(0.2007110859116329), np.float64(0.23003619459691865), np.float64(0.21036821649927134), np.float64(0.20714900627505328), np.float64(0.19763041717892096), np.float64(0.21257569170399104), np.float64(0.20567904022778496), np.float64(0.20117348706701735), np.float64(0.19523078749906195), np.float64(0.19911657964488666), np.float64(0.20817907508168043), np.float64(0.19966919694710578), np.float64(0.20107981272721812), np.float64(0.2103052634767087), np.float64(0.20161463694670165), np.float64(0.20551055554708975), np.float64(0.1957335612800244), np.float64(0.2067936666262672), np.float64(0.2178461197918031), np.float64(0.20187093316759824), np.float64(0.19596264474480365), np.float64(0.19178273681408953), np.float64(0.209719048205085), np.float64(0.19331484123023424), np.float64(0.22166725073054097), np.float64(0.20053242791043566), np.float64(0.20925204113937884), np.float64(0.19409709517202883), np.float64(0.18897060477504626), np.float64(0.20722234625119523), np.float64(0.20256593112517227), np.float64(0.202041066801724), np.float64(0.18811023517806033), np.float64(0.1924908070954473), np.float64(0.18139042320252396), np.float64(0.2004055233539376), np.float64(0.20466653680521796), np.float64(0.20781174386495094), np.float64(0.20213261043948766), np.float64(0.1972498777217088), np.float64(0.2006610473626644), np.float64(0.20571504620758554), np.float64(0.20711354119233932), np.float64(0.18810817984272177), np.float64(0.2033307380288189), np.float64(0.20283679521157189), np.float64(0.19598316436253935), np.float64(0.20595247227529245), np.float64(0.20126246967349612), np.float64(0.21004211023810695), np.float64(0.19147926494646306), np.float64(0.19528899505618919), np.float64(0.19065118896272523), np.float64(0.19081715449459447), np.float64(0.19386715021096576), np.float64(0.19402512540678576), np.float64(0.21048045506495736)] [np.float64(0.36697013905522147), np.float64(0.36511843809379907), np.float64(0.362845825911688), np.float64(0.3602049497097642), np.float64(0.35773364626322646), np.float64(0.3550737767278345), np.float64(0.35281370319005334), np.float64(0.3506085419211119), np.float64(0.34873873234085695), np.float64(0.34658047814852894), np.float64(0.34504229795849245), np.float64(0.3433934385026098), np.float64(0.34135068992590634), np.float64(0.33958430600919975), np.float64(0.3381913960445253), np.float64(0.336627350030309), np.float64(0.335042243726056), np.float64(0.33325424276338844), np.float64(0.3314149650391012), np.float64(0.32969891650033123), np.float64(0.3282000009493166), np.float64(0.326766377449876), np.float64(0.3254166004224486), np.float64(0.32357972736457286), np.float64(0.32201293693780064), np.float64(0.3205290975610658), np.float64(0.31949659953063), np.float64(0.3185243620202502), np.float64(0.31715760999829956), np.float64(0.31589698004734185), np.float64(0.31512118286776003), np.float64(0.3141190340951136), np.float64(0.3130176612970772), np.float64(0.31194114627547576), np.float64(0.3109751695790049), np.float64(0.31014540767965487), np.float64(0.3094227492778267), np.float64(0.30891484427763305), np.float64(0.30827332240410754), np.float64(0.3076399689738827), np.float64(0.30707179018005776), np.float64(0.30625230635795747), np.float64(0.30554020481673044), np.float64(0.3047995816427096), np.float64(0.3043766899529673), np.float64(0.30380590852412315), np.float64(0.3035464929746975), np.float64(0.3032515977693212), np.float64(0.3028529934348288), np.float64(0.30227751171413114), np.float64(0.3016240294950954), np.float64(0.301152170978546), np.float64(0.30055384253959977), np.float64(0.3003168279947309), np.float64(0.2998997677236477), np.float64(0.2995007268425954), np.float64(0.298988906170209), np.float64(0.29836317602719337), np.float64(0.29788760657218727), np.float64(0.29755440642482894), np.float64(0.2971038845057112), np.float64(0.2968540143128057), np.float64(0.2964971267880869), np.float64(0.2962236735379173), np.float64(0.29612122221154846), np.float64(0.2959775513542668), np.float64(0.29562793539507853), np.float64(0.295525746791046), np.float64(0.29528225130869024), np.float64(0.295115674713289), np.float64(0.29484873985173043), np.float64(0.29456922112432254), np.float64(0.29434989529044164), np.float64(0.2941348447658303), np.float64(0.29371977571986035), np.float64(0.2933815379663159), np.float64(0.2931969069084183), np.float64(0.2929123417899903), np.float64(0.29283931802873875), np.float64(0.29247513208409265), np.float64(0.2920397251346136), np.float64(0.2918739545995206), np.float64(0.29162342770643207), np.float64(0.29125864844382576), np.float64(0.2909366981208189), np.float64(0.2906975941267585), np.float64(0.2904012739187707), np.float64(0.2900673945422201), np.float64(0.2897759697492082), np.float64(0.28943859418155876), np.float64(0.28925165470697295), np.float64(0.289003413964227), np.float64(0.2888245343504352), np.float64(0.28865284886883286), np.float64(0.28832069039089225), np.float64(0.2880038011751349), np.float64(0.2877310238676881), np.float64(0.2875671448169603), np.float64(0.28737779364285043), np.float64(0.2871136267800197), np.float64(0.2870038759106594), np.float64(0.2867439933018203), np.float64(0.28655443554935495), np.float64(0.28642620157740606), np.float64(0.28633705513255636), np.float64(0.2860565952680152), np.float64(0.2858381033612663), np.float64(0.2856695962090314), np.float64(0.28556013973542965), np.float64(0.2853539190260406), np.float64(0.28517422738836345), np.float64(0.28499701661868276), np.float64(0.28476564280318095), np.float64(0.28458094251909594), np.float64(0.2845218287852493), np.float64(0.28439269034239906), np.float64(0.28422369943122305), np.float64(0.2840190179379232), np.float64(0.2838051084838688), np.float64(0.2837444000587253), np.float64(0.28354760899036424), np.float64(0.28345632370780316), np.float64(0.2832411028076218), np.float64(0.2831677503222337), np.float64(0.2830397234348792), np.float64(0.2829428210290206), np.float64(0.28285931254572), np.float64(0.2828003052167484), np.float64(0.28281420672717705), np.float64(0.2827527767842763), np.float64(0.2827025840904148), np.float64(0.2826371260141445), np.float64(0.2825054580081414), np.float64(0.28242539649819226), np.float64(0.28231529387659593), np.float64(0.28228639925426857), np.float64(0.28225895425598385), np.float64(0.28216308550326724), np.float64(0.2820163773508749), np.float64(0.2819853608116311), np.float64(0.28190066304835937), np.float64(0.281867872281985), np.float64(0.28178342945141605), np.float64(0.28182384519895026), np.float64(0.28182774082711815), np.float64(0.2817283209738322), np.float64(0.2817137664271448), np.float64(0.28159589431795556), np.float64(0.2815094931732369), np.float64(0.28139135259415105), np.float64(0.2813880753930818), np.float64(0.2812847885504009), np.float64(0.28119988798983075), np.float64(0.2811479793667964), np.float64(0.28098460192783103), np.float64(0.28084322733341865), np.float64(0.2806788530106261), np.float64(0.28051077561602106), np.float64(0.28030665565306295), np.float64(0.2802024731771051), np.float64(0.28012129047399953), np.float64(0.2799763546460808), np.float64(0.27983371935015905), np.float64(0.279741110258714), np.float64(0.2796362143162939), np.float64(0.27944827725801497), np.float64(0.2794274557315517), np.float64(0.27932714884400694), np.float64(0.27924190219988093), np.float64(0.27902941441884055), np.float64(0.27894521363240404), np.float64(0.2789140563770967), np.float64(0.2787866523987144), np.float64(0.27874694740443995), np.float64(0.2787010506287886), np.float64(0.2786229933056614), np.float64(0.2784301199480328), np.float64(0.27828839906360464), np.float64(0.2782690026963999), np.float64(0.2783136972303444), np.float64(0.27818491739915563), np.float64(0.278109027238013), np.float64(0.27801932757968834), np.float64(0.2779411814818155), np.float64(0.27781277213395894), np.float64(0.27775347146303764), np.float64(0.2776393114987848), np.float64(0.2775171207230895), np.float64(0.277324958839496), np.float64(0.277240657763595), np.float64(0.2771962260208576), np.float64(0.27717649117820853), np.float64(0.2770716634101262), np.float64(0.2770526585072457), np.float64(0.27703848670014736), np.float64(0.27698521841938545), np.float64(0.27683456427053205), np.float64(0.2767313549529776), np.float64(0.2765864973020364), np.float64(0.27639949164703176), np.float64(0.2762422284336403), np.float64(0.27604265194478766), np.float64(0.275864527026726), np.float64(0.2757326353676855), np.float64(0.27556130048764227), np.float64(0.27539363519343907), np.float64(0.2752431880193178), np.float64(0.2750769067971612), np.float64(0.2750043311354103), np.float64(0.2748880201521166), np.float64(0.2746621599503764), np.float64(0.2744868394327596), np.float64(0.2743437940163027), np.float64(0.2741485556442473), np.float64(0.27400718645874267), np.float64(0.2738395689256482), np.float64(0.273589854198621), np.float64(0.27340098129540363), np.float64(0.273263375848268), np.float64(0.27308421609192646), np.float64(0.2728956457948146), np.float64(0.27277195672012455), np.float64(0.2726858057474527), np.float64(0.2725511208730504), np.float64(0.2724618866041483), np.float64(0.2723033037377692), np.float64(0.2721690597972706), np.float64(0.27188048023168604), np.float64(0.2716377531732366), np.float64(0.2714512792257427), np.float64(0.27130310727090146), np.float64(0.2711520748285843), np.float64(0.27100388994327895), np.float64(0.27089370084924436), np.float64(0.27079580030881195), np.float64(0.2706740725147826), np.float64(0.2705056393327599), np.float64(0.270283212908838), np.float64(0.2700808661598434), np.float64(0.2699330930653309), np.float64(0.26970570488915113), np.float64(0.26950024198009637), np.float64(0.26928634789346967), np.float64(0.2690898282427805), np.float64(0.26889766335188997), np.float64(0.2687588404477185), np.float64(0.2685965040808282), np.float64(0.2684138839835857), np.float64(0.2682459389827426), np.float64(0.2680670233596292), np.float64(0.26782970203280615), np.float64(0.26762457297763403), np.float64(0.26744823225912184), np.float64(0.26727458743425864), np.float64(0.26716904377145073), np.float64(0.26708136849632097), np.float64(0.2669729081688458), np.float64(0.26680286625476846), np.float64(0.2665792505352045), np.float64(0.26641481259409483), np.float64(0.2662662289224933), np.float64(0.2660141993653573), np.float64(0.265732573421097), np.float64(0.2656107375054835), np.float64(0.26537957952493657), np.float64(0.26522793919882964), np.float64(0.26504813743308864), np.float64(0.26485755282004186), np.float64(0.2646943281919172), np.float64(0.26450014040808834), np.float64(0.2642761774402662), np.float64(0.2640788404269355), np.float64(0.26391409341541544), np.float64(0.26372427847366864), np.float64(0.2634494157246041), np.float64(0.26316394618459066), np.float64(0.26293405948019305), np.float64(0.26277905460112344), np.float64(0.2626621796741342), np.float64(0.2624887159942134), np.float64(0.2622214422017222), np.float64(0.2619946318823576), np.float64(0.26182774723834257), np.float64(0.2617050614365784), np.float64(0.2615272771767474), np.float64(0.2614022604632653), np.float64(0.2612174558460735), np.float64(0.2610945558700717), np.float64(0.2609708312399357), np.float64(0.2608375701818451), np.float64(0.26066426601570053), np.float64(0.2604961307326887), np.float64(0.2603342738576882), np.float64(0.26006762359916513), np.float64(0.25983416045622504), np.float64(0.2596840356607551), np.float64(0.2595502501789489), np.float64(0.25941403068674734), np.float64(0.25923403716559273), np.float64(0.2590283724482574)]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8773\n"
     ]
    }
   ],
   "source": [
    "model.forward(X_test, training=False)\n",
    "# Compute softmax probabilities for the test output\n",
    "# print(X_test.shape, y_test.shape)\n",
    "# print(model.output, y_test)\n",
    "loss_function.forward(model.output.squeeze(), y_test)\n",
    "# Calculate accuracy for the test set\n",
    "predictions = np.round(model.output.squeeze())\n",
    "if len(y_test.shape) == 2:\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_true = y_test\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy = np.mean(predictions == y_true)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleNN:\n",
    "    def __init__(self, n_models=5):\n",
    "        self.models = []\n",
    "        self.n_models = n_models\n",
    "        self.loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "        \n",
    "\n",
    "    def create_and_train_models(self, hyperparams):\n",
    "        # Create and train multiple models with the same hyperparameters\n",
    "        for i in range(self.n_models):\n",
    "            model = NN(\n",
    "                l1=hyperparams['l1'],\n",
    "                l2=hyperparams['l2'],\n",
    "                input_size=17,\n",
    "                hidden_sizes=hyperparams['hidden_size'],\n",
    "                output_size=1,\n",
    "                hidden_activation=hidden_activation,\n",
    "                dropout_rates=[hyperparams['dropout_rate']],\n",
    "                use_batch_norm=hyperparams['batch_norm']\n",
    "            )\n",
    "            print(f\"Training model {i+1}/{self.n_models}\")\n",
    "            # Train model using existing train_and_evaluate function\n",
    "            self.train = Train(hyperparams, model)\n",
    "            model, val_accuracy = self.train.train_and_evaluate(\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_val=X_val,\n",
    "                y_val=y_val,\n",
    "            )\n",
    "            self.models.append(model)\n",
    "            print(f\"Model {i+1} validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using majority voting\"\"\"\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            model.forward(X, training=False)\n",
    "            self.loss_activation.forward(\n",
    "                model.output, np.zeros((X.shape[0], 2)))  # Dummy y values\n",
    "            pred = np.argmax(self.loss_activation.output, axis=1)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        # Majority voting\n",
    "        predictions = np.array(predictions)\n",
    "        final_predictions = np.apply_along_axis(\n",
    "            lambda x: np.bincount(x).argmax(),\n",
    "            axis=0,\n",
    "            arr=predictions\n",
    "        )\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] <class 'src.activation_functions.Activation_Leaky_ReLU'> [0.1] [False]\n",
      "Training model 1/5\n",
      "Data shapes:\n",
      "X_train: (135, 17), y_train: (135, 1)\n",
      "Hyperparams: {'hidden_size': [8], 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': [False], 'learning_rate': 0.001, 'l1': 1e-06, 'l2': 0.001, 'dropout_rate': 0.1, 'batch_size': 16, 'n_epochs': 300, 'weight_decay': 0.001, 'patience': 50, 'CC': False, 'weights_init': 'random', 'val_accuracy': np.float64(0.7925925925925926)}\n",
      "Epoch 0: Train Loss: 0.3447, Acc: 54.76% | Val Loss: 0.2979, Acc: 64.71%\n",
      "Epoch 10: Train Loss: 0.2743, Acc: 66.47% | Val Loss: 0.2945, Acc: 61.76%\n",
      "Epoch 20: Train Loss: 0.2497, Acc: 66.77% | Val Loss: 0.2911, Acc: 58.82%\n"
     ]
    }
   ],
   "source": [
    "ensemble = EnsembleNN(n_models=5)\n",
    "\n",
    "ensemble.create_and_train_models(best_hyperparams)\n",
    "\n",
    "_ , test_accuracy = ensemble.train.test(X_test, y_test)\n",
    "\n",
    "print(f\"Ensemble Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "ensemble.train.plot(accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
