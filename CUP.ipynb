{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c44e849b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1f027f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3dfe7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.activation_functions import *\n",
    "from src.loss_functions import *\n",
    "from src.random_search import *\n",
    "from src.batch_normalization import *\n",
    "from src.layer import *\n",
    "from src.early_stopping import *\n",
    "from src.utils import *\n",
    "from src.optimizers import *\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "575e320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.946373</td>\n",
       "      <td>0.307995</td>\n",
       "      <td>0.820058</td>\n",
       "      <td>-0.309386</td>\n",
       "      <td>0.950936</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>-0.093048</td>\n",
       "      <td>-0.029318</td>\n",
       "      <td>0.995230</td>\n",
       "      <td>-1.175176</td>\n",
       "      <td>2.295016</td>\n",
       "      <td>0.223732</td>\n",
       "      <td>-0.011599</td>\n",
       "      <td>-0.503652</td>\n",
       "      <td>-5.564158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.074075</td>\n",
       "      <td>-0.992654</td>\n",
       "      <td>-1.162582</td>\n",
       "      <td>0.997240</td>\n",
       "      <td>-0.074209</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.095561</td>\n",
       "      <td>0.995411</td>\n",
       "      <td>0.675930</td>\n",
       "      <td>3.147029</td>\n",
       "      <td>-0.297508</td>\n",
       "      <td>-0.361982</td>\n",
       "      <td>-0.186246</td>\n",
       "      <td>3.445744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.841384</td>\n",
       "      <td>0.531605</td>\n",
       "      <td>0.810176</td>\n",
       "      <td>-0.534053</td>\n",
       "      <td>0.845451</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.082832</td>\n",
       "      <td>-0.051079</td>\n",
       "      <td>0.995254</td>\n",
       "      <td>-1.069958</td>\n",
       "      <td>2.415989</td>\n",
       "      <td>0.234664</td>\n",
       "      <td>0.170027</td>\n",
       "      <td>-0.344143</td>\n",
       "      <td>-3.675575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.737117</td>\n",
       "      <td>-0.668400</td>\n",
       "      <td>-1.065601</td>\n",
       "      <td>0.671734</td>\n",
       "      <td>0.740793</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.073704</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>0.995038</td>\n",
       "      <td>11.038418</td>\n",
       "      <td>1.003455</td>\n",
       "      <td>-0.100332</td>\n",
       "      <td>-1.032355</td>\n",
       "      <td>-1.184874</td>\n",
       "      <td>15.554511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.987858</td>\n",
       "      <td>-0.119426</td>\n",
       "      <td>-1.072857</td>\n",
       "      <td>0.120013</td>\n",
       "      <td>-0.992772</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.098661</td>\n",
       "      <td>-0.011863</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>14.834930</td>\n",
       "      <td>1.127759</td>\n",
       "      <td>-0.112600</td>\n",
       "      <td>-0.134817</td>\n",
       "      <td>2.047468</td>\n",
       "      <td>20.522760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   1  0.946373  0.307995  0.820058 -0.309386  0.950936 -0.000913 -0.093048   \n",
       "1   2 -0.074075 -0.992654 -1.162582  0.997240 -0.074209 -0.002159 -0.004956   \n",
       "2   3  0.841384  0.531605  0.810176 -0.534053  0.845451 -0.001057 -0.082832   \n",
       "3   4  0.737117 -0.668400 -1.065601  0.671734  0.740793  0.000008  0.073704   \n",
       "4   5 -0.987858 -0.119426 -1.072857  0.120013 -0.992772  0.000064 -0.098661   \n",
       "\n",
       "         8         9          10        11        12        13        14  \\\n",
       "0 -0.029318  0.995230  -1.175176  2.295016  0.223732 -0.011599 -0.503652   \n",
       "1 -0.095561  0.995411   0.675930  3.147029 -0.297508 -0.361982 -0.186246   \n",
       "2 -0.051079  0.995254  -1.069958  2.415989  0.234664  0.170027 -0.344143   \n",
       "3 -0.066844  0.995038  11.038418  1.003455 -0.100332 -1.032355 -1.184874   \n",
       "4 -0.011863  0.995050  14.834930  1.127759 -0.112600 -0.134817  2.047468   \n",
       "\n",
       "          15  \n",
       "0  -5.564158  \n",
       "1   3.445744  \n",
       "2  -3.675575  \n",
       "3  15.554511  \n",
       "4  20.522760  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path = \"../ML_project/data/cup/ML-CUP24-TR.csv\"\n",
    "df_path2 = \"../ML_project/data/cup/ML-CUP24-TS.csv\"\n",
    "\n",
    "# Preview the dataset\n",
    "df = pd.read_csv(df_path, skiprows=7, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3ad00fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"ID\"] + [f'input_{i}' for i in range(12)] + ['target_x', 'target_y', 'target_z']\n",
    "df = df.drop(\"ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f408ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1          2\n",
      "0  -0.421997  0.236717  -7.342594\n",
      "1  -0.283333  0.050838   3.428940\n",
      "2   0.137419  0.030498  -2.907336\n",
      "3   1.758643 -0.886580  16.933458\n",
      "4  -1.091619  0.158737   2.392301\n",
      "5  -0.030139 -0.041892  -0.703612\n",
      "6  -0.537285  0.111040   2.657905\n",
      "7  -0.296103  0.080915   2.885263\n",
      "8  -1.578751 -0.185479  14.876680\n",
      "9   1.155768 -0.025354  12.329478\n",
      "10  0.237865  0.755455   7.693303\n",
      "11  0.880421  0.209778  -8.828166\n",
      "12  0.687578  0.985988  14.896379\n",
      "13  0.762072  0.217130  -9.108539\n",
      "14 -2.156456 -0.696712  20.812513\n",
      "15 -0.494655  0.115973  -5.513408\n",
      "16 -1.620315 -0.362419  17.202943\n",
      "17  0.149752  0.676320   8.854500\n",
      "18 -0.794149 -1.553299  17.377104\n",
      "19 -0.049514  0.745878   8.182392\n",
      "20  2.333131 -0.558883  24.923707\n",
      "21  1.227097  0.381899  14.242438\n",
      "22 -0.740300  0.539295   8.972121\n",
      "23 -1.312315 -1.067413  16.626081\n",
      "24  0.588437  0.455289  -9.114358\n",
      "25 -1.013359 -0.028985   8.870993\n",
      "26  1.082475 -1.512010  18.644240\n",
      "27  0.109942  0.027452  -2.324193\n",
      "28  0.602006  0.084882  -0.530813\n",
      "29  0.714760 -0.968250  11.404483\n",
      "30 -1.834703 -1.432885  22.239871\n",
      "31 -0.389891 -1.593560  17.165242\n",
      "32 -1.225807  0.931367  15.208020\n",
      "33 -1.136326 -2.218823  24.275035\n",
      "34  0.170235 -0.531179  -4.953277\n",
      "35  0.662164 -0.864290  11.928916\n",
      "36 -0.444337  0.379639  -7.851968\n",
      "37 -0.130831  0.941642  -9.006643\n",
      "38  0.201728 -0.187148  -4.138837\n",
      "39  1.574429 -0.745339  19.248727\n",
      "40 -0.529139 -2.301167  23.365477\n",
      "41 -1.750184 -0.047519  -0.107279\n",
      "42 -0.341972 -0.191209   4.300549\n",
      "43  1.143781  1.528815  18.359779\n",
      "44 -0.122708  1.581754  14.061882\n",
      "45 -1.949109 -0.508890  22.318044\n",
      "46  1.087278 -0.535810  11.699753\n",
      "47  0.480836  0.427886   5.048967\n",
      "48 -0.787201  0.176681  -6.322790\n",
      "49  0.847878  0.198636   2.757632             0         1          2\n",
      "0   -0.035279  0.314440   2.480273\n",
      "1    0.010229  0.038111   3.504100\n",
      "2    0.152397 -0.053318  -3.716572\n",
      "3    0.328237 -0.119977  -4.182435\n",
      "4    0.562020 -1.044573  12.244242\n",
      "..        ...       ...        ...\n",
      "195  1.302774 -0.133306  13.349132\n",
      "196 -0.634115 -0.624596  10.122236\n",
      "197  0.655548 -0.063550   7.711853\n",
      "198  0.551904  1.353437  15.577295\n",
      "199  0.913495  0.101263  -9.749162\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, X_scaler, y_scaler = preprocess_data(\n",
    "    df, \n",
    "    target=[\"target_x\", \"target_y\", \"target_z\"],\n",
    "    normalize_type=\"z-score\",\n",
    "    val_ratio=0.2,\n",
    "    regression=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cde649dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 12), (200, 3), (50, 12), (50, 3))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "75c8fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4625dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'hidden_size': [3, 4, 5, 6],\n",
    "    'n_h_layers': [3, 4, 5],\n",
    "    'hidden_activation': [Activation_Tanh, Activation_Leaky_ReLU, Activation_Sigmoid, Activation_ReLU],\n",
    "    'batch_norm': [False],\n",
    "    'learning_rate': np.logspace(-3, -1, num=20).tolist(),\n",
    "    'l1':  np.logspace(-5, -1, num=10).tolist(),\n",
    "    'l2': np.logspace(-5, -1, num=10).tolist(),\n",
    "    'dropout_rate': np.logspace(-5, -1, num=10).tolist(),\n",
    "    'batch_size': [8, 16, 32],\n",
    "    'n_epochs': [50,100],\n",
    "    'weight_decay': np.logspace(-5, -1, num=20).tolist(),\n",
    "    'patience': [10, 30, 50],\n",
    "    'CC': [False],\n",
    "    'weights_init': ['gaussian', 'gaussian_scaled', 'xavier', 'he', 'random'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2700b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.012915496650148827, 'l2': 0.0005994842503189409, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.3364, Acc: -36.62% | Val Loss: 1.3600, Acc: -39.87%\n",
      "Epoch 10: Train Loss: 0.9554, Acc: 1.50% | Val Loss: 1.0034, Acc: -3.20%\n",
      "Epoch 20: Train Loss: 0.8326, Acc: 16.27% | Val Loss: 0.8917, Acc: 8.29%\n",
      "Epoch 30: Train Loss: 0.7816, Acc: 20.87% | Val Loss: 0.8548, Acc: 12.08%\n",
      "Epoch 40: Train Loss: 0.7476, Acc: 24.63% | Val Loss: 0.8221, Acc: 15.45%\n",
      "Epoch 50: Train Loss: 0.7292, Acc: 25.74% | Val Loss: 0.8037, Acc: 17.34%\n",
      "Epoch 60: Train Loss: 0.7184, Acc: 26.77% | Val Loss: 0.7971, Acc: 18.02%\n",
      "Epoch 70: Train Loss: 0.7109, Acc: 27.40% | Val Loss: 0.7928, Acc: 18.46%\n",
      "Epoch 80: Train Loss: 0.7055, Acc: 27.90% | Val Loss: 0.7917, Acc: 18.58%\n",
      "Epoch 90: Train Loss: 0.7003, Acc: 27.92% | Val Loss: 0.7903, Acc: 18.72%\n",
      "Final Validation score: 0.1886\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1886\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.012915496650148827, 'l2': 0.0005994842503189409, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2717, Acc: -36.22% | Val Loss: 1.2639, Acc: -13.48%\n",
      "Epoch 10: Train Loss: 1.1690, Acc: -24.84% | Val Loss: 1.2110, Acc: -8.73%\n",
      "Epoch 20: Train Loss: 1.0510, Acc: -12.66% | Val Loss: 1.1353, Acc: -1.94%\n",
      "Epoch 30: Train Loss: 0.9418, Acc: 0.35% | Val Loss: 1.0629, Acc: 4.57%\n",
      "Epoch 40: Train Loss: 0.8662, Acc: 5.15% | Val Loss: 0.9964, Acc: 10.54%\n",
      "Epoch 50: Train Loss: 0.8224, Acc: 8.22% | Val Loss: 0.9449, Acc: 15.16%\n",
      "Epoch 60: Train Loss: 0.7954, Acc: 15.92% | Val Loss: 0.9019, Acc: 19.02%\n",
      "Epoch 70: Train Loss: 0.7712, Acc: 19.52% | Val Loss: 0.8503, Acc: 23.65%\n",
      "Epoch 80: Train Loss: 0.7484, Acc: 21.39% | Val Loss: 0.8008, Acc: 28.10%\n",
      "Epoch 90: Train Loss: 0.7278, Acc: 22.00% | Val Loss: 0.7601, Acc: 31.75%\n",
      "Final Validation score: 0.3395\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3395\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.012915496650148827, 'l2': 0.0005994842503189409, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1777, Acc: -14.12% | Val Loss: 1.0575, Acc: -43.69%\n",
      "Epoch 10: Train Loss: 0.9677, Acc: 7.03% | Val Loss: 0.9032, Acc: -22.72%\n",
      "Epoch 20: Train Loss: 0.9300, Acc: 9.94% | Val Loss: 0.8426, Acc: -14.50%\n",
      "Epoch 30: Train Loss: 0.8990, Acc: 13.77% | Val Loss: 0.7970, Acc: -8.30%\n",
      "Epoch 40: Train Loss: 0.8709, Acc: 15.32% | Val Loss: 0.7557, Acc: -2.68%\n",
      "Epoch 50: Train Loss: 0.8347, Acc: 19.49% | Val Loss: 0.7069, Acc: 3.95%\n",
      "Epoch 60: Train Loss: 0.7955, Acc: 23.11% | Val Loss: 0.6599, Acc: 10.34%\n",
      "Epoch 70: Train Loss: 0.7612, Acc: 27.18% | Val Loss: 0.6329, Acc: 14.00%\n",
      "Epoch 80: Train Loss: 0.7271, Acc: 29.60% | Val Loss: 0.6113, Acc: 16.93%\n",
      "Epoch 90: Train Loss: 0.7027, Acc: 31.67% | Val Loss: 0.5966, Acc: 18.93%\n",
      "Final Validation score: 0.2017\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2017\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.012915496650148827, 'l2': 0.0005994842503189409, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2688, Acc: -35.00% | Val Loss: 1.4289, Acc: -32.89%\n",
      "Epoch 10: Train Loss: 1.1234, Acc: -17.57% | Val Loss: 1.2965, Acc: -20.58%\n",
      "Epoch 20: Train Loss: 1.0140, Acc: -8.03% | Val Loss: 1.1675, Acc: -8.58%\n",
      "Epoch 30: Train Loss: 0.9310, Acc: 2.45% | Val Loss: 1.0596, Acc: 1.45%\n",
      "Epoch 40: Train Loss: 0.8440, Acc: 9.74% | Val Loss: 0.9420, Acc: 12.39%\n",
      "Epoch 50: Train Loss: 0.7863, Acc: 16.67% | Val Loss: 0.8684, Acc: 19.24%\n",
      "Epoch 60: Train Loss: 0.7576, Acc: 21.96% | Val Loss: 0.8307, Acc: 22.74%\n",
      "Epoch 70: Train Loss: 0.7429, Acc: 21.73% | Val Loss: 0.8126, Acc: 24.42%\n",
      "Epoch 80: Train Loss: 0.7345, Acc: 22.14% | Val Loss: 0.8041, Acc: 25.22%\n",
      "Epoch 90: Train Loss: 0.7295, Acc: 23.53% | Val Loss: 0.8000, Acc: 25.59%\n",
      "Final Validation score: 0.2581\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2581\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.012915496650148827, 'l2': 0.0005994842503189409, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2407, Acc: -31.82% | Val Loss: 1.1438, Acc: -10.70%\n",
      "Epoch 10: Train Loss: 1.0897, Acc: -14.09% | Val Loss: 1.0419, Acc: -0.83%\n",
      "Epoch 20: Train Loss: 1.0009, Acc: -5.45% | Val Loss: 0.9687, Acc: 6.25%\n",
      "Epoch 30: Train Loss: 0.9167, Acc: 5.34% | Val Loss: 0.8984, Acc: 13.05%\n",
      "Epoch 40: Train Loss: 0.8372, Acc: 12.72% | Val Loss: 0.8330, Acc: 19.38%\n",
      "Epoch 50: Train Loss: 0.7628, Acc: 22.05% | Val Loss: 0.7452, Acc: 27.88%\n",
      "Epoch 60: Train Loss: 0.7143, Acc: 25.42% | Val Loss: 0.6917, Acc: 33.06%\n",
      "Epoch 70: Train Loss: 0.6910, Acc: 28.07% | Val Loss: 0.6703, Acc: 35.13%\n",
      "Epoch 80: Train Loss: 0.6748, Acc: 30.21% | Val Loss: 0.6541, Acc: 36.69%\n",
      "Epoch 90: Train Loss: 0.6633, Acc: 30.67% | Val Loss: 0.6424, Acc: 37.82%\n",
      "Final Validation score: 0.3864\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3864\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.2749\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0016681005372000592, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.0087, Acc: -7.11% | Val Loss: 0.9320, Acc: 4.15%\n",
      "Epoch 10: Train Loss: 0.7517, Acc: 20.92% | Val Loss: 0.7987, Acc: 17.85%\n",
      "Epoch 20: Train Loss: 0.7530, Acc: 19.91% | Val Loss: 0.7793, Acc: 19.86%\n",
      "Epoch 30: Train Loss: 0.7474, Acc: 22.15% | Val Loss: 0.7798, Acc: 19.80%\n",
      "Epoch 40: Train Loss: 0.7323, Acc: 23.61% | Val Loss: 0.7773, Acc: 20.05%\n",
      "Final Validation score: 0.1926\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1926\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0016681005372000592, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.0542, Acc: -12.25% | Val Loss: 1.1243, Acc: -0.95%\n",
      "Epoch 10: Train Loss: 0.8196, Acc: 10.86% | Val Loss: 0.9905, Acc: 11.07%\n",
      "Epoch 20: Train Loss: 0.7849, Acc: 16.63% | Val Loss: 0.9770, Acc: 12.28%\n",
      "Epoch 30: Train Loss: 0.7847, Acc: 16.26% | Val Loss: 0.9644, Acc: 13.41%\n",
      "Epoch 40: Train Loss: 0.7942, Acc: 14.55% | Val Loss: 0.9679, Acc: 13.10%\n",
      "Final Validation score: 0.1258\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.1258\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0016681005372000592, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.1713, Acc: -16.57% | Val Loss: 0.7592, Acc: -3.15%\n",
      "Epoch 10: Train Loss: 1.0557, Acc: -5.12% | Val Loss: 0.7680, Acc: -4.35%\n",
      "Epoch 20: Train Loss: 1.0550, Acc: -3.31% | Val Loss: 0.7716, Acc: -4.85%\n",
      "Epoch 30: Train Loss: 1.0567, Acc: -3.71% | Val Loss: 0.7726, Acc: -4.98%\n",
      "Early stopping at epoch 31\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0474\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0474\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0016681005372000592, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.0037, Acc: -6.90% | Val Loss: 1.0812, Acc: -0.56%\n",
      "Epoch 10: Train Loss: 0.9732, Acc: -3.29% | Val Loss: 1.0879, Acc: -1.18%\n",
      "Epoch 20: Train Loss: 0.9733, Acc: -4.01% | Val Loss: 1.0892, Acc: -1.30%\n",
      "Epoch 30: Train Loss: 0.9730, Acc: -3.65% | Val Loss: 1.0887, Acc: -1.25%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0125\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0125\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0016681005372000592, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.0689, Acc: -20.51% | Val Loss: 1.0451, Acc: -1.15%\n",
      "Epoch 10: Train Loss: 0.8047, Acc: 15.79% | Val Loss: 0.8844, Acc: 14.41%\n",
      "Epoch 20: Train Loss: 0.7705, Acc: 16.68% | Val Loss: 0.8227, Acc: 20.38%\n",
      "Epoch 30: Train Loss: 0.8465, Acc: 9.60% | Val Loss: 0.8879, Acc: 14.07%\n",
      "Epoch 40: Train Loss: 0.8449, Acc: 7.31% | Val Loss: 0.8877, Acc: 14.09%\n",
      "Early stopping at epoch 49\n",
      "Restoring model weights from epoch 19\n",
      "Final Validation score: 0.1391\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.1391\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.0795\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2918, Acc: -29.94% | Val Loss: 1.2605, Acc: -29.64%\n",
      "Epoch 10: Train Loss: 0.9261, Acc: 7.05% | Val Loss: 0.9694, Acc: 0.30%\n",
      "Epoch 20: Train Loss: 0.8530, Acc: 13.50% | Val Loss: 0.8721, Acc: 10.31%\n",
      "Epoch 30: Train Loss: 0.8295, Acc: 14.43% | Val Loss: 0.8591, Acc: 11.65%\n",
      "Epoch 40: Train Loss: 0.8216, Acc: 16.67% | Val Loss: 0.8483, Acc: 12.75%\n",
      "Final Validation score: 0.1395\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1395\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1423, Acc: -21.25% | Val Loss: 1.0971, Acc: 1.50%\n",
      "Epoch 10: Train Loss: 0.7436, Acc: 21.88% | Val Loss: 0.8711, Acc: 21.79%\n",
      "Epoch 20: Train Loss: 0.7297, Acc: 22.43% | Val Loss: 0.8554, Acc: 23.20%\n",
      "Epoch 30: Train Loss: 0.7171, Acc: 24.98% | Val Loss: 0.8437, Acc: 24.25%\n",
      "Epoch 40: Train Loss: 0.7174, Acc: 25.08% | Val Loss: 0.8382, Acc: 24.75%\n",
      "Final Validation score: 0.2485\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.2485\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2521, Acc: -18.47% | Val Loss: 0.9495, Acc: -29.02%\n",
      "Epoch 10: Train Loss: 0.7812, Acc: 25.84% | Val Loss: 0.5950, Acc: 19.16%\n",
      "Epoch 20: Train Loss: 0.7362, Acc: 29.69% | Val Loss: 0.5446, Acc: 25.99%\n",
      "Epoch 30: Train Loss: 0.7057, Acc: 33.10% | Val Loss: 0.5505, Acc: 25.20%\n",
      "Epoch 40: Train Loss: 0.7022, Acc: 33.17% | Val Loss: 0.5422, Acc: 26.33%\n",
      "Final Validation score: 0.2680\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2680\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1933, Acc: -23.55% | Val Loss: 1.3585, Acc: -26.35%\n",
      "Epoch 10: Train Loss: 0.8656, Acc: 9.78% | Val Loss: 1.0200, Acc: 5.14%\n",
      "Epoch 20: Train Loss: 0.8406, Acc: 12.67% | Val Loss: 0.9945, Acc: 7.51%\n",
      "Epoch 30: Train Loss: 0.7649, Acc: 20.30% | Val Loss: 0.9011, Acc: 16.20%\n",
      "Epoch 40: Train Loss: 0.7189, Acc: 25.62% | Val Loss: 0.8633, Acc: 19.71%\n",
      "Final Validation score: 0.2154\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2154\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1589, Acc: -18.40% | Val Loss: 1.0822, Acc: -4.74%\n",
      "Epoch 10: Train Loss: 0.7108, Acc: 25.47% | Val Loss: 0.7283, Acc: 29.51%\n",
      "Epoch 20: Train Loss: 0.7122, Acc: 26.75% | Val Loss: 0.6707, Acc: 35.08%\n",
      "Epoch 30: Train Loss: 0.6592, Acc: 32.09% | Val Loss: 0.6283, Acc: 39.19%\n",
      "Epoch 40: Train Loss: 0.6433, Acc: 33.69% | Val Loss: 0.6142, Acc: 40.56%\n",
      "Final Validation score: 0.4112\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4112\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.2565\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.0005994842503189409, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1510, Acc: -16.20% | Val Loss: 1.0673, Acc: -9.77%\n",
      "Epoch 10: Train Loss: 0.9146, Acc: 7.54% | Val Loss: 0.9201, Acc: 5.37%\n",
      "Epoch 20: Train Loss: 0.8330, Acc: 14.34% | Val Loss: 0.8513, Acc: 12.44%\n",
      "Epoch 30: Train Loss: 0.8076, Acc: 19.16% | Val Loss: 0.8316, Acc: 14.47%\n",
      "Epoch 40: Train Loss: 0.7984, Acc: 19.76% | Val Loss: 0.8245, Acc: 15.20%\n",
      "Epoch 50: Train Loss: 0.7947, Acc: 19.47% | Val Loss: 0.8215, Acc: 15.51%\n",
      "Epoch 60: Train Loss: 0.7859, Acc: 21.36% | Val Loss: 0.8138, Acc: 16.30%\n",
      "Epoch 70: Train Loss: 0.7801, Acc: 20.72% | Val Loss: 0.8157, Acc: 16.11%\n",
      "Epoch 80: Train Loss: 0.7739, Acc: 21.03% | Val Loss: 0.8171, Acc: 15.97%\n",
      "Epoch 90: Train Loss: 0.7918, Acc: 20.80% | Val Loss: 0.8160, Acc: 16.08%\n",
      "Final Validation score: 0.1576\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1576\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.0005994842503189409, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1247, Acc: -20.00% | Val Loss: 1.1492, Acc: -3.18%\n",
      "Epoch 10: Train Loss: 0.9002, Acc: 6.08% | Val Loss: 1.0553, Acc: 5.25%\n",
      "Epoch 20: Train Loss: 0.8398, Acc: 12.82% | Val Loss: 1.0187, Acc: 8.54%\n",
      "Epoch 30: Train Loss: 0.8125, Acc: 15.40% | Val Loss: 0.9845, Acc: 11.60%\n",
      "Epoch 40: Train Loss: 0.8021, Acc: 15.69% | Val Loss: 0.9783, Acc: 12.16%\n",
      "Epoch 50: Train Loss: 0.7903, Acc: 17.32% | Val Loss: 0.9589, Acc: 13.90%\n",
      "Epoch 60: Train Loss: 0.7946, Acc: 17.30% | Val Loss: 0.9677, Acc: 13.11%\n",
      "Epoch 70: Train Loss: 0.7906, Acc: 18.45% | Val Loss: 0.9445, Acc: 15.20%\n",
      "Epoch 80: Train Loss: 0.7896, Acc: 16.43% | Val Loss: 0.9531, Acc: 14.42%\n",
      "Epoch 90: Train Loss: 0.7929, Acc: 17.53% | Val Loss: 0.9555, Acc: 14.21%\n",
      "Final Validation score: 0.1454\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.1454\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.0005994842503189409, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1875, Acc: -14.05% | Val Loss: 0.7658, Acc: -4.06%\n",
      "Epoch 10: Train Loss: 0.8900, Acc: 15.89% | Val Loss: 0.6710, Acc: 8.83%\n",
      "Epoch 20: Train Loss: 0.7979, Acc: 24.47% | Val Loss: 0.6617, Acc: 10.08%\n",
      "Epoch 30: Train Loss: 0.7906, Acc: 23.60% | Val Loss: 0.6688, Acc: 9.13%\n",
      "Epoch 40: Train Loss: 0.8028, Acc: 22.96% | Val Loss: 0.6709, Acc: 8.84%\n",
      "Early stopping at epoch 48\n",
      "Restoring model weights from epoch 18\n",
      "Final Validation score: 0.0865\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.0865\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.0005994842503189409, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1074, Acc: -14.87% | Val Loss: 1.1350, Acc: -5.55%\n",
      "Epoch 10: Train Loss: 0.9602, Acc: 0.40% | Val Loss: 1.0577, Acc: 1.63%\n",
      "Epoch 20: Train Loss: 0.8650, Acc: 10.72% | Val Loss: 0.9158, Acc: 14.83%\n",
      "Epoch 30: Train Loss: 0.8589, Acc: 11.17% | Val Loss: 0.9101, Acc: 15.36%\n",
      "Epoch 40: Train Loss: 0.8085, Acc: 16.19% | Val Loss: 0.8787, Acc: 18.28%\n",
      "Epoch 50: Train Loss: 0.7955, Acc: 17.65% | Val Loss: 0.8358, Acc: 22.27%\n",
      "Epoch 60: Train Loss: 0.7809, Acc: 19.49% | Val Loss: 0.8311, Acc: 22.71%\n",
      "Epoch 70: Train Loss: 0.7901, Acc: 18.41% | Val Loss: 0.8290, Acc: 22.90%\n",
      "Epoch 80: Train Loss: 0.7831, Acc: 19.09% | Val Loss: 0.8277, Acc: 23.02%\n",
      "Epoch 90: Train Loss: 0.7705, Acc: 19.45% | Val Loss: 0.8260, Acc: 23.18%\n",
      "Final Validation score: 0.2279\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2279\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.0005994842503189409, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1730, Acc: -22.52% | Val Loss: 1.0578, Acc: -2.38%\n",
      "Epoch 10: Train Loss: 0.8352, Acc: 14.55% | Val Loss: 0.8498, Acc: 17.75%\n",
      "Epoch 20: Train Loss: 0.7902, Acc: 18.79% | Val Loss: 0.7575, Acc: 26.69%\n",
      "Epoch 30: Train Loss: 0.7911, Acc: 18.76% | Val Loss: 0.7311, Acc: 29.24%\n",
      "Epoch 40: Train Loss: 0.7625, Acc: 22.10% | Val Loss: 0.7134, Acc: 30.95%\n",
      "Epoch 50: Train Loss: 0.7502, Acc: 23.65% | Val Loss: 0.6992, Acc: 32.33%\n",
      "Epoch 60: Train Loss: 0.7386, Acc: 21.59% | Val Loss: 0.6937, Acc: 32.86%\n",
      "Epoch 70: Train Loss: 0.7321, Acc: 24.94% | Val Loss: 0.6862, Acc: 33.59%\n",
      "Epoch 80: Train Loss: 0.7198, Acc: 25.83% | Val Loss: 0.6707, Acc: 35.09%\n",
      "Epoch 90: Train Loss: 0.7311, Acc: 24.51% | Val Loss: 0.6593, Acc: 36.19%\n",
      "Final Validation score: 0.3673\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3673\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.1969\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.03593813663804626, 'l2': 0.0005994842503189409, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 2.6366508987303556e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2935, Acc: -30.69% | Val Loss: 1.3562, Acc: -39.48%\n",
      "Epoch 10: Train Loss: 1.2038, Acc: -21.99% | Val Loss: 1.2532, Acc: -28.89%\n",
      "Epoch 20: Train Loss: 1.1424, Acc: -15.09% | Val Loss: 1.1819, Acc: -21.56%\n",
      "Epoch 30: Train Loss: 1.1040, Acc: -11.98% | Val Loss: 1.1357, Acc: -16.81%\n",
      "Epoch 40: Train Loss: 1.0777, Acc: -9.04% | Val Loss: 1.1049, Acc: -13.63%\n",
      "Final Validation score: -0.1150\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.1150\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.03593813663804626, 'l2': 0.0005994842503189409, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 2.6366508987303556e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.4990, Acc: -57.07% | Val Loss: 1.5049, Acc: -35.11%\n",
      "Epoch 10: Train Loss: 1.4285, Acc: -48.25% | Val Loss: 1.4443, Acc: -29.67%\n",
      "Epoch 20: Train Loss: 1.3305, Acc: -40.56% | Val Loss: 1.3642, Acc: -22.49%\n",
      "Epoch 30: Train Loss: 1.2140, Acc: -27.32% | Val Loss: 1.2785, Acc: -14.79%\n",
      "Epoch 40: Train Loss: 1.1334, Acc: -18.47% | Val Loss: 1.2256, Acc: -10.04%\n",
      "Final Validation score: -0.0781\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0781\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.03593813663804626, 'l2': 0.0005994842503189409, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 2.6366508987303556e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.4814, Acc: -41.05% | Val Loss: 1.3687, Acc: -85.98%\n",
      "Epoch 10: Train Loss: 1.3982, Acc: -38.06% | Val Loss: 1.2754, Acc: -73.30%\n",
      "Epoch 20: Train Loss: 1.3259, Acc: -26.03% | Val Loss: 1.1895, Acc: -61.62%\n",
      "Epoch 30: Train Loss: 1.2662, Acc: -22.12% | Val Loss: 1.1112, Acc: -50.99%\n",
      "Epoch 40: Train Loss: 1.2130, Acc: -17.03% | Val Loss: 1.0404, Acc: -41.37%\n",
      "Final Validation score: -0.3425\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.3425\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.03593813663804626, 'l2': 0.0005994842503189409, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 2.6366508987303556e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2224, Acc: -26.08% | Val Loss: 1.3876, Acc: -29.05%\n",
      "Epoch 10: Train Loss: 1.1682, Acc: -21.43% | Val Loss: 1.3216, Acc: -22.91%\n",
      "Epoch 20: Train Loss: 1.1249, Acc: -16.78% | Val Loss: 1.2687, Acc: -17.99%\n",
      "Epoch 30: Train Loss: 1.0907, Acc: -12.97% | Val Loss: 1.2286, Acc: -14.27%\n",
      "Epoch 40: Train Loss: 1.0649, Acc: -10.49% | Val Loss: 1.1988, Acc: -11.49%\n",
      "Final Validation score: -0.0960\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0960\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 0.03593813663804626, 'l2': 0.0005994842503189409, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 2.6366508987303556e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.3496, Acc: -43.03% | Val Loss: 1.3224, Acc: -27.99%\n",
      "Epoch 10: Train Loss: 1.2696, Acc: -31.69% | Val Loss: 1.2608, Acc: -22.02%\n",
      "Epoch 20: Train Loss: 1.2041, Acc: -24.12% | Val Loss: 1.2050, Acc: -16.62%\n",
      "Epoch 30: Train Loss: 1.1442, Acc: -18.38% | Val Loss: 1.1573, Acc: -12.00%\n",
      "Epoch 40: Train Loss: 1.1021, Acc: -13.58% | Val Loss: 1.1223, Acc: -8.62%\n",
      "Final Validation score: -0.0655\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0655\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.1394\n",
      "3 <class 'src.activation_functions.Activation_Tanh'> 0.1 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 1e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2166, Acc: -22.80% | Val Loss: 1.2587, Acc: -29.45%\n",
      "Epoch 10: Train Loss: 1.0105, Acc: -2.19% | Val Loss: 1.0082, Acc: -3.69%\n",
      "Epoch 20: Train Loss: 1.0020, Acc: -1.40% | Val Loss: 0.9878, Acc: -1.60%\n",
      "Epoch 30: Train Loss: 0.9983, Acc: -0.52% | Val Loss: 0.9843, Acc: -1.23%\n",
      "Epoch 40: Train Loss: 0.9977, Acc: -0.37% | Val Loss: 0.9828, Acc: -1.07%\n",
      "Final Validation score: -0.0099\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0099\n",
      "3 <class 'src.activation_functions.Activation_Tanh'> 0.1 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 1e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2212, Acc: -29.90% | Val Loss: 1.2317, Acc: -10.59%\n",
      "Epoch 10: Train Loss: 0.9810, Acc: -3.17% | Val Loss: 1.1177, Acc: -0.35%\n",
      "Early stopping at epoch 17\n",
      "Restoring model weights from epoch 7\n",
      "Final Validation score: -0.0062\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0062\n",
      "3 <class 'src.activation_functions.Activation_Tanh'> 0.1 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 1e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2730, Acc: -21.05% | Val Loss: 1.0294, Acc: -39.87%\n",
      "Epoch 10: Train Loss: 1.0663, Acc: -2.26% | Val Loss: 0.7752, Acc: -5.33%\n",
      "Epoch 20: Train Loss: 1.0661, Acc: -1.45% | Val Loss: 0.7678, Acc: -4.33%\n",
      "Epoch 30: Train Loss: 1.0525, Acc: 0.26% | Val Loss: 0.7667, Acc: -4.17%\n",
      "Epoch 40: Train Loss: 1.0540, Acc: -0.11% | Val Loss: 0.7672, Acc: -4.24%\n",
      "Early stopping at epoch 43\n",
      "Restoring model weights from epoch 33\n",
      "Final Validation score: -0.0418\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0418\n",
      "3 <class 'src.activation_functions.Activation_Tanh'> 0.1 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 1e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1767, Acc: -21.45% | Val Loss: 1.3389, Acc: -24.52%\n",
      "Epoch 10: Train Loss: 0.9732, Acc: -0.14% | Val Loss: 1.1032, Acc: -2.60%\n",
      "Epoch 20: Train Loss: 0.9720, Acc: -0.53% | Val Loss: 1.0949, Acc: -1.83%\n",
      "Epoch 30: Train Loss: 0.9752, Acc: -0.33% | Val Loss: 1.0920, Acc: -1.56%\n",
      "Epoch 40: Train Loss: 0.9764, Acc: -0.68% | Val Loss: 1.0903, Acc: -1.40%\n",
      "Final Validation score: -0.0132\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0132\n",
      "3 <class 'src.activation_functions.Activation_Tanh'> 0.1 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.1, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 1e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2384, Acc: -28.78% | Val Loss: 1.1482, Acc: -11.12%\n",
      "Epoch 10: Train Loss: 0.9885, Acc: -1.25% | Val Loss: 1.0531, Acc: -1.92%\n",
      "Epoch 20: Train Loss: 0.9911, Acc: -2.21% | Val Loss: 1.0486, Acc: -1.49%\n",
      "Epoch 30: Train Loss: 0.9823, Acc: -0.77% | Val Loss: 1.0489, Acc: -1.52%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 20\n",
      "Final Validation score: -0.0152\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0152\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0173\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.3807, Acc: -43.23% | Val Loss: 1.4580, Acc: -49.95%\n",
      "Epoch 10: Train Loss: 1.2080, Acc: -22.80% | Val Loss: 1.2638, Acc: -29.97%\n",
      "Epoch 20: Train Loss: 1.1053, Acc: -12.49% | Val Loss: 1.1398, Acc: -17.22%\n",
      "Epoch 30: Train Loss: 1.0503, Acc: -5.34% | Val Loss: 1.0705, Acc: -10.10%\n",
      "Epoch 40: Train Loss: 1.0273, Acc: -3.70% | Val Loss: 1.0376, Acc: -6.72%\n",
      "Epoch 50: Train Loss: 1.0157, Acc: -2.54% | Val Loss: 1.0205, Acc: -4.95%\n",
      "Epoch 60: Train Loss: 1.0102, Acc: -1.66% | Val Loss: 1.0108, Acc: -3.96%\n",
      "Epoch 70: Train Loss: 1.0065, Acc: -1.95% | Val Loss: 1.0049, Acc: -3.35%\n",
      "Epoch 80: Train Loss: 1.0050, Acc: -1.17% | Val Loss: 1.0008, Acc: -2.93%\n",
      "Epoch 90: Train Loss: 1.0038, Acc: -1.54% | Val Loss: 0.9980, Acc: -2.64%\n",
      "Final Validation score: -0.0245\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0245\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2448, Acc: -32.70% | Val Loss: 1.2343, Acc: -10.82%\n",
      "Epoch 10: Train Loss: 1.0286, Acc: -8.81% | Val Loss: 1.1179, Acc: -0.37%\n",
      "Epoch 20: Train Loss: 0.9888, Acc: -3.48% | Val Loss: 1.1112, Acc: 0.23%\n",
      "Epoch 30: Train Loss: 0.9812, Acc: -2.33% | Val Loss: 1.1121, Acc: 0.15%\n",
      "Epoch 40: Train Loss: 0.9741, Acc: -3.11% | Val Loss: 1.1131, Acc: 0.06%\n",
      "Early stopping at epoch 49\n",
      "Restoring model weights from epoch 19\n",
      "Final Validation score: -0.0003\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0003\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.3331, Acc: -27.58% | Val Loss: 1.0941, Acc: -48.67%\n",
      "Epoch 10: Train Loss: 1.1696, Acc: -11.30% | Val Loss: 0.9057, Acc: -23.07%\n",
      "Epoch 20: Train Loss: 1.1041, Acc: -4.59% | Val Loss: 0.8328, Acc: -13.16%\n",
      "Epoch 30: Train Loss: 1.0799, Acc: -3.85% | Val Loss: 0.8058, Acc: -9.49%\n",
      "Epoch 40: Train Loss: 1.0701, Acc: -1.87% | Val Loss: 0.7927, Acc: -7.71%\n",
      "Epoch 50: Train Loss: 1.0658, Acc: -1.65% | Val Loss: 0.7863, Acc: -6.84%\n",
      "Epoch 60: Train Loss: 1.0637, Acc: -1.00% | Val Loss: 0.7821, Acc: -6.27%\n",
      "Epoch 70: Train Loss: 1.0614, Acc: -0.87% | Val Loss: 0.7793, Acc: -5.90%\n",
      "Epoch 80: Train Loss: 1.0604, Acc: -0.80% | Val Loss: 0.7776, Acc: -5.66%\n",
      "Epoch 90: Train Loss: 1.0595, Acc: -0.79% | Val Loss: 0.7765, Acc: -5.51%\n",
      "Final Validation score: -0.0534\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0534\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.1799, Acc: -23.98% | Val Loss: 1.3475, Acc: -25.32%\n",
      "Epoch 10: Train Loss: 1.0225, Acc: -5.42% | Val Loss: 1.1612, Acc: -7.99%\n",
      "Epoch 20: Train Loss: 0.9910, Acc: -3.23% | Val Loss: 1.1220, Acc: -4.35%\n",
      "Epoch 30: Train Loss: 0.9847, Acc: -3.05% | Val Loss: 1.1106, Acc: -3.28%\n",
      "Epoch 40: Train Loss: 0.9795, Acc: -1.21% | Val Loss: 1.1050, Acc: -2.77%\n",
      "Epoch 50: Train Loss: 0.9777, Acc: -3.02% | Val Loss: 1.1019, Acc: -2.48%\n",
      "Epoch 60: Train Loss: 0.9770, Acc: -2.32% | Val Loss: 1.1000, Acc: -2.30%\n",
      "Epoch 70: Train Loss: 0.9769, Acc: -1.22% | Val Loss: 1.0987, Acc: -2.19%\n",
      "Epoch 80: Train Loss: 0.9754, Acc: -1.58% | Val Loss: 1.0977, Acc: -2.08%\n",
      "Epoch 90: Train Loss: 0.9747, Acc: -0.86% | Val Loss: 1.0970, Acc: -2.03%\n",
      "Final Validation score: -0.0198\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0198\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.3470, Acc: -37.63% | Val Loss: 1.1723, Acc: -13.46%\n",
      "Epoch 10: Train Loss: 1.1223, Acc: -15.65% | Val Loss: 1.0714, Acc: -3.69%\n",
      "Epoch 20: Train Loss: 1.0476, Acc: -8.05% | Val Loss: 1.0429, Acc: -0.94%\n",
      "Epoch 30: Train Loss: 1.0175, Acc: -9.27% | Val Loss: 1.0336, Acc: -0.03%\n",
      "Epoch 40: Train Loss: 1.0077, Acc: -3.86% | Val Loss: 1.0315, Acc: 0.17%\n",
      "Epoch 50: Train Loss: 1.0007, Acc: -3.68% | Val Loss: 1.0315, Acc: 0.17%\n",
      "Epoch 60: Train Loss: 0.9965, Acc: -1.91% | Val Loss: 1.0321, Acc: 0.11%\n",
      "Epoch 70: Train Loss: 0.9940, Acc: -1.69% | Val Loss: 1.0331, Acc: 0.02%\n",
      "Early stopping at epoch 73\n",
      "Restoring model weights from epoch 43\n",
      "Final Validation score: -0.0001\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0001\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0196\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 0.0016681005372000592, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.1, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0680, Acc: -15.63% | Val Loss: 1.0541, Acc: -8.41%\n",
      "Epoch 10: Train Loss: 0.8599, Acc: 7.97% | Val Loss: 0.8936, Acc: 8.10%\n",
      "Epoch 20: Train Loss: 0.8244, Acc: 11.30% | Val Loss: 0.8579, Acc: 11.77%\n",
      "Epoch 30: Train Loss: 0.8057, Acc: 16.55% | Val Loss: 0.8393, Acc: 13.68%\n",
      "Epoch 40: Train Loss: 0.7936, Acc: 17.10% | Val Loss: 0.8273, Acc: 14.91%\n",
      "Epoch 50: Train Loss: 0.7848, Acc: 15.37% | Val Loss: 0.8188, Acc: 15.78%\n",
      "Epoch 60: Train Loss: 0.7800, Acc: 19.88% | Val Loss: 0.8124, Acc: 16.45%\n",
      "Epoch 70: Train Loss: 0.7729, Acc: 16.83% | Val Loss: 0.8072, Acc: 16.98%\n",
      "Epoch 80: Train Loss: 0.7687, Acc: 17.43% | Val Loss: 0.8029, Acc: 17.42%\n",
      "Epoch 90: Train Loss: 0.7642, Acc: 17.73% | Val Loss: 0.7993, Acc: 17.79%\n",
      "Final Validation score: 0.1809\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1809\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 0.0016681005372000592, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.1, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1751, Acc: -32.21% | Val Loss: 1.2041, Acc: -8.11%\n",
      "Epoch 10: Train Loss: 0.8995, Acc: 4.49% | Val Loss: 0.9387, Acc: 15.72%\n",
      "Epoch 20: Train Loss: 0.8556, Acc: 3.20% | Val Loss: 0.8851, Acc: 20.53%\n",
      "Epoch 30: Train Loss: 0.8348, Acc: 6.84% | Val Loss: 0.8593, Acc: 22.85%\n",
      "Epoch 40: Train Loss: 0.8221, Acc: 6.04% | Val Loss: 0.8432, Acc: 24.29%\n",
      "Epoch 50: Train Loss: 0.8124, Acc: 12.67% | Val Loss: 0.8318, Acc: 25.31%\n",
      "Epoch 60: Train Loss: 0.8046, Acc: 12.11% | Val Loss: 0.8232, Acc: 26.09%\n",
      "Epoch 70: Train Loss: 0.7987, Acc: 10.38% | Val Loss: 0.8162, Acc: 26.71%\n",
      "Epoch 80: Train Loss: 0.7934, Acc: 10.44% | Val Loss: 0.8104, Acc: 27.23%\n",
      "Epoch 90: Train Loss: 0.7890, Acc: 9.13% | Val Loss: 0.8055, Acc: 27.68%\n",
      "Final Validation score: 0.2804\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.2804\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 0.0016681005372000592, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.1, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0980, Acc: -7.89% | Val Loss: 0.7685, Acc: -4.43%\n",
      "Epoch 10: Train Loss: 0.8730, Acc: 12.38% | Val Loss: 0.6158, Acc: 16.33%\n",
      "Epoch 20: Train Loss: 0.8470, Acc: 17.01% | Val Loss: 0.5985, Acc: 18.68%\n",
      "Epoch 30: Train Loss: 0.8319, Acc: 18.06% | Val Loss: 0.5908, Acc: 19.73%\n",
      "Epoch 40: Train Loss: 0.8218, Acc: 20.30% | Val Loss: 0.5862, Acc: 20.35%\n",
      "Epoch 50: Train Loss: 0.8154, Acc: 18.57% | Val Loss: 0.5829, Acc: 20.80%\n",
      "Epoch 60: Train Loss: 0.8100, Acc: 21.02% | Val Loss: 0.5804, Acc: 21.13%\n",
      "Epoch 70: Train Loss: 0.8039, Acc: 21.31% | Val Loss: 0.5784, Acc: 21.40%\n",
      "Epoch 80: Train Loss: 0.7998, Acc: 21.22% | Val Loss: 0.5768, Acc: 21.62%\n",
      "Epoch 90: Train Loss: 0.7961, Acc: 22.51% | Val Loss: 0.5754, Acc: 21.81%\n",
      "Final Validation score: 0.2196\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2196\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 0.0016681005372000592, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.1, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0439, Acc: -11.66% | Val Loss: 1.1719, Acc: -8.99%\n",
      "Epoch 10: Train Loss: 0.8445, Acc: 10.49% | Val Loss: 1.0314, Acc: 4.07%\n",
      "Epoch 20: Train Loss: 0.8163, Acc: 14.58% | Val Loss: 1.0003, Acc: 6.97%\n",
      "Epoch 30: Train Loss: 0.8016, Acc: 13.29% | Val Loss: 0.9820, Acc: 8.67%\n",
      "Epoch 40: Train Loss: 0.7913, Acc: 15.65% | Val Loss: 0.9692, Acc: 9.86%\n",
      "Epoch 50: Train Loss: 0.7844, Acc: 14.47% | Val Loss: 0.9593, Acc: 10.79%\n",
      "Epoch 60: Train Loss: 0.7777, Acc: 13.94% | Val Loss: 0.9511, Acc: 11.54%\n",
      "Epoch 70: Train Loss: 0.7733, Acc: 17.92% | Val Loss: 0.9443, Acc: 12.17%\n",
      "Epoch 80: Train Loss: 0.7687, Acc: 18.23% | Val Loss: 0.9385, Acc: 12.72%\n",
      "Epoch 90: Train Loss: 0.7646, Acc: 18.68% | Val Loss: 0.9333, Acc: 13.20%\n",
      "Final Validation score: 0.1358\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.1358\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.004281332398719396, 'l1': 0.0016681005372000592, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.1, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.3630, Acc: -49.60% | Val Loss: 1.2355, Acc: -19.57%\n",
      "Epoch 10: Train Loss: 0.8649, Acc: 5.98% | Val Loss: 0.8336, Acc: 19.32%\n",
      "Epoch 20: Train Loss: 0.8203, Acc: 10.99% | Val Loss: 0.8037, Acc: 22.22%\n",
      "Epoch 30: Train Loss: 0.8041, Acc: 9.32% | Val Loss: 0.7867, Acc: 23.86%\n",
      "Epoch 40: Train Loss: 0.7938, Acc: 14.71% | Val Loss: 0.7765, Acc: 24.85%\n",
      "Epoch 50: Train Loss: 0.7867, Acc: 14.88% | Val Loss: 0.7699, Acc: 25.49%\n",
      "Epoch 60: Train Loss: 0.7827, Acc: 12.70% | Val Loss: 0.7650, Acc: 25.96%\n",
      "Epoch 70: Train Loss: 0.7765, Acc: 12.78% | Val Loss: 0.7611, Acc: 26.33%\n",
      "Epoch 80: Train Loss: 0.7732, Acc: 17.36% | Val Loss: 0.7579, Acc: 26.64%\n",
      "Epoch 90: Train Loss: 0.7699, Acc: 16.35% | Val Loss: 0.7551, Acc: 26.91%\n",
      "Final Validation score: 0.2713\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.2713\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.2176\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.00021544346900318823, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.9408, Acc: -1.09% | Val Loss: 0.8211, Acc: 15.55%\n",
      "Epoch 10: Train Loss: 0.6920, Acc: 26.83% | Val Loss: 0.7029, Acc: 27.71%\n",
      "Epoch 20: Train Loss: 0.6859, Acc: 27.04% | Val Loss: 0.6796, Acc: 30.10%\n",
      "Epoch 30: Train Loss: 0.6396, Acc: 34.00% | Val Loss: 0.6725, Acc: 30.83%\n",
      "Epoch 40: Train Loss: 0.6493, Acc: 32.75% | Val Loss: 0.6999, Acc: 28.02%\n",
      "Epoch 50: Train Loss: 0.6465, Acc: 30.62% | Val Loss: 0.6832, Acc: 29.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SCHOOL STUFF\\MASTER'S - COMPUTER SCIENCE - AI\\SEM 1\\PROJECTS\\machine learning\\ML_project\\src\\activation_functions.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  self.output = 1 / (1 + np.exp(-inputs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 56\n",
      "Restoring model weights from epoch 26\n",
      "Final Validation score: 0.2977\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.2977\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.00021544346900318823, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1048, Acc: -22.33% | Val Loss: 1.0539, Acc: 5.37%\n",
      "Epoch 10: Train Loss: 0.7749, Acc: 15.25% | Val Loss: 0.8103, Acc: 27.24%\n",
      "Epoch 20: Train Loss: 0.7306, Acc: 20.68% | Val Loss: 0.7357, Acc: 33.94%\n",
      "Epoch 30: Train Loss: 0.6895, Acc: 23.03% | Val Loss: 0.6851, Acc: 38.49%\n",
      "Epoch 40: Train Loss: 0.6991, Acc: 25.11% | Val Loss: 0.6702, Acc: 39.82%\n",
      "Epoch 50: Train Loss: 0.6530, Acc: 28.44% | Val Loss: 0.6641, Acc: 40.38%\n",
      "Epoch 60: Train Loss: 0.6844, Acc: 23.91% | Val Loss: 0.6712, Acc: 39.74%\n",
      "Epoch 70: Train Loss: 0.7010, Acc: 23.05% | Val Loss: 0.6811, Acc: 38.84%\n",
      "Early stopping at epoch 77\n",
      "Restoring model weights from epoch 47\n",
      "Final Validation score: 0.3899\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3899\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.00021544346900318823, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0675, Acc: -6.08% | Val Loss: 0.7136, Acc: 3.03%\n",
      "Epoch 10: Train Loss: 0.7161, Acc: 29.84% | Val Loss: 0.5344, Acc: 27.38%\n",
      "Epoch 20: Train Loss: 0.6632, Acc: 33.44% | Val Loss: 0.5325, Acc: 27.64%\n",
      "Epoch 30: Train Loss: 0.6764, Acc: 34.27% | Val Loss: 0.5354, Acc: 27.25%\n",
      "Epoch 40: Train Loss: 0.7087, Acc: 31.38% | Val Loss: 0.5451, Acc: 25.93%\n",
      "Epoch 50: Train Loss: 0.6804, Acc: 29.53% | Val Loss: 0.5641, Acc: 23.36%\n",
      "Epoch 60: Train Loss: 0.6855, Acc: 32.43% | Val Loss: 0.5597, Acc: 23.94%\n",
      "Early stopping at epoch 69\n",
      "Restoring model weights from epoch 39\n",
      "Final Validation score: 0.2874\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2874\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.00021544346900318823, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0925, Acc: -22.40% | Val Loss: 1.0582, Acc: 1.58%\n",
      "Epoch 10: Train Loss: 0.7480, Acc: 17.70% | Val Loss: 0.8512, Acc: 20.83%\n",
      "Epoch 20: Train Loss: 0.6818, Acc: 26.54% | Val Loss: 0.7937, Acc: 26.18%\n",
      "Epoch 30: Train Loss: 0.7082, Acc: 24.54% | Val Loss: 0.8005, Acc: 25.55%\n",
      "Epoch 40: Train Loss: 0.6923, Acc: 25.24% | Val Loss: 0.8130, Acc: 24.39%\n",
      "Epoch 50: Train Loss: 0.7391, Acc: 22.73% | Val Loss: 0.7900, Acc: 26.53%\n",
      "Early stopping at epoch 51\n",
      "Restoring model weights from epoch 21\n",
      "Final Validation score: 0.2616\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2616\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.00021544346900318823, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0204, Acc: -5.07% | Val Loss: 0.9669, Acc: 6.42%\n",
      "Epoch 10: Train Loss: 0.7347, Acc: 20.49% | Val Loss: 0.7419, Acc: 28.19%\n",
      "Epoch 20: Train Loss: 0.7074, Acc: 22.91% | Val Loss: 0.6583, Acc: 36.29%\n",
      "Epoch 30: Train Loss: 0.7092, Acc: 23.22% | Val Loss: 0.6417, Acc: 37.90%\n",
      "Epoch 40: Train Loss: 0.6739, Acc: 29.07% | Val Loss: 0.6237, Acc: 39.64%\n",
      "Epoch 50: Train Loss: 0.6888, Acc: 21.16% | Val Loss: 0.6499, Acc: 37.10%\n",
      "Early stopping at epoch 57\n",
      "Restoring model weights from epoch 27\n",
      "Final Validation score: 0.3970\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3970\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.3267\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.012915496650148827, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1.623776739188721e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2134, Acc: -22.79% | Val Loss: 1.2545, Acc: -29.02%\n",
      "Epoch 10: Train Loss: 1.0390, Acc: -5.47% | Val Loss: 1.0520, Acc: -8.19%\n",
      "Epoch 20: Train Loss: 1.0135, Acc: -3.51% | Val Loss: 1.0155, Acc: -4.45%\n",
      "Epoch 30: Train Loss: 1.0064, Acc: -4.18% | Val Loss: 1.0029, Acc: -3.15%\n",
      "Epoch 40: Train Loss: 1.0035, Acc: -2.77% | Val Loss: 0.9967, Acc: -2.51%\n",
      "Epoch 50: Train Loss: 1.0019, Acc: -2.21% | Val Loss: 0.9931, Acc: -2.14%\n",
      "Epoch 60: Train Loss: 1.0011, Acc: -1.86% | Val Loss: 0.9907, Acc: -1.89%\n",
      "Epoch 70: Train Loss: 1.0006, Acc: -2.28% | Val Loss: 0.9890, Acc: -1.72%\n",
      "Epoch 80: Train Loss: 1.0002, Acc: -2.56% | Val Loss: 0.9877, Acc: -1.59%\n",
      "Epoch 90: Train Loss: 0.9999, Acc: -1.35% | Val Loss: 0.9868, Acc: -1.49%\n",
      "Final Validation score: -0.0142\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0142\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.012915496650148827, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1.623776739188721e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1823, Acc: -24.89% | Val Loss: 1.1857, Acc: -6.46%\n",
      "Epoch 10: Train Loss: 0.9642, Acc: -1.37% | Val Loss: 1.1225, Acc: -0.78%\n",
      "Epoch 20: Train Loss: 0.9635, Acc: -1.81% | Val Loss: 1.1236, Acc: -0.88%\n",
      "Epoch 30: Train Loss: 0.9628, Acc: -0.87% | Val Loss: 1.1246, Acc: -0.97%\n",
      "Epoch 40: Train Loss: 0.9626, Acc: -1.68% | Val Loss: 1.1250, Acc: -1.01%\n",
      "Epoch 50: Train Loss: 0.9625, Acc: -1.91% | Val Loss: 1.1252, Acc: -1.03%\n",
      "Early stopping at epoch 52\n",
      "Restoring model weights from epoch 2\n",
      "Final Validation score: -0.0103\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0103\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.012915496650148827, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1.623776739188721e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2525, Acc: -23.55% | Val Loss: 0.9714, Acc: -31.99%\n",
      "Epoch 10: Train Loss: 1.0570, Acc: -0.65% | Val Loss: 0.7708, Acc: -4.74%\n",
      "Epoch 20: Train Loss: 1.0558, Acc: -1.09% | Val Loss: 0.7705, Acc: -4.70%\n",
      "Epoch 30: Train Loss: 1.0553, Acc: -1.04% | Val Loss: 0.7716, Acc: -4.84%\n",
      "Epoch 40: Train Loss: 1.0552, Acc: -1.16% | Val Loss: 0.7748, Acc: -5.28%\n",
      "Epoch 50: Train Loss: 1.0550, Acc: -0.52% | Val Loss: 0.7734, Acc: -5.09%\n",
      "Early stopping at epoch 54\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation score: -0.0490\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0490\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.012915496650148827, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1.623776739188721e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1879, Acc: -26.59% | Val Loss: 1.3651, Acc: -26.96%\n",
      "Epoch 10: Train Loss: 0.9793, Acc: -1.67% | Val Loss: 1.1195, Acc: -4.12%\n",
      "Epoch 20: Train Loss: 0.9730, Acc: -3.02% | Val Loss: 1.0982, Acc: -2.13%\n",
      "Epoch 30: Train Loss: 0.9725, Acc: -2.46% | Val Loss: 1.0945, Acc: -1.79%\n",
      "Epoch 40: Train Loss: 0.9725, Acc: -0.85% | Val Loss: 1.0925, Acc: -1.60%\n",
      "Epoch 50: Train Loss: 0.9723, Acc: -1.04% | Val Loss: 1.0920, Acc: -1.56%\n",
      "Epoch 60: Train Loss: 0.9723, Acc: -1.30% | Val Loss: 1.0924, Acc: -1.59%\n",
      "Epoch 70: Train Loss: 0.9723, Acc: -0.82% | Val Loss: 1.0919, Acc: -1.55%\n",
      "Epoch 80: Train Loss: 0.9723, Acc: -1.09% | Val Loss: 1.0920, Acc: -1.55%\n",
      "Epoch 90: Train Loss: 0.9723, Acc: -1.05% | Val Loss: 1.0917, Acc: -1.53%\n",
      "Final Validation score: -0.0154\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0154\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.012915496650148827, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 1.623776739188721e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2461, Acc: -32.20% | Val Loss: 1.1507, Acc: -11.37%\n",
      "Epoch 10: Train Loss: 1.0380, Acc: -7.06% | Val Loss: 1.0430, Acc: -0.95%\n",
      "Epoch 20: Train Loss: 1.0048, Acc: -3.96% | Val Loss: 1.0366, Acc: -0.32%\n",
      "Epoch 30: Train Loss: 0.9949, Acc: -3.38% | Val Loss: 1.0376, Acc: -0.42%\n",
      "Epoch 40: Train Loss: 0.9906, Acc: -4.57% | Val Loss: 1.0391, Acc: -0.57%\n",
      "Epoch 50: Train Loss: 0.9882, Acc: -2.07% | Val Loss: 1.0405, Acc: -0.70%\n",
      "Epoch 60: Train Loss: 0.9867, Acc: -2.46% | Val Loss: 1.0416, Acc: -0.81%\n",
      "Epoch 70: Train Loss: 0.9857, Acc: -2.33% | Val Loss: 1.0425, Acc: -0.90%\n",
      "Early stopping at epoch 73\n",
      "Restoring model weights from epoch 23\n",
      "Final Validation score: -0.0093\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0093\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0196\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0707, Acc: -13.92% | Val Loss: 1.0259, Acc: -5.51%\n",
      "Epoch 10: Train Loss: 0.8957, Acc: 8.33% | Val Loss: 0.9072, Acc: 6.70%\n",
      "Epoch 20: Train Loss: 0.8744, Acc: 7.57% | Val Loss: 0.8918, Acc: 8.29%\n",
      "Epoch 30: Train Loss: 0.8607, Acc: 10.07% | Val Loss: 0.8832, Acc: 9.16%\n",
      "Epoch 40: Train Loss: 0.8511, Acc: 11.03% | Val Loss: 0.8776, Acc: 9.74%\n",
      "Epoch 50: Train Loss: 0.8421, Acc: 11.22% | Val Loss: 0.8734, Acc: 10.18%\n",
      "Epoch 60: Train Loss: 0.8401, Acc: 13.75% | Val Loss: 0.8702, Acc: 10.50%\n",
      "Epoch 70: Train Loss: 0.8331, Acc: 12.21% | Val Loss: 0.8676, Acc: 10.77%\n",
      "Epoch 80: Train Loss: 0.8325, Acc: 12.86% | Val Loss: 0.8658, Acc: 10.96%\n",
      "Epoch 90: Train Loss: 0.8296, Acc: 15.26% | Val Loss: 0.8640, Acc: 11.14%\n",
      "Final Validation score: 0.1129\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1129\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0279, Acc: -9.28% | Val Loss: 1.0582, Acc: 4.99%\n",
      "Epoch 10: Train Loss: 0.8572, Acc: 6.62% | Val Loss: 0.9737, Acc: 12.57%\n",
      "Epoch 20: Train Loss: 0.8479, Acc: 9.60% | Val Loss: 0.9718, Acc: 12.75%\n",
      "Epoch 30: Train Loss: 0.8548, Acc: 7.22% | Val Loss: 0.9694, Acc: 12.96%\n",
      "Epoch 40: Train Loss: 0.8471, Acc: 7.30% | Val Loss: 0.9671, Acc: 13.17%\n",
      "Epoch 50: Train Loss: 0.8452, Acc: 7.74% | Val Loss: 0.9643, Acc: 13.42%\n",
      "Epoch 60: Train Loss: 0.8405, Acc: 5.77% | Val Loss: 0.9608, Acc: 13.73%\n",
      "Epoch 70: Train Loss: 0.8408, Acc: 6.23% | Val Loss: 0.9587, Acc: 13.92%\n",
      "Epoch 80: Train Loss: 0.8388, Acc: 11.60% | Val Loss: 0.9572, Acc: 14.06%\n",
      "Epoch 90: Train Loss: 0.8362, Acc: 8.41% | Val Loss: 0.9561, Acc: 14.16%\n",
      "Final Validation score: 0.1427\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.1427\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2650, Acc: -25.15% | Val Loss: 1.0251, Acc: -39.28%\n",
      "Epoch 10: Train Loss: 1.1146, Acc: -7.89% | Val Loss: 0.8901, Acc: -20.94%\n",
      "Epoch 20: Train Loss: 1.0688, Acc: -5.05% | Val Loss: 0.8488, Acc: -15.33%\n",
      "Epoch 30: Train Loss: 1.0463, Acc: -5.74% | Val Loss: 0.8263, Acc: -12.28%\n",
      "Epoch 40: Train Loss: 1.0376, Acc: -4.71% | Val Loss: 0.8117, Acc: -10.29%\n",
      "Epoch 50: Train Loss: 1.0198, Acc: -0.22% | Val Loss: 0.8009, Acc: -8.83%\n",
      "Epoch 60: Train Loss: 1.0074, Acc: -2.59% | Val Loss: 0.7928, Acc: -7.72%\n",
      "Epoch 70: Train Loss: 0.9997, Acc: 3.20% | Val Loss: 0.7861, Acc: -6.82%\n",
      "Epoch 80: Train Loss: 0.9964, Acc: -2.12% | Val Loss: 0.7808, Acc: -6.09%\n",
      "Epoch 90: Train Loss: 0.9905, Acc: 3.03% | Val Loss: 0.7760, Acc: -5.45%\n",
      "Final Validation score: -0.0495\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0495\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1236, Acc: -19.87% | Val Loss: 1.2812, Acc: -19.15%\n",
      "Epoch 10: Train Loss: 0.9122, Acc: 3.55% | Val Loss: 1.0569, Acc: 1.70%\n",
      "Epoch 20: Train Loss: 0.8717, Acc: 4.30% | Val Loss: 1.0072, Acc: 6.33%\n",
      "Epoch 30: Train Loss: 0.8565, Acc: 8.68% | Val Loss: 0.9826, Acc: 8.61%\n",
      "Epoch 40: Train Loss: 0.8384, Acc: 10.34% | Val Loss: 0.9658, Acc: 10.18%\n",
      "Epoch 50: Train Loss: 0.8335, Acc: 12.00% | Val Loss: 0.9522, Acc: 11.45%\n",
      "Epoch 60: Train Loss: 0.8183, Acc: 13.51% | Val Loss: 0.9378, Acc: 12.79%\n",
      "Epoch 70: Train Loss: 0.8086, Acc: 11.96% | Val Loss: 0.9273, Acc: 13.75%\n",
      "Epoch 80: Train Loss: 0.8059, Acc: 11.55% | Val Loss: 0.9195, Acc: 14.48%\n",
      "Epoch 90: Train Loss: 0.8003, Acc: 11.22% | Val Loss: 0.9130, Acc: 15.09%\n",
      "Final Validation score: 0.1555\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.1555\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1660, Acc: -31.08% | Val Loss: 0.9603, Acc: 7.06%\n",
      "Epoch 10: Train Loss: 0.8690, Acc: 7.48% | Val Loss: 0.8195, Acc: 20.68%\n",
      "Epoch 20: Train Loss: 0.8463, Acc: 9.05% | Val Loss: 0.7938, Acc: 23.17%\n",
      "Epoch 30: Train Loss: 0.8386, Acc: 10.51% | Val Loss: 0.7865, Acc: 23.88%\n",
      "Epoch 40: Train Loss: 0.8347, Acc: 12.39% | Val Loss: 0.7825, Acc: 24.27%\n",
      "Epoch 50: Train Loss: 0.8342, Acc: 12.43% | Val Loss: 0.7790, Acc: 24.61%\n",
      "Epoch 60: Train Loss: 0.8270, Acc: 10.76% | Val Loss: 0.7754, Acc: 24.96%\n",
      "Epoch 70: Train Loss: 0.8239, Acc: 12.34% | Val Loss: 0.7721, Acc: 25.28%\n",
      "Epoch 80: Train Loss: 0.8344, Acc: 10.73% | Val Loss: 0.7683, Acc: 25.64%\n",
      "Epoch 90: Train Loss: 0.8198, Acc: 13.73% | Val Loss: 0.7661, Acc: 25.85%\n",
      "Final Validation score: 0.2608\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.2608\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.1245\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.03593813663804626, 'l2': 0.03593813663804626, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.3473, Acc: -42.01% | Val Loss: 1.3025, Acc: -33.96%\n",
      "Epoch 10: Train Loss: 0.8737, Acc: 7.87% | Val Loss: 0.9526, Acc: 2.03%\n",
      "Epoch 20: Train Loss: 0.8547, Acc: 10.98% | Val Loss: 0.9263, Acc: 4.74%\n",
      "Epoch 30: Train Loss: 0.8495, Acc: 12.42% | Val Loss: 0.9166, Acc: 5.73%\n",
      "Epoch 40: Train Loss: 0.8483, Acc: 11.47% | Val Loss: 0.9124, Acc: 6.16%\n",
      "Epoch 50: Train Loss: 0.8490, Acc: 11.46% | Val Loss: 0.9112, Acc: 6.29%\n",
      "Epoch 60: Train Loss: 0.8504, Acc: 11.84% | Val Loss: 0.9111, Acc: 6.30%\n",
      "Early stopping at epoch 66\n",
      "Restoring model weights from epoch 56\n",
      "Final Validation score: 0.0626\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.0626\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.03593813663804626, 'l2': 0.03593813663804626, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1439, Acc: -23.79% | Val Loss: 1.1060, Acc: 0.70%\n",
      "Epoch 10: Train Loss: 0.8259, Acc: 5.38% | Val Loss: 0.9121, Acc: 18.11%\n",
      "Early stopping at epoch 17\n",
      "Restoring model weights from epoch 7\n",
      "Final Validation score: 0.1730\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.1730\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.03593813663804626, 'l2': 0.03593813663804626, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0123, Acc: -2.78% | Val Loss: 0.8182, Acc: -11.17%\n",
      "Epoch 10: Train Loss: 0.9000, Acc: 9.91% | Val Loss: 0.7415, Acc: -0.75%\n",
      "Epoch 20: Train Loss: 0.9035, Acc: 11.45% | Val Loss: 0.7433, Acc: -1.00%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation score: -0.0100\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0100\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.03593813663804626, 'l2': 0.03593813663804626, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0504, Acc: -18.19% | Val Loss: 1.1444, Acc: -6.43%\n",
      "Epoch 10: Train Loss: 0.8622, Acc: 0.00% | Val Loss: 0.9957, Acc: 7.39%\n",
      "Epoch 20: Train Loss: 0.8635, Acc: 5.64% | Val Loss: 1.0006, Acc: 6.94%\n",
      "Early stopping at epoch 20\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation score: 0.0694\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.0694\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.03593813663804626, 'l2': 0.03593813663804626, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.4768, Acc: -69.04% | Val Loss: 1.2002, Acc: -16.16%\n",
      "Epoch 10: Train Loss: 0.9279, Acc: -0.35% | Val Loss: 0.8768, Acc: 15.15%\n",
      "Epoch 20: Train Loss: 0.8981, Acc: 0.99% | Val Loss: 0.8651, Acc: 16.27%\n",
      "Early stopping at epoch 29\n",
      "Restoring model weights from epoch 19\n",
      "Final Validation score: 0.1616\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.1616\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.0913\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1376, Acc: -19.41% | Val Loss: 1.0674, Acc: -9.77%\n",
      "Epoch 10: Train Loss: 0.9993, Acc: -2.72% | Val Loss: 0.9819, Acc: -0.99%\n",
      "Epoch 20: Train Loss: 0.9993, Acc: -5.68% | Val Loss: 0.9803, Acc: -0.82%\n",
      "Epoch 30: Train Loss: 0.9992, Acc: -3.31% | Val Loss: 0.9802, Acc: -0.81%\n",
      "Epoch 40: Train Loss: 0.9992, Acc: -4.39% | Val Loss: 0.9798, Acc: -0.77%\n",
      "Epoch 50: Train Loss: 0.9993, Acc: -2.67% | Val Loss: 0.9796, Acc: -0.75%\n",
      "Epoch 60: Train Loss: 0.9991, Acc: -3.84% | Val Loss: 0.9797, Acc: -0.76%\n",
      "Epoch 70: Train Loss: 0.9992, Acc: -3.04% | Val Loss: 0.9794, Acc: -0.73%\n",
      "Epoch 80: Train Loss: 1.0006, Acc: -2.92% | Val Loss: 0.9795, Acc: -0.73%\n",
      "Epoch 90: Train Loss: 0.9992, Acc: -4.04% | Val Loss: 0.9794, Acc: -0.73%\n",
      "Final Validation score: -0.0078\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0078\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1102, Acc: -29.55% | Val Loss: 1.1394, Acc: -2.30%\n",
      "Epoch 10: Train Loss: 0.9627, Acc: -4.06% | Val Loss: 1.1253, Acc: -1.04%\n",
      "Epoch 20: Train Loss: 0.9625, Acc: -6.15% | Val Loss: 1.1255, Acc: -1.05%\n",
      "Epoch 30: Train Loss: 0.9625, Acc: -2.42% | Val Loss: 1.1256, Acc: -1.06%\n",
      "Epoch 40: Train Loss: 0.9626, Acc: -5.22% | Val Loss: 1.1256, Acc: -1.06%\n",
      "Epoch 50: Train Loss: 0.9624, Acc: -2.69% | Val Loss: 1.1256, Acc: -1.06%\n",
      "Early stopping at epoch 53\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0106\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0106\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1790, Acc: -19.40% | Val Loss: 0.8833, Acc: -20.02%\n",
      "Epoch 10: Train Loss: 1.0551, Acc: -3.48% | Val Loss: 0.7719, Acc: -4.89%\n",
      "Epoch 20: Train Loss: 1.0550, Acc: -3.91% | Val Loss: 0.7706, Acc: -4.70%\n",
      "Epoch 30: Train Loss: 1.0549, Acc: -2.66% | Val Loss: 0.7728, Acc: -5.01%\n",
      "Epoch 40: Train Loss: 1.0552, Acc: -2.97% | Val Loss: 0.7708, Acc: -4.74%\n",
      "Epoch 50: Train Loss: 1.0547, Acc: -3.08% | Val Loss: 0.7744, Acc: -5.23%\n",
      "Epoch 60: Train Loss: 1.0550, Acc: -2.41% | Val Loss: 0.7789, Acc: -5.84%\n",
      "Epoch 70: Train Loss: 1.0547, Acc: -2.52% | Val Loss: 0.7758, Acc: -5.42%\n",
      "Early stopping at epoch 76\n",
      "Restoring model weights from epoch 26\n",
      "Final Validation score: -0.0496\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0496\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1369, Acc: -38.23% | Val Loss: 1.2641, Acc: -17.57%\n",
      "Epoch 10: Train Loss: 0.9775, Acc: -3.67% | Val Loss: 1.1046, Acc: -2.73%\n",
      "Epoch 20: Train Loss: 0.9740, Acc: -3.74% | Val Loss: 1.0965, Acc: -1.97%\n",
      "Epoch 30: Train Loss: 0.9732, Acc: -6.44% | Val Loss: 1.0938, Acc: -1.73%\n",
      "Epoch 40: Train Loss: 0.9729, Acc: -2.33% | Val Loss: 1.0931, Acc: -1.66%\n",
      "Epoch 50: Train Loss: 0.9728, Acc: -4.52% | Val Loss: 1.0921, Acc: -1.57%\n",
      "Epoch 60: Train Loss: 0.9726, Acc: -3.79% | Val Loss: 1.0926, Acc: -1.61%\n",
      "Epoch 70: Train Loss: 0.9725, Acc: -3.12% | Val Loss: 1.0923, Acc: -1.59%\n",
      "Epoch 80: Train Loss: 0.9725, Acc: -4.79% | Val Loss: 1.0928, Acc: -1.63%\n",
      "Epoch 90: Train Loss: 0.9724, Acc: -5.21% | Val Loss: 1.0922, Acc: -1.58%\n",
      "Final Validation score: -0.0162\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0162\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0016681005372000592, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1929, Acc: -27.71% | Val Loss: 1.0853, Acc: -5.04%\n",
      "Epoch 10: Train Loss: 0.9907, Acc: -4.72% | Val Loss: 1.0391, Acc: -0.57%\n",
      "Epoch 20: Train Loss: 0.9854, Acc: -4.39% | Val Loss: 1.0430, Acc: -0.95%\n",
      "Epoch 30: Train Loss: 0.9838, Acc: -6.72% | Val Loss: 1.0451, Acc: -1.15%\n",
      "Epoch 40: Train Loss: 0.9830, Acc: -3.75% | Val Loss: 1.0461, Acc: -1.24%\n",
      "Epoch 50: Train Loss: 0.9826, Acc: -5.49% | Val Loss: 1.0468, Acc: -1.31%\n",
      "Early stopping at epoch 55\n",
      "Restoring model weights from epoch 5\n",
      "Final Validation score: -0.0134\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0134\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0195\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 7.742636826811278e-05, 'l2': 1e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2292, Acc: -25.47% | Val Loss: 1.2954, Acc: -33.23%\n",
      "Epoch 10: Train Loss: 1.2145, Acc: -26.60% | Val Loss: 1.2799, Acc: -31.63%\n",
      "Epoch 20: Train Loss: 1.2095, Acc: -24.32% | Val Loss: 1.2741, Acc: -31.04%\n",
      "Epoch 30: Train Loss: 1.2064, Acc: -26.00% | Val Loss: 1.2705, Acc: -30.66%\n",
      "Epoch 40: Train Loss: 1.2040, Acc: -22.90% | Val Loss: 1.2678, Acc: -30.39%\n",
      "Epoch 50: Train Loss: 1.2023, Acc: -27.28% | Val Loss: 1.2657, Acc: -30.17%\n",
      "Epoch 60: Train Loss: 1.2009, Acc: -22.21% | Val Loss: 1.2639, Acc: -29.99%\n",
      "Epoch 70: Train Loss: 1.1995, Acc: -25.15% | Val Loss: 1.2624, Acc: -29.83%\n",
      "Epoch 80: Train Loss: 1.1986, Acc: -21.98% | Val Loss: 1.2611, Acc: -29.70%\n",
      "Epoch 90: Train Loss: 1.1974, Acc: -27.90% | Val Loss: 1.2600, Acc: -29.58%\n",
      "Final Validation score: -0.2949\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.2949\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 7.742636826811278e-05, 'l2': 1e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2372, Acc: -31.96% | Val Loss: 1.2643, Acc: -13.51%\n",
      "Epoch 10: Train Loss: 1.2192, Acc: -29.92% | Val Loss: 1.2515, Acc: -12.37%\n",
      "Epoch 20: Train Loss: 1.2115, Acc: -29.17% | Val Loss: 1.2456, Acc: -11.84%\n",
      "Epoch 30: Train Loss: 1.2058, Acc: -30.57% | Val Loss: 1.2415, Acc: -11.47%\n",
      "Epoch 40: Train Loss: 1.2016, Acc: -32.90% | Val Loss: 1.2383, Acc: -11.18%\n",
      "Epoch 50: Train Loss: 1.1982, Acc: -29.12% | Val Loss: 1.2356, Acc: -10.94%\n",
      "Epoch 60: Train Loss: 1.1952, Acc: -27.67% | Val Loss: 1.2333, Acc: -10.73%\n",
      "Epoch 70: Train Loss: 1.1929, Acc: -29.15% | Val Loss: 1.2313, Acc: -10.55%\n",
      "Epoch 80: Train Loss: 1.1899, Acc: -27.11% | Val Loss: 1.2295, Acc: -10.39%\n",
      "Epoch 90: Train Loss: 1.1882, Acc: -25.55% | Val Loss: 1.2279, Acc: -10.24%\n",
      "Final Validation score: -0.1012\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.1012\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 7.742636826811278e-05, 'l2': 1e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2853, Acc: -22.74% | Val Loss: 1.0656, Acc: -44.79%\n",
      "Epoch 10: Train Loss: 1.2628, Acc: -21.97% | Val Loss: 1.0390, Acc: -41.18%\n",
      "Epoch 20: Train Loss: 1.2530, Acc: -20.94% | Val Loss: 1.0266, Acc: -39.50%\n",
      "Epoch 30: Train Loss: 1.2463, Acc: -24.85% | Val Loss: 1.0179, Acc: -38.31%\n",
      "Epoch 40: Train Loss: 1.2409, Acc: -20.69% | Val Loss: 1.0111, Acc: -37.38%\n",
      "Epoch 50: Train Loss: 1.2367, Acc: -18.82% | Val Loss: 1.0054, Acc: -36.62%\n",
      "Epoch 60: Train Loss: 1.2333, Acc: -17.72% | Val Loss: 1.0006, Acc: -35.95%\n",
      "Epoch 70: Train Loss: 1.2297, Acc: -19.46% | Val Loss: 0.9962, Acc: -35.37%\n",
      "Epoch 80: Train Loss: 1.2271, Acc: -17.35% | Val Loss: 0.9924, Acc: -34.84%\n",
      "Epoch 90: Train Loss: 1.2244, Acc: -22.51% | Val Loss: 0.9888, Acc: -34.36%\n",
      "Final Validation score: -0.3396\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.3396\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 7.742636826811278e-05, 'l2': 1e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2031, Acc: -27.20% | Val Loss: 1.4062, Acc: -30.78%\n",
      "Epoch 10: Train Loss: 1.1905, Acc: -24.89% | Val Loss: 1.3900, Acc: -29.28%\n",
      "Epoch 20: Train Loss: 1.1851, Acc: -29.39% | Val Loss: 1.3825, Acc: -28.58%\n",
      "Epoch 30: Train Loss: 1.1818, Acc: -26.70% | Val Loss: 1.3781, Acc: -28.17%\n",
      "Epoch 40: Train Loss: 1.1797, Acc: -22.97% | Val Loss: 1.3749, Acc: -27.87%\n",
      "Epoch 50: Train Loss: 1.1777, Acc: -27.45% | Val Loss: 1.3725, Acc: -27.64%\n",
      "Epoch 60: Train Loss: 1.1762, Acc: -24.06% | Val Loss: 1.3704, Acc: -27.45%\n",
      "Epoch 70: Train Loss: 1.1753, Acc: -24.06% | Val Loss: 1.3687, Acc: -27.29%\n",
      "Epoch 80: Train Loss: 1.1737, Acc: -24.41% | Val Loss: 1.3672, Acc: -27.16%\n",
      "Epoch 90: Train Loss: 1.1730, Acc: -21.54% | Val Loss: 1.3659, Acc: -27.03%\n",
      "Final Validation score: -0.2694\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.2694\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0012742749857031334, 'l1': 7.742636826811278e-05, 'l2': 1e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2602, Acc: -32.35% | Val Loss: 1.1722, Acc: -13.45%\n",
      "Epoch 10: Train Loss: 1.2439, Acc: -31.50% | Val Loss: 1.1617, Acc: -12.43%\n",
      "Epoch 20: Train Loss: 1.2377, Acc: -31.31% | Val Loss: 1.1574, Acc: -12.02%\n",
      "Epoch 30: Train Loss: 1.2337, Acc: -29.15% | Val Loss: 1.1545, Acc: -11.74%\n",
      "Epoch 40: Train Loss: 1.2305, Acc: -32.44% | Val Loss: 1.1523, Acc: -11.53%\n",
      "Epoch 50: Train Loss: 1.2280, Acc: -28.94% | Val Loss: 1.1506, Acc: -11.35%\n",
      "Epoch 60: Train Loss: 1.2260, Acc: -28.61% | Val Loss: 1.1491, Acc: -11.21%\n",
      "Epoch 70: Train Loss: 1.2242, Acc: -26.69% | Val Loss: 1.1477, Acc: -11.08%\n",
      "Epoch 80: Train Loss: 1.2227, Acc: -28.44% | Val Loss: 1.1466, Acc: -10.97%\n",
      "Epoch 90: Train Loss: 1.2210, Acc: -28.94% | Val Loss: 1.1455, Acc: -10.87%\n",
      "Final Validation score: -0.1078\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.1078\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.2226\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00206913808111479, 'l1': 1e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2245, Acc: -26.17% | Val Loss: 1.2826, Acc: -31.91%\n",
      "Epoch 10: Train Loss: 0.8866, Acc: 7.18% | Val Loss: 0.9056, Acc: 6.86%\n",
      "Epoch 20: Train Loss: 0.8487, Acc: 11.56% | Val Loss: 0.8744, Acc: 10.07%\n",
      "Epoch 30: Train Loss: 0.8115, Acc: 15.39% | Val Loss: 0.8618, Acc: 11.36%\n",
      "Epoch 40: Train Loss: 0.7941, Acc: 15.35% | Val Loss: 0.8521, Acc: 12.36%\n",
      "Final Validation score: 0.1369\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1369\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00206913808111479, 'l1': 1e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2294, Acc: -36.23% | Val Loss: 1.2516, Acc: -12.38%\n",
      "Epoch 10: Train Loss: 0.8264, Acc: 8.05% | Val Loss: 0.9354, Acc: 16.01%\n",
      "Epoch 20: Train Loss: 0.7891, Acc: 16.58% | Val Loss: 0.8852, Acc: 20.53%\n",
      "Epoch 30: Train Loss: 0.7480, Acc: 16.74% | Val Loss: 0.8480, Acc: 23.87%\n",
      "Epoch 40: Train Loss: 0.7326, Acc: 21.62% | Val Loss: 0.8279, Acc: 25.66%\n",
      "Final Validation score: 0.2592\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.2592\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00206913808111479, 'l1': 1e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2797, Acc: -30.68% | Val Loss: 1.0516, Acc: -42.89%\n",
      "Epoch 10: Train Loss: 0.9027, Acc: 10.85% | Val Loss: 0.6227, Acc: 15.38%\n",
      "Epoch 20: Train Loss: 0.7629, Acc: 22.09% | Val Loss: 0.5987, Acc: 18.65%\n",
      "Epoch 30: Train Loss: 0.7383, Acc: 25.55% | Val Loss: 0.5810, Acc: 21.06%\n",
      "Epoch 40: Train Loss: 0.7002, Acc: 30.05% | Val Loss: 0.5686, Acc: 22.74%\n",
      "Final Validation score: 0.2322\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2322\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00206913808111479, 'l1': 1e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2006, Acc: -32.06% | Val Loss: 1.3993, Acc: -30.14%\n",
      "Epoch 10: Train Loss: 0.8639, Acc: 6.45% | Val Loss: 0.9912, Acc: 7.82%\n",
      "Epoch 20: Train Loss: 0.8191, Acc: 13.73% | Val Loss: 0.9328, Acc: 13.25%\n",
      "Epoch 30: Train Loss: 0.7753, Acc: 16.81% | Val Loss: 0.8953, Acc: 16.73%\n",
      "Epoch 40: Train Loss: 0.7469, Acc: 17.17% | Val Loss: 0.8735, Acc: 18.76%\n",
      "Final Validation score: 0.2575\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2575\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00206913808111479, 'l1': 1e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2529, Acc: -36.87% | Val Loss: 1.1627, Acc: -12.53%\n",
      "Epoch 10: Train Loss: 0.9822, Acc: -5.62% | Val Loss: 0.9430, Acc: 8.73%\n",
      "Epoch 20: Train Loss: 0.9261, Acc: -2.48% | Val Loss: 0.8973, Acc: 13.16%\n",
      "Epoch 30: Train Loss: 0.8667, Acc: 8.75% | Val Loss: 0.8411, Acc: 18.60%\n",
      "Epoch 40: Train Loss: 0.8219, Acc: 13.21% | Val Loss: 0.8018, Acc: 22.40%\n",
      "Final Validation score: 0.2435\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.2435\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.2259\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.00021544346900318823, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.5657, Acc: -59.55% | Val Loss: 1.6312, Acc: -67.76%\n",
      "Epoch 10: Train Loss: 1.4553, Acc: -46.37% | Val Loss: 1.5458, Acc: -58.98%\n",
      "Epoch 20: Train Loss: 1.4004, Acc: -40.90% | Val Loss: 1.5048, Acc: -54.76%\n",
      "Epoch 30: Train Loss: 1.3511, Acc: -35.84% | Val Loss: 1.4694, Acc: -51.12%\n",
      "Epoch 40: Train Loss: 1.3258, Acc: -36.41% | Val Loss: 1.4443, Acc: -48.55%\n",
      "Final Validation score: -0.4672\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.4672\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.00021544346900318823, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.5062, Acc: -57.93% | Val Loss: 1.6270, Acc: -46.08%\n",
      "Epoch 10: Train Loss: 1.3791, Acc: -45.37% | Val Loss: 1.4866, Acc: -33.48%\n",
      "Epoch 20: Train Loss: 1.2631, Acc: -33.92% | Val Loss: 1.3816, Acc: -24.05%\n",
      "Epoch 30: Train Loss: 1.1845, Acc: -28.51% | Val Loss: 1.2808, Acc: -15.00%\n",
      "Epoch 40: Train Loss: 1.1388, Acc: -20.08% | Val Loss: 1.2142, Acc: -9.02%\n",
      "Final Validation score: -0.0526\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0526\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.00021544346900318823, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.5969, Acc: -53.31% | Val Loss: 1.3612, Acc: -84.96%\n",
      "Epoch 10: Train Loss: 1.3567, Acc: -28.70% | Val Loss: 1.1396, Acc: -54.85%\n",
      "Epoch 20: Train Loss: 1.2523, Acc: -18.82% | Val Loss: 1.0470, Acc: -42.26%\n",
      "Epoch 30: Train Loss: 1.1887, Acc: -13.10% | Val Loss: 0.9974, Acc: -35.52%\n",
      "Epoch 40: Train Loss: 1.1623, Acc: -11.25% | Val Loss: 0.9637, Acc: -30.94%\n",
      "Final Validation score: -0.2782\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.2782\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.00021544346900318823, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 0.9435, Acc: 2.23% | Val Loss: 1.0277, Acc: 4.42%\n",
      "Epoch 10: Train Loss: 0.8458, Acc: 12.44% | Val Loss: 0.9861, Acc: 8.29%\n",
      "Epoch 20: Train Loss: 0.8190, Acc: 15.54% | Val Loss: 0.9700, Acc: 9.79%\n",
      "Epoch 30: Train Loss: 0.8037, Acc: 16.94% | Val Loss: 0.9618, Acc: 10.55%\n",
      "Epoch 40: Train Loss: 0.7820, Acc: 18.60% | Val Loss: 0.9550, Acc: 11.19%\n",
      "Final Validation score: 0.1163\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.1163\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.00021544346900318823, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.023357214690901212, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2463, Acc: -27.89% | Val Loss: 1.1284, Acc: -9.21%\n",
      "Epoch 10: Train Loss: 1.1700, Acc: -21.41% | Val Loss: 1.0849, Acc: -5.00%\n",
      "Epoch 20: Train Loss: 1.1316, Acc: -16.99% | Val Loss: 1.0673, Acc: -3.30%\n",
      "Epoch 30: Train Loss: 1.1259, Acc: -15.74% | Val Loss: 1.0534, Acc: -1.95%\n",
      "Epoch 40: Train Loss: 1.0944, Acc: -12.26% | Val Loss: 1.0391, Acc: -0.57%\n",
      "Final Validation score: 0.0076\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.0076\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.1348\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 1.623776739188721e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0823, Acc: -10.21% | Val Loss: 0.9757, Acc: -0.34%\n",
      "Epoch 10: Train Loss: 0.9993, Acc: -0.93% | Val Loss: 0.9773, Acc: -0.52%\n",
      "Early stopping at epoch 10\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0052\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0052\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 1.623776739188721e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0305, Acc: -8.46% | Val Loss: 1.1254, Acc: -1.04%\n",
      "Epoch 10: Train Loss: 0.9622, Acc: -1.73% | Val Loss: 1.1254, Acc: -1.04%\n",
      "Early stopping at epoch 10\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0104\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0104\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 1.623776739188721e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1722, Acc: -12.47% | Val Loss: 0.7419, Acc: -0.81%\n",
      "Epoch 10: Train Loss: 1.0570, Acc: -2.14% | Val Loss: 0.7708, Acc: -4.74%\n",
      "Early stopping at epoch 10\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0474\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0474\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 1.623776739188721e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0528, Acc: -9.48% | Val Loss: 1.0820, Acc: -0.63%\n",
      "Epoch 10: Train Loss: 0.8505, Acc: 11.07% | Val Loss: 0.9990, Acc: 7.09%\n",
      "Epoch 20: Train Loss: 0.8397, Acc: 12.59% | Val Loss: 0.9893, Acc: 7.99%\n",
      "Early stopping at epoch 25\n",
      "Restoring model weights from epoch 15\n",
      "Final Validation score: 0.0645\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.0645\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 1.623776739188721e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0978, Acc: -14.90% | Val Loss: 1.0481, Acc: -1.44%\n",
      "Epoch 10: Train Loss: 0.9823, Acc: -0.85% | Val Loss: 1.0484, Acc: -1.46%\n",
      "Early stopping at epoch 10\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0146\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0146\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0026\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.004641588833612777, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1038, Acc: -13.33% | Val Loss: 1.0214, Acc: -5.05%\n",
      "Epoch 10: Train Loss: 0.7121, Acc: 24.40% | Val Loss: 0.7114, Acc: 26.84%\n",
      "Epoch 20: Train Loss: 0.6694, Acc: 29.17% | Val Loss: 0.6963, Acc: 28.39%\n",
      "Epoch 30: Train Loss: 0.6492, Acc: 30.88% | Val Loss: 0.7020, Acc: 27.80%\n",
      "Epoch 40: Train Loss: 0.6298, Acc: 30.59% | Val Loss: 0.6624, Acc: 31.88%\n",
      "Epoch 50: Train Loss: 0.6512, Acc: 29.50% | Val Loss: 0.6605, Acc: 32.07%\n",
      "Epoch 60: Train Loss: 0.6482, Acc: 33.10% | Val Loss: 0.6512, Acc: 33.02%\n",
      "Epoch 70: Train Loss: 0.6304, Acc: 34.39% | Val Loss: 0.6475, Acc: 33.41%\n",
      "Epoch 80: Train Loss: 0.6276, Acc: 34.34% | Val Loss: 0.6467, Acc: 33.49%\n",
      "Epoch 90: Train Loss: 0.6363, Acc: 31.28% | Val Loss: 0.6457, Acc: 33.59%\n",
      "Final Validation score: 0.3366\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.3366\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.004641588833612777, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1773, Acc: -31.25% | Val Loss: 1.1499, Acc: -3.24%\n",
      "Epoch 10: Train Loss: 0.6514, Acc: 28.59% | Val Loss: 0.6604, Acc: 40.71%\n",
      "Epoch 20: Train Loss: 0.6382, Acc: 31.21% | Val Loss: 0.6479, Acc: 41.83%\n",
      "Epoch 30: Train Loss: 0.6418, Acc: 28.30% | Val Loss: 0.6447, Acc: 42.11%\n",
      "Epoch 40: Train Loss: 0.6586, Acc: 28.69% | Val Loss: 0.6452, Acc: 42.07%\n",
      "Epoch 50: Train Loss: 0.6357, Acc: 30.97% | Val Loss: 0.6394, Acc: 42.59%\n",
      "Epoch 60: Train Loss: 0.6244, Acc: 32.52% | Val Loss: 0.6376, Acc: 42.75%\n",
      "Epoch 70: Train Loss: 0.6295, Acc: 32.07% | Val Loss: 0.6383, Acc: 42.69%\n",
      "Epoch 80: Train Loss: 0.6286, Acc: 33.02% | Val Loss: 0.6398, Acc: 42.56%\n",
      "Epoch 90: Train Loss: 0.6333, Acc: 31.16% | Val Loss: 0.6380, Acc: 42.72%\n",
      "Final Validation score: 0.4262\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4262\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.004641588833612777, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1389, Acc: -19.56% | Val Loss: 0.7811, Acc: -6.14%\n",
      "Epoch 10: Train Loss: 0.7636, Acc: 23.62% | Val Loss: 0.5914, Acc: 19.64%\n",
      "Epoch 20: Train Loss: 0.6996, Acc: 30.98% | Val Loss: 0.5602, Acc: 23.88%\n",
      "Epoch 30: Train Loss: 0.7040, Acc: 31.16% | Val Loss: 0.5464, Acc: 25.76%\n",
      "Epoch 40: Train Loss: 0.6879, Acc: 31.05% | Val Loss: 0.5370, Acc: 27.03%\n",
      "Epoch 50: Train Loss: 0.6834, Acc: 33.12% | Val Loss: 0.5331, Acc: 27.57%\n",
      "Epoch 60: Train Loss: 0.6852, Acc: 33.34% | Val Loss: 0.5328, Acc: 27.61%\n",
      "Epoch 70: Train Loss: 0.7005, Acc: 31.84% | Val Loss: 0.5309, Acc: 27.86%\n",
      "Epoch 80: Train Loss: 0.6709, Acc: 34.43% | Val Loss: 0.5298, Acc: 28.01%\n",
      "Epoch 90: Train Loss: 0.6609, Acc: 34.10% | Val Loss: 0.5279, Acc: 28.27%\n",
      "Final Validation score: 0.2795\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2795\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.004641588833612777, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1565, Acc: -28.49% | Val Loss: 1.1790, Acc: -9.65%\n",
      "Epoch 10: Train Loss: 0.6682, Acc: 29.46% | Val Loss: 0.7720, Acc: 28.20%\n",
      "Epoch 20: Train Loss: 0.6275, Acc: 33.12% | Val Loss: 0.7276, Acc: 32.33%\n",
      "Epoch 30: Train Loss: 0.6386, Acc: 31.80% | Val Loss: 0.7136, Acc: 33.64%\n",
      "Epoch 40: Train Loss: 0.6190, Acc: 34.03% | Val Loss: 0.7052, Acc: 34.42%\n",
      "Epoch 50: Train Loss: 0.6227, Acc: 33.20% | Val Loss: 0.7017, Acc: 34.74%\n",
      "Epoch 60: Train Loss: 0.6418, Acc: 30.88% | Val Loss: 0.6979, Acc: 35.09%\n",
      "Epoch 70: Train Loss: 0.6069, Acc: 36.17% | Val Loss: 0.6968, Acc: 35.19%\n",
      "Epoch 80: Train Loss: 0.6173, Acc: 34.84% | Val Loss: 0.6895, Acc: 35.87%\n",
      "Epoch 90: Train Loss: 0.6274, Acc: 33.05% | Val Loss: 0.6885, Acc: 35.97%\n",
      "Final Validation score: 0.3602\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.3602\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.012915496650148827 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.004641588833612777, 'l2': 2.782559402207126e-05, 'dropout_rate': 0.012915496650148827, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1311, Acc: -24.27% | Val Loss: 1.0309, Acc: 0.23%\n",
      "Epoch 10: Train Loss: 0.6819, Acc: 25.22% | Val Loss: 0.6508, Acc: 37.01%\n",
      "Epoch 20: Train Loss: 0.6823, Acc: 26.36% | Val Loss: 0.6299, Acc: 39.04%\n",
      "Epoch 30: Train Loss: 0.6820, Acc: 25.63% | Val Loss: 0.6263, Acc: 39.39%\n",
      "Epoch 40: Train Loss: 0.6579, Acc: 28.07% | Val Loss: 0.6190, Acc: 40.10%\n",
      "Epoch 50: Train Loss: 0.6509, Acc: 31.72% | Val Loss: 0.6133, Acc: 40.64%\n",
      "Epoch 60: Train Loss: 0.6556, Acc: 27.37% | Val Loss: 0.5995, Acc: 41.98%\n",
      "Epoch 70: Train Loss: 0.6352, Acc: 31.41% | Val Loss: 0.5962, Acc: 42.30%\n",
      "Epoch 80: Train Loss: 0.6344, Acc: 29.89% | Val Loss: 0.5885, Acc: 43.04%\n",
      "Epoch 90: Train Loss: 0.6397, Acc: 30.93% | Val Loss: 0.5893, Acc: 42.96%\n",
      "Final Validation score: 0.4347\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4347\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.3674\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0016681005372000592, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2553, Acc: -29.34% | Val Loss: 1.3068, Acc: -34.40%\n",
      "Epoch 10: Train Loss: 1.1582, Acc: -17.52% | Val Loss: 1.2114, Acc: -24.59%\n",
      "Epoch 20: Train Loss: 1.1169, Acc: -13.75% | Val Loss: 1.1583, Acc: -19.13%\n",
      "Epoch 30: Train Loss: 1.0813, Acc: -8.52% | Val Loss: 1.1133, Acc: -14.50%\n",
      "Epoch 40: Train Loss: 1.0550, Acc: -6.51% | Val Loss: 1.0780, Acc: -10.87%\n",
      "Final Validation score: -0.0832\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0832\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0016681005372000592, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2435, Acc: -33.91% | Val Loss: 1.2479, Acc: -12.05%\n",
      "Epoch 10: Train Loss: 1.0863, Acc: -13.45% | Val Loss: 1.1399, Acc: -2.35%\n",
      "Epoch 20: Train Loss: 1.0134, Acc: -6.29% | Val Loss: 1.1110, Acc: 0.25%\n",
      "Epoch 30: Train Loss: 0.9954, Acc: -5.14% | Val Loss: 1.1101, Acc: 0.33%\n",
      "Epoch 40: Train Loss: 0.9877, Acc: -3.75% | Val Loss: 1.1105, Acc: 0.30%\n",
      "Final Validation score: 0.0026\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.0026\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0016681005372000592, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2834, Acc: -23.65% | Val Loss: 1.0559, Acc: -43.47%\n",
      "Epoch 10: Train Loss: 1.1497, Acc: -9.78% | Val Loss: 0.9248, Acc: -25.66%\n",
      "Epoch 20: Train Loss: 1.1080, Acc: -5.19% | Val Loss: 0.8676, Acc: -17.88%\n",
      "Epoch 30: Train Loss: 1.0779, Acc: -2.21% | Val Loss: 0.8185, Acc: -11.22%\n",
      "Epoch 40: Train Loss: 1.0603, Acc: -0.70% | Val Loss: 0.7850, Acc: -6.67%\n",
      "Final Validation score: -0.0555\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0555\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0016681005372000592, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2513, Acc: -29.82% | Val Loss: 1.4248, Acc: -32.51%\n",
      "Epoch 10: Train Loss: 1.1456, Acc: -17.94% | Val Loss: 1.3340, Acc: -24.07%\n",
      "Epoch 20: Train Loss: 1.1025, Acc: -13.84% | Val Loss: 1.2810, Acc: -19.14%\n",
      "Epoch 30: Train Loss: 1.0711, Acc: -10.74% | Val Loss: 1.2415, Acc: -15.46%\n",
      "Epoch 40: Train Loss: 1.0484, Acc: -8.12% | Val Loss: 1.2120, Acc: -12.72%\n",
      "Final Validation score: -0.1086\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.1086\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0016681005372000592, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2196, Acc: -26.81% | Val Loss: 1.1456, Acc: -10.87%\n",
      "Epoch 10: Train Loss: 1.0437, Acc: -9.17% | Val Loss: 1.0623, Acc: -2.81%\n",
      "Epoch 20: Train Loss: 1.0057, Acc: -3.07% | Val Loss: 1.0488, Acc: -1.50%\n",
      "Epoch 30: Train Loss: 0.9926, Acc: -2.67% | Val Loss: 1.0462, Acc: -1.25%\n",
      "Epoch 40: Train Loss: 0.9866, Acc: -0.62% | Val Loss: 1.0461, Acc: -1.25%\n",
      "Final Validation score: -0.0129\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0129\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0515\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.005455594781168515, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0735, Acc: -8.82% | Val Loss: 0.9880, Acc: -1.61%\n",
      "Epoch 10: Train Loss: 1.0000, Acc: -4.28% | Val Loss: 0.9833, Acc: -1.13%\n",
      "Epoch 20: Train Loss: 0.9991, Acc: -3.81% | Val Loss: 0.9818, Acc: -0.98%\n",
      "Epoch 30: Train Loss: 0.9993, Acc: -3.98% | Val Loss: 0.9815, Acc: -0.94%\n",
      "Epoch 40: Train Loss: 0.9991, Acc: -6.03% | Val Loss: 0.9809, Acc: -0.88%\n",
      "Final Validation score: -0.0088\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0088\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.005455594781168515, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 0.9968, Acc: -8.29% | Val Loss: 1.1244, Acc: -0.95%\n",
      "Epoch 10: Train Loss: 0.9630, Acc: -4.78% | Val Loss: 1.1253, Acc: -1.03%\n",
      "Epoch 20: Train Loss: 0.9629, Acc: -3.22% | Val Loss: 1.1255, Acc: -1.05%\n",
      "Epoch 30: Train Loss: 0.9626, Acc: -4.51% | Val Loss: 1.1255, Acc: -1.05%\n",
      "Epoch 40: Train Loss: 0.9625, Acc: -2.24% | Val Loss: 1.1256, Acc: -1.07%\n",
      "Final Validation score: -0.0106\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0106\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.005455594781168515, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1252, Acc: -14.39% | Val Loss: 0.7609, Acc: -3.39%\n",
      "Epoch 10: Train Loss: 1.0556, Acc: -3.42% | Val Loss: 0.7705, Acc: -4.69%\n",
      "Epoch 20: Train Loss: 1.0561, Acc: -5.93% | Val Loss: 0.7761, Acc: -5.45%\n",
      "Epoch 30: Train Loss: 1.0554, Acc: -4.22% | Val Loss: 0.7698, Acc: -4.60%\n",
      "Epoch 40: Train Loss: 1.0551, Acc: -4.56% | Val Loss: 0.7756, Acc: -5.38%\n",
      "Final Validation score: -0.0508\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0508\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.005455594781168515, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0870, Acc: -19.86% | Val Loss: 1.0910, Acc: -1.46%\n",
      "Epoch 10: Train Loss: 0.8490, Acc: 10.91% | Val Loss: 1.0436, Acc: 2.94%\n",
      "Epoch 20: Train Loss: 0.8412, Acc: 12.99% | Val Loss: 1.0135, Acc: 5.74%\n",
      "Epoch 30: Train Loss: 0.8197, Acc: 13.27% | Val Loss: 1.0049, Acc: 6.54%\n",
      "Epoch 40: Train Loss: 0.7333, Acc: 19.22% | Val Loss: 0.8885, Acc: 17.37%\n",
      "Final Validation score: 0.2291\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2291\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 7.742636826811278e-05, 'dropout_rate': 0.0005994842503189409, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.005455594781168515, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1814, Acc: -29.54% | Val Loss: 1.0426, Acc: -0.90%\n",
      "Epoch 10: Train Loss: 0.9829, Acc: -3.92% | Val Loss: 1.0474, Acc: -1.37%\n",
      "Epoch 20: Train Loss: 0.9823, Acc: -7.13% | Val Loss: 1.0484, Acc: -1.46%\n",
      "Epoch 30: Train Loss: 0.9819, Acc: -3.31% | Val Loss: 1.0486, Acc: -1.49%\n",
      "Epoch 40: Train Loss: 0.9820, Acc: -2.83% | Val Loss: 1.0491, Acc: -1.53%\n",
      "Final Validation score: -0.0152\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0152\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.0287\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1539, Acc: -16.50% | Val Loss: 1.0692, Acc: -9.96%\n",
      "Epoch 10: Train Loss: 0.9998, Acc: -1.07% | Val Loss: 0.9854, Acc: -1.34%\n",
      "Epoch 20: Train Loss: 0.9996, Acc: -2.63% | Val Loss: 0.9844, Acc: -1.24%\n",
      "Epoch 30: Train Loss: 0.9994, Acc: -0.31% | Val Loss: 0.9838, Acc: -1.18%\n",
      "Epoch 40: Train Loss: 0.9993, Acc: -0.26% | Val Loss: 0.9835, Acc: -1.15%\n",
      "Final Validation score: -0.0112\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0112\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1666, Acc: -22.08% | Val Loss: 1.1288, Acc: -1.35%\n",
      "Epoch 10: Train Loss: 0.9662, Acc: -1.84% | Val Loss: 1.1184, Acc: -0.41%\n",
      "Epoch 20: Train Loss: 0.9649, Acc: -1.48% | Val Loss: 1.1202, Acc: -0.58%\n",
      "Epoch 30: Train Loss: 0.9643, Acc: -0.47% | Val Loss: 1.1211, Acc: -0.66%\n",
      "Early stopping at epoch 32\n",
      "Restoring model weights from epoch 2\n",
      "Final Validation score: -0.0067\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0067\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3200, Acc: -25.07% | Val Loss: 0.9602, Acc: -30.47%\n",
      "Epoch 10: Train Loss: 1.0575, Acc: -0.64% | Val Loss: 0.7670, Acc: -4.22%\n",
      "Epoch 20: Train Loss: 1.0556, Acc: 0.06% | Val Loss: 0.7679, Acc: -4.35%\n",
      "Epoch 30: Train Loss: 1.0559, Acc: -0.25% | Val Loss: 0.7691, Acc: -4.51%\n",
      "Epoch 40: Train Loss: 1.0557, Acc: -0.65% | Val Loss: 0.7701, Acc: -4.64%\n",
      "Early stopping at epoch 40\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation score: -0.0464\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0464\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1640, Acc: -19.59% | Val Loss: 1.1923, Acc: -10.89%\n",
      "Epoch 10: Train Loss: 0.9730, Acc: -0.47% | Val Loss: 1.0911, Acc: -1.47%\n",
      "Epoch 20: Train Loss: 0.9728, Acc: -0.24% | Val Loss: 1.0914, Acc: -1.51%\n",
      "Epoch 30: Train Loss: 0.9727, Acc: -1.28% | Val Loss: 1.0913, Acc: -1.50%\n",
      "Early stopping at epoch 39\n",
      "Restoring model weights from epoch 9\n",
      "Final Validation score: -0.0151\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0151\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 2.782559402207126e-05, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.06158482110660261, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2269, Acc: -26.07% | Val Loss: 1.0472, Acc: -1.35%\n",
      "Epoch 10: Train Loss: 0.9863, Acc: -0.59% | Val Loss: 1.0388, Acc: -0.54%\n",
      "Epoch 20: Train Loss: 0.9849, Acc: -0.42% | Val Loss: 1.0410, Acc: -0.75%\n",
      "Epoch 30: Train Loss: 0.9842, Acc: -0.41% | Val Loss: 1.0422, Acc: -0.87%\n",
      "Early stopping at epoch 31\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0088\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0088\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0176\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.9262, Acc: -110.13% | Val Loss: 1.9921, Acc: -104.88%\n",
      "Epoch 10: Train Loss: 0.8317, Acc: 13.63% | Val Loss: 0.7915, Acc: 18.60%\n",
      "Epoch 20: Train Loss: 0.7091, Acc: 24.51% | Val Loss: 0.7304, Acc: 24.88%\n",
      "Epoch 30: Train Loss: 0.7149, Acc: 26.71% | Val Loss: 0.7311, Acc: 24.81%\n",
      "Epoch 40: Train Loss: 0.7201, Acc: 25.56% | Val Loss: 0.7378, Acc: 24.12%\n",
      "Early stopping at epoch 49\n",
      "Restoring model weights from epoch 19\n",
      "Final Validation score: 0.2414\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.2414\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2416, Acc: -36.23% | Val Loss: 1.1384, Acc: -2.21%\n",
      "Epoch 10: Train Loss: 0.9409, Acc: -6.45% | Val Loss: 1.0962, Acc: 1.58%\n",
      "Epoch 20: Train Loss: 0.9078, Acc: -0.80% | Val Loss: 1.0294, Acc: 7.57%\n",
      "Epoch 30: Train Loss: 0.8736, Acc: 1.12% | Val Loss: 0.9793, Acc: 12.07%\n",
      "Epoch 40: Train Loss: 0.8628, Acc: 6.61% | Val Loss: 0.9625, Acc: 13.58%\n",
      "Epoch 50: Train Loss: 0.8532, Acc: 7.57% | Val Loss: 0.9479, Acc: 14.89%\n",
      "Epoch 60: Train Loss: 0.8445, Acc: 7.69% | Val Loss: 0.9347, Acc: 16.08%\n",
      "Epoch 70: Train Loss: 0.8357, Acc: 10.91% | Val Loss: 0.9219, Acc: 17.23%\n",
      "Epoch 80: Train Loss: 0.8324, Acc: 9.76% | Val Loss: 0.9039, Acc: 18.85%\n",
      "Epoch 90: Train Loss: 0.8198, Acc: 10.45% | Val Loss: 0.8768, Acc: 21.27%\n",
      "Final Validation score: 0.2337\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.2337\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.7285, Acc: -74.77% | Val Loss: 1.0537, Acc: -43.17%\n",
      "Epoch 10: Train Loss: 0.9562, Acc: 8.17% | Val Loss: 0.6022, Acc: 18.18%\n",
      "Epoch 20: Train Loss: 0.9734, Acc: 5.05% | Val Loss: 0.6229, Acc: 15.36%\n",
      "Epoch 30: Train Loss: 0.9996, Acc: 2.20% | Val Loss: 0.6366, Acc: 13.49%\n",
      "Epoch 40: Train Loss: 1.0123, Acc: 2.22% | Val Loss: 0.6645, Acc: 9.71%\n",
      "Early stopping at epoch 40\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation score: 0.0971\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.0971\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1088, Acc: -21.79% | Val Loss: 1.1736, Acc: -9.15%\n",
      "Epoch 10: Train Loss: 0.9240, Acc: 1.54% | Val Loss: 1.0481, Acc: 2.52%\n",
      "Epoch 20: Train Loss: 0.8482, Acc: 10.01% | Val Loss: 0.9944, Acc: 7.52%\n",
      "Epoch 30: Train Loss: 0.8349, Acc: 12.07% | Val Loss: 0.9996, Acc: 7.03%\n",
      "Epoch 40: Train Loss: 0.8311, Acc: 13.56% | Val Loss: 1.0018, Acc: 6.83%\n",
      "Epoch 50: Train Loss: 0.8300, Acc: 9.68% | Val Loss: 0.9993, Acc: 7.07%\n",
      "Early stopping at epoch 52\n",
      "Restoring model weights from epoch 22\n",
      "Final Validation score: 0.0696\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.0696\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 1e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.0103, Acc: -7.68% | Val Loss: 1.0313, Acc: 0.18%\n",
      "Epoch 10: Train Loss: 0.8516, Acc: 8.97% | Val Loss: 0.9223, Acc: 10.74%\n",
      "Epoch 20: Train Loss: 0.8179, Acc: 11.08% | Val Loss: 0.8482, Acc: 17.91%\n",
      "Epoch 30: Train Loss: 0.8134, Acc: 11.58% | Val Loss: 0.8421, Acc: 18.50%\n",
      "Epoch 40: Train Loss: 0.8151, Acc: 12.11% | Val Loss: 0.8546, Acc: 17.29%\n",
      "Epoch 50: Train Loss: 0.8105, Acc: 11.97% | Val Loss: 0.8580, Acc: 16.96%\n",
      "Early stopping at epoch 57\n",
      "Restoring model weights from epoch 27\n",
      "Final Validation score: 0.1749\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.1749\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.1633\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 4.281332398719396e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.4259, Acc: -53.78% | Val Loss: 1.4777, Acc: -51.97%\n",
      "Epoch 10: Train Loss: 1.0804, Acc: -12.88% | Val Loss: 1.1038, Acc: -13.52%\n",
      "Epoch 20: Train Loss: 1.0331, Acc: -9.23% | Val Loss: 1.0290, Acc: -5.83%\n",
      "Epoch 30: Train Loss: 1.0099, Acc: -3.35% | Val Loss: 1.0082, Acc: -3.69%\n",
      "Epoch 40: Train Loss: 1.0107, Acc: -3.82% | Val Loss: 0.9989, Acc: -2.73%\n",
      "Epoch 50: Train Loss: 1.0028, Acc: -4.52% | Val Loss: 0.9937, Acc: -2.20%\n",
      "Epoch 60: Train Loss: 1.0021, Acc: -4.28% | Val Loss: 0.9906, Acc: -1.88%\n",
      "Epoch 70: Train Loss: 1.0006, Acc: -7.41% | Val Loss: 0.9884, Acc: -1.66%\n",
      "Epoch 80: Train Loss: 0.9974, Acc: -2.97% | Val Loss: 0.9870, Acc: -1.51%\n",
      "Epoch 90: Train Loss: 0.9991, Acc: -2.82% | Val Loss: 0.9859, Acc: -1.40%\n",
      "Final Validation score: -0.0132\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0132\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 4.281332398719396e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1909, Acc: -36.69% | Val Loss: 1.1712, Acc: -5.15%\n",
      "Epoch 10: Train Loss: 1.0020, Acc: -9.42% | Val Loss: 1.1041, Acc: 0.87%\n",
      "Epoch 20: Train Loss: 0.9796, Acc: -5.77% | Val Loss: 1.1084, Acc: 0.48%\n",
      "Epoch 30: Train Loss: 0.9692, Acc: -3.47% | Val Loss: 1.1129, Acc: 0.08%\n",
      "Epoch 40: Train Loss: 0.9705, Acc: -3.84% | Val Loss: 1.1159, Acc: -0.19%\n",
      "Early stopping at epoch 40\n",
      "Restoring model weights from epoch 10\n",
      "Final Validation score: -0.0019\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0019\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 4.281332398719396e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.3423, Acc: -33.68% | Val Loss: 1.2849, Acc: -74.59%\n",
      "Epoch 10: Train Loss: 1.1225, Acc: -12.25% | Val Loss: 0.9414, Acc: -27.92%\n",
      "Epoch 20: Train Loss: 1.0711, Acc: -5.61% | Val Loss: 0.8312, Acc: -12.94%\n",
      "Epoch 30: Train Loss: 1.0605, Acc: -5.94% | Val Loss: 0.8012, Acc: -8.87%\n",
      "Epoch 40: Train Loss: 1.0588, Acc: -5.16% | Val Loss: 0.7888, Acc: -7.19%\n",
      "Epoch 50: Train Loss: 1.0580, Acc: -3.89% | Val Loss: 0.7814, Acc: -6.17%\n",
      "Epoch 60: Train Loss: 1.0578, Acc: -2.65% | Val Loss: 0.7785, Acc: -5.78%\n",
      "Epoch 70: Train Loss: 1.0550, Acc: -3.84% | Val Loss: 0.7764, Acc: -5.49%\n",
      "Epoch 80: Train Loss: 1.0593, Acc: -6.06% | Val Loss: 0.7732, Acc: -5.06%\n",
      "Epoch 90: Train Loss: 1.0568, Acc: -8.67% | Val Loss: 0.7728, Acc: -5.01%\n",
      "Final Validation score: -0.0500\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0500\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 4.281332398719396e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0163, Acc: -9.23% | Val Loss: 1.1479, Acc: -6.75%\n",
      "Epoch 10: Train Loss: 0.9841, Acc: -4.46% | Val Loss: 1.1090, Acc: -3.14%\n",
      "Epoch 20: Train Loss: 0.9734, Acc: -1.98% | Val Loss: 1.0988, Acc: -2.19%\n",
      "Epoch 30: Train Loss: 0.9756, Acc: -5.65% | Val Loss: 1.0947, Acc: -1.81%\n",
      "Epoch 40: Train Loss: 0.9736, Acc: -5.48% | Val Loss: 1.0929, Acc: -1.65%\n",
      "Epoch 50: Train Loss: 0.9708, Acc: -4.49% | Val Loss: 1.0913, Acc: -1.49%\n",
      "Epoch 60: Train Loss: 0.9708, Acc: -3.31% | Val Loss: 1.0910, Acc: -1.46%\n",
      "Epoch 70: Train Loss: 0.9768, Acc: -5.66% | Val Loss: 1.0896, Acc: -1.33%\n",
      "Epoch 80: Train Loss: 0.9759, Acc: -4.65% | Val Loss: 1.0891, Acc: -1.29%\n",
      "Epoch 90: Train Loss: 0.9733, Acc: -2.26% | Val Loss: 1.0886, Acc: -1.24%\n",
      "Final Validation score: -0.0122\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0122\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 0.03593813663804626, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 4.281332398719396e-05, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.4599, Acc: -64.02% | Val Loss: 1.2969, Acc: -25.51%\n",
      "Epoch 10: Train Loss: 1.0632, Acc: -20.08% | Val Loss: 1.0533, Acc: -1.94%\n",
      "Epoch 20: Train Loss: 1.0174, Acc: -6.79% | Val Loss: 1.0386, Acc: -0.52%\n",
      "Epoch 30: Train Loss: 1.0002, Acc: -4.94% | Val Loss: 1.0377, Acc: -0.43%\n",
      "Epoch 40: Train Loss: 0.9953, Acc: -8.28% | Val Loss: 1.0394, Acc: -0.60%\n",
      "Epoch 50: Train Loss: 0.9871, Acc: -4.29% | Val Loss: 1.0412, Acc: -0.77%\n",
      "Early stopping at epoch 54\n",
      "Restoring model weights from epoch 24\n",
      "Final Validation score: -0.0081\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0081\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0171\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0005994842503189409, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.3631, Acc: -37.54% | Val Loss: 1.4413, Acc: -48.23%\n",
      "Epoch 10: Train Loss: 1.2955, Acc: -30.35% | Val Loss: 1.3596, Acc: -39.83%\n",
      "Epoch 20: Train Loss: 1.2367, Acc: -25.38% | Val Loss: 1.2913, Acc: -32.81%\n",
      "Epoch 30: Train Loss: 1.1861, Acc: -22.93% | Val Loss: 1.2341, Acc: -26.92%\n",
      "Epoch 40: Train Loss: 1.1448, Acc: -16.51% | Val Loss: 1.1870, Acc: -22.08%\n",
      "Epoch 50: Train Loss: 1.1163, Acc: -13.60% | Val Loss: 1.1489, Acc: -18.17%\n",
      "Epoch 60: Train Loss: 1.0995, Acc: -12.32% | Val Loss: 1.1191, Acc: -15.09%\n",
      "Epoch 70: Train Loss: 1.0763, Acc: -8.19% | Val Loss: 1.0957, Acc: -12.69%\n",
      "Epoch 80: Train Loss: 1.0579, Acc: -6.02% | Val Loss: 1.0777, Acc: -10.84%\n",
      "Epoch 90: Train Loss: 1.0546, Acc: -7.33% | Val Loss: 1.0639, Acc: -9.42%\n",
      "Final Validation score: -0.0838\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0838\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0005994842503189409, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0679, Acc: -11.49% | Val Loss: 1.1366, Acc: -2.05%\n",
      "Epoch 10: Train Loss: 1.0513, Acc: -9.55% | Val Loss: 1.1244, Acc: -0.95%\n",
      "Epoch 20: Train Loss: 1.0255, Acc: -6.95% | Val Loss: 1.1169, Acc: -0.28%\n",
      "Epoch 30: Train Loss: 1.0066, Acc: -5.22% | Val Loss: 1.1129, Acc: 0.08%\n",
      "Epoch 40: Train Loss: 0.9969, Acc: -3.64% | Val Loss: 1.1110, Acc: 0.25%\n",
      "Epoch 50: Train Loss: 0.9978, Acc: -5.60% | Val Loss: 1.1103, Acc: 0.31%\n",
      "Epoch 60: Train Loss: 0.9967, Acc: -4.78% | Val Loss: 1.1103, Acc: 0.32%\n",
      "Epoch 70: Train Loss: 0.9753, Acc: -2.06% | Val Loss: 1.1105, Acc: 0.29%\n",
      "Epoch 80: Train Loss: 0.9813, Acc: -3.11% | Val Loss: 1.1110, Acc: 0.25%\n",
      "Epoch 90: Train Loss: 0.9832, Acc: -2.35% | Val Loss: 1.1115, Acc: 0.21%\n",
      "Final Validation score: 0.0016\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.0016\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0005994842503189409, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.4145, Acc: -35.47% | Val Loss: 1.1653, Acc: -58.34%\n",
      "Epoch 10: Train Loss: 1.3586, Acc: -30.75% | Val Loss: 1.1032, Acc: -49.90%\n",
      "Epoch 20: Train Loss: 1.3098, Acc: -24.66% | Val Loss: 1.0518, Acc: -42.92%\n",
      "Epoch 30: Train Loss: 1.2711, Acc: -20.67% | Val Loss: 1.0089, Acc: -37.09%\n",
      "Epoch 40: Train Loss: 1.2417, Acc: -19.02% | Val Loss: 0.9730, Acc: -32.21%\n",
      "Epoch 50: Train Loss: 1.2134, Acc: -15.00% | Val Loss: 0.9418, Acc: -27.97%\n",
      "Epoch 60: Train Loss: 1.1899, Acc: -12.90% | Val Loss: 0.9155, Acc: -24.40%\n",
      "Epoch 70: Train Loss: 1.1688, Acc: -12.06% | Val Loss: 0.8926, Acc: -21.29%\n",
      "Epoch 80: Train Loss: 1.1573, Acc: -10.63% | Val Loss: 0.8733, Acc: -18.67%\n",
      "Epoch 90: Train Loss: 1.1478, Acc: -8.78% | Val Loss: 0.8569, Acc: -16.43%\n",
      "Final Validation score: -0.1469\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.1469\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0005994842503189409, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1836, Acc: -23.65% | Val Loss: 1.3486, Acc: -25.43%\n",
      "Epoch 10: Train Loss: 1.1282, Acc: -16.66% | Val Loss: 1.2896, Acc: -19.93%\n",
      "Epoch 20: Train Loss: 1.0990, Acc: -14.14% | Val Loss: 1.2476, Acc: -16.03%\n",
      "Epoch 30: Train Loss: 1.0630, Acc: -10.23% | Val Loss: 1.2164, Acc: -13.13%\n",
      "Epoch 40: Train Loss: 1.0456, Acc: -8.08% | Val Loss: 1.1924, Acc: -10.89%\n",
      "Epoch 50: Train Loss: 1.0315, Acc: -6.81% | Val Loss: 1.1743, Acc: -9.21%\n",
      "Epoch 60: Train Loss: 1.0200, Acc: -4.97% | Val Loss: 1.1602, Acc: -7.90%\n",
      "Epoch 70: Train Loss: 1.0080, Acc: -3.96% | Val Loss: 1.1494, Acc: -6.89%\n",
      "Epoch 80: Train Loss: 1.0069, Acc: -3.80% | Val Loss: 1.1409, Acc: -6.11%\n",
      "Epoch 90: Train Loss: 0.9966, Acc: -2.90% | Val Loss: 1.1343, Acc: -5.49%\n",
      "Final Validation score: -0.0504\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0504\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0005994842503189409, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.4634, Acc: -51.68% | Val Loss: 1.3428, Acc: -29.96%\n",
      "Epoch 10: Train Loss: 1.3933, Acc: -44.63% | Val Loss: 1.2827, Acc: -24.14%\n",
      "Epoch 20: Train Loss: 1.3236, Acc: -36.18% | Val Loss: 1.2294, Acc: -18.98%\n",
      "Epoch 30: Train Loss: 1.2704, Acc: -31.67% | Val Loss: 1.1844, Acc: -14.63%\n",
      "Epoch 40: Train Loss: 1.2149, Acc: -25.85% | Val Loss: 1.1483, Acc: -11.13%\n",
      "Epoch 50: Train Loss: 1.1779, Acc: -20.72% | Val Loss: 1.1208, Acc: -8.47%\n",
      "Epoch 60: Train Loss: 1.1469, Acc: -17.64% | Val Loss: 1.1003, Acc: -6.49%\n",
      "Epoch 70: Train Loss: 1.1230, Acc: -17.38% | Val Loss: 1.0852, Acc: -5.03%\n",
      "Epoch 80: Train Loss: 1.1025, Acc: -12.77% | Val Loss: 1.0741, Acc: -3.95%\n",
      "Epoch 90: Train Loss: 1.0931, Acc: -12.78% | Val Loss: 1.0657, Acc: -3.15%\n",
      "Final Validation score: -0.0260\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0260\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0611\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.1, 'l2': 0.00021544346900318823, 'dropout_rate': 0.0016681005372000592, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 4.281332398719396e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1193, Acc: -14.46% | Val Loss: 1.0414, Acc: -7.11%\n",
      "Epoch 10: Train Loss: 0.9992, Acc: -0.86% | Val Loss: 0.9790, Acc: -0.69%\n",
      "Epoch 20: Train Loss: 0.9992, Acc: -3.31% | Val Loss: 0.9791, Acc: -0.70%\n",
      "Early stopping at epoch 21\n",
      "Restoring model weights from epoch 11\n",
      "Final Validation score: -0.0072\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0072\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.1, 'l2': 0.00021544346900318823, 'dropout_rate': 0.0016681005372000592, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 4.281332398719396e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1124, Acc: -25.20% | Val Loss: 1.1478, Acc: -3.06%\n",
      "Epoch 10: Train Loss: 0.9625, Acc: -1.53% | Val Loss: 1.1257, Acc: -1.07%\n",
      "Early stopping at epoch 15\n",
      "Restoring model weights from epoch 5\n",
      "Final Validation score: -0.0107\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0107\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.1, 'l2': 0.00021544346900318823, 'dropout_rate': 0.0016681005372000592, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 4.281332398719396e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1651, Acc: -12.17% | Val Loss: 0.7663, Acc: -4.12%\n",
      "Epoch 10: Train Loss: 1.0560, Acc: -0.25% | Val Loss: 0.7624, Acc: -3.60%\n",
      "Early stopping at epoch 11\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0595\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0595\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.1, 'l2': 0.00021544346900318823, 'dropout_rate': 0.0016681005372000592, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 4.281332398719396e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1102, Acc: -16.12% | Val Loss: 1.1692, Acc: -8.73%\n",
      "Epoch 10: Train Loss: 0.9725, Acc: -1.23% | Val Loss: 1.0884, Acc: -1.22%\n",
      "Early stopping at epoch 14\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation score: -0.0127\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0127\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.1, 'l2': 0.00021544346900318823, 'dropout_rate': 0.0016681005372000592, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 4.281332398719396e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1764, Acc: -23.16% | Val Loss: 1.0486, Acc: -1.49%\n",
      "Epoch 10: Train Loss: 0.9819, Acc: -2.33% | Val Loss: 1.0477, Acc: -1.40%\n",
      "Early stopping at epoch 11\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0140\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0140\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0208\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.4555, Acc: -46.53% | Val Loss: 1.4772, Acc: -51.93%\n",
      "Epoch 10: Train Loss: 0.9624, Acc: 2.56% | Val Loss: 1.0078, Acc: -3.65%\n",
      "Epoch 20: Train Loss: 0.9719, Acc: 1.68% | Val Loss: 0.9947, Acc: -2.30%\n",
      "Early stopping at epoch 26\n",
      "Restoring model weights from epoch 16\n",
      "Final Validation score: -0.0488\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0488\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.3546, Acc: -44.61% | Val Loss: 1.4086, Acc: -26.47%\n",
      "Epoch 10: Train Loss: 0.9829, Acc: -2.45% | Val Loss: 1.0475, Acc: 5.95%\n",
      "Epoch 20: Train Loss: 0.9216, Acc: 4.10% | Val Loss: 1.0549, Acc: 5.29%\n",
      "Early stopping at epoch 22\n",
      "Restoring model weights from epoch 12\n",
      "Final Validation score: 0.0489\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.0489\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.4377, Acc: -35.81% | Val Loss: 1.2513, Acc: -70.03%\n",
      "Epoch 10: Train Loss: 0.9700, Acc: 7.95% | Val Loss: 0.7695, Acc: -4.56%\n",
      "Early stopping at epoch 19\n",
      "Restoring model weights from epoch 9\n",
      "Final Validation score: -0.1011\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.1011\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1074, Acc: -14.26% | Val Loss: 1.1886, Acc: -10.54%\n",
      "Epoch 10: Train Loss: 0.8875, Acc: 8.84% | Val Loss: 1.0401, Acc: 3.27%\n",
      "Epoch 20: Train Loss: 0.9080, Acc: 5.44% | Val Loss: 1.0708, Acc: 0.41%\n",
      "Early stopping at epoch 22\n",
      "Restoring model weights from epoch 12\n",
      "Final Validation score: -0.0029\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0029\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 0.03593813663804626, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2294, Acc: -26.59% | Val Loss: 0.9778, Acc: 5.37%\n",
      "Epoch 10: Train Loss: 0.9158, Acc: 4.85% | Val Loss: 0.8988, Acc: 13.01%\n",
      "Early stopping at epoch 14\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation score: 0.0878\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.0878\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0032\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.04832930238571752, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1350, Acc: -14.32% | Val Loss: 0.9707, Acc: 0.17%\n",
      "Epoch 10: Train Loss: 0.8573, Acc: 11.62% | Val Loss: 0.9098, Acc: 6.43%\n",
      "Epoch 20: Train Loss: 0.8278, Acc: 16.06% | Val Loss: 0.8631, Acc: 11.23%\n",
      "Epoch 30: Train Loss: 0.7885, Acc: 19.46% | Val Loss: 0.8538, Acc: 12.18%\n",
      "Epoch 40: Train Loss: 0.7966, Acc: 19.44% | Val Loss: 0.8578, Acc: 11.78%\n",
      "Epoch 50: Train Loss: 0.8011, Acc: 17.85% | Val Loss: 0.8583, Acc: 11.73%\n",
      "Epoch 60: Train Loss: 0.8461, Acc: 13.39% | Val Loss: 0.8707, Acc: 10.46%\n",
      "Epoch 70: Train Loss: 0.7846, Acc: 19.61% | Val Loss: 0.8535, Acc: 12.22%\n",
      "Epoch 80: Train Loss: 0.7860, Acc: 19.52% | Val Loss: 0.8548, Acc: 12.08%\n",
      "Epoch 90: Train Loss: 0.7868, Acc: 18.94% | Val Loss: 0.8541, Acc: 12.15%\n",
      "Early stopping at epoch 99\n",
      "Restoring model weights from epoch 69\n",
      "Final Validation score: 0.1286\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1286\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.04832930238571752, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1569, Acc: -23.18% | Val Loss: 1.1692, Acc: -4.98%\n",
      "Epoch 10: Train Loss: 0.9629, Acc: -1.22% | Val Loss: 1.1248, Acc: -0.99%\n",
      "Epoch 20: Train Loss: 0.9621, Acc: -2.55% | Val Loss: 1.1254, Acc: -1.04%\n",
      "Epoch 30: Train Loss: 0.9625, Acc: -1.65% | Val Loss: 1.1256, Acc: -1.06%\n",
      "Early stopping at epoch 33\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0106\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0106\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.04832930238571752, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1523, Acc: -12.63% | Val Loss: 0.7210, Acc: 2.03%\n",
      "Epoch 10: Train Loss: 0.9055, Acc: 13.74% | Val Loss: 0.6548, Acc: 11.02%\n",
      "Epoch 20: Train Loss: 0.8894, Acc: 14.25% | Val Loss: 0.6584, Acc: 10.54%\n",
      "Epoch 30: Train Loss: 0.8811, Acc: 15.77% | Val Loss: 0.6515, Acc: 11.47%\n",
      "Epoch 40: Train Loss: 0.8836, Acc: 15.30% | Val Loss: 0.6465, Acc: 12.16%\n",
      "Epoch 50: Train Loss: 0.8792, Acc: 15.78% | Val Loss: 0.6258, Acc: 14.97%\n",
      "Epoch 60: Train Loss: 0.8864, Acc: 14.33% | Val Loss: 0.6123, Acc: 16.80%\n",
      "Epoch 70: Train Loss: 0.8694, Acc: 16.41% | Val Loss: 0.6121, Acc: 16.83%\n",
      "Epoch 80: Train Loss: 0.8605, Acc: 17.22% | Val Loss: 0.6248, Acc: 15.10%\n",
      "Epoch 90: Train Loss: 0.8527, Acc: 18.02% | Val Loss: 0.6119, Acc: 16.86%\n",
      "Early stopping at epoch 91\n",
      "Restoring model weights from epoch 61\n",
      "Final Validation score: 0.1728\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.1728\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.04832930238571752, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2331, Acc: -29.99% | Val Loss: 1.1397, Acc: -5.99%\n",
      "Epoch 10: Train Loss: 0.9728, Acc: -1.30% | Val Loss: 1.0895, Acc: -1.33%\n",
      "Epoch 20: Train Loss: 0.9725, Acc: -1.04% | Val Loss: 1.0907, Acc: -1.43%\n",
      "Epoch 30: Train Loss: 0.9737, Acc: -2.09% | Val Loss: 1.0905, Acc: -1.42%\n",
      "Epoch 40: Train Loss: 0.9724, Acc: -1.49% | Val Loss: 1.0918, Acc: -1.54%\n",
      "Early stopping at epoch 47\n",
      "Restoring model weights from epoch 17\n",
      "Final Validation score: -0.0137\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0137\n",
      "6 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.04832930238571752, 'l1': 0.012915496650148827, 'l2': 0.03593813663804626, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.9647, Acc: -0.68% | Val Loss: 0.9225, Acc: 10.72%\n",
      "Epoch 10: Train Loss: 0.7941, Acc: 15.40% | Val Loss: 0.7656, Acc: 25.91%\n",
      "Epoch 20: Train Loss: 0.7668, Acc: 20.41% | Val Loss: 0.7357, Acc: 28.80%\n",
      "Epoch 30: Train Loss: 0.7642, Acc: 20.78% | Val Loss: 0.7207, Acc: 30.25%\n",
      "Epoch 40: Train Loss: 0.7709, Acc: 19.81% | Val Loss: 0.7087, Acc: 31.41%\n",
      "Epoch 50: Train Loss: 0.7773, Acc: 20.23% | Val Loss: 0.7127, Acc: 31.03%\n",
      "Epoch 60: Train Loss: 0.7532, Acc: 21.77% | Val Loss: 0.7339, Acc: 28.97%\n",
      "Epoch 70: Train Loss: 0.7565, Acc: 21.86% | Val Loss: 0.7257, Acc: 29.76%\n",
      "Epoch 80: Train Loss: 0.7554, Acc: 21.27% | Val Loss: 0.7119, Acc: 31.10%\n",
      "Epoch 90: Train Loss: 0.7520, Acc: 21.54% | Val Loss: 0.7063, Acc: 31.64%\n",
      "Early stopping at epoch 97\n",
      "Restoring model weights from epoch 67\n",
      "Final Validation score: 0.3142\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3142\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.1183\n",
      "4 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 7.742636826811278e-05, 'l2': 0.03593813663804626, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2243, Acc: -30.97% | Val Loss: 1.1852, Acc: -21.90%\n",
      "Epoch 10: Train Loss: 0.8534, Acc: 11.18% | Val Loss: 0.8425, Acc: 13.35%\n",
      "Epoch 20: Train Loss: 0.7917, Acc: 16.45% | Val Loss: 0.7855, Acc: 19.22%\n",
      "Epoch 30: Train Loss: 0.7508, Acc: 20.95% | Val Loss: 0.7621, Acc: 21.62%\n",
      "Epoch 40: Train Loss: 0.7404, Acc: 21.12% | Val Loss: 0.7536, Acc: 22.49%\n",
      "Final Validation score: 0.2272\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.2272\n",
      "4 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 7.742636826811278e-05, 'l2': 0.03593813663804626, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1188, Acc: -26.84% | Val Loss: 1.1074, Acc: 0.58%\n",
      "Epoch 10: Train Loss: 0.7644, Acc: 15.87% | Val Loss: 0.8129, Acc: 27.02%\n",
      "Epoch 20: Train Loss: 0.7211, Acc: 21.20% | Val Loss: 0.7733, Acc: 30.57%\n",
      "Epoch 30: Train Loss: 0.7081, Acc: 21.74% | Val Loss: 0.7506, Acc: 32.61%\n",
      "Epoch 40: Train Loss: 0.6923, Acc: 24.34% | Val Loss: 0.7445, Acc: 33.16%\n",
      "Final Validation score: 0.3263\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.3263\n",
      "4 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 7.742636826811278e-05, 'l2': 0.03593813663804626, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2779, Acc: -25.06% | Val Loss: 0.9612, Acc: -30.60%\n",
      "Epoch 10: Train Loss: 0.8546, Acc: 16.00% | Val Loss: 0.7160, Acc: 2.72%\n",
      "Epoch 20: Train Loss: 0.8126, Acc: 18.14% | Val Loss: 0.6978, Acc: 5.19%\n",
      "Epoch 30: Train Loss: 0.7783, Acc: 22.96% | Val Loss: 0.6692, Acc: 9.07%\n",
      "Epoch 40: Train Loss: 0.7457, Acc: 26.01% | Val Loss: 0.6389, Acc: 13.19%\n",
      "Final Validation score: 0.1463\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.1463\n",
      "4 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 7.742636826811278e-05, 'l2': 0.03593813663804626, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3453, Acc: -45.54% | Val Loss: 1.4716, Acc: -36.87%\n",
      "Epoch 10: Train Loss: 0.8661, Acc: 7.62% | Val Loss: 1.0361, Acc: 3.64%\n",
      "Epoch 20: Train Loss: 0.8501, Acc: 7.82% | Val Loss: 1.0202, Acc: 5.12%\n",
      "Epoch 30: Train Loss: 0.8288, Acc: 12.90% | Val Loss: 0.9917, Acc: 7.77%\n",
      "Epoch 40: Train Loss: 0.8149, Acc: 13.50% | Val Loss: 0.9571, Acc: 10.99%\n",
      "Final Validation score: 0.1257\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.1257\n",
      "4 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 7.742636826811278e-05, 'l2': 0.03593813663804626, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.0626, Acc: -15.06% | Val Loss: 0.9172, Acc: 11.23%\n",
      "Epoch 10: Train Loss: 0.7867, Acc: 11.32% | Val Loss: 0.7999, Acc: 22.58%\n",
      "Epoch 20: Train Loss: 0.7528, Acc: 16.16% | Val Loss: 0.7830, Acc: 24.22%\n",
      "Epoch 30: Train Loss: 0.7466, Acc: 20.31% | Val Loss: 0.7744, Acc: 25.05%\n",
      "Epoch 40: Train Loss: 0.7389, Acc: 22.00% | Val Loss: 0.7712, Acc: 25.36%\n",
      "Final Validation score: 0.2561\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.2561\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.2163\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 1e-05, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2631, Acc: -34.04% | Val Loss: 1.2964, Acc: -33.33%\n",
      "Epoch 10: Train Loss: 1.0319, Acc: -9.01% | Val Loss: 1.0421, Acc: -7.18%\n",
      "Epoch 20: Train Loss: 1.0120, Acc: -5.75% | Val Loss: 1.0120, Acc: -4.08%\n",
      "Epoch 30: Train Loss: 1.0060, Acc: -4.43% | Val Loss: 1.0016, Acc: -3.01%\n",
      "Epoch 40: Train Loss: 1.0034, Acc: -2.86% | Val Loss: 0.9962, Acc: -2.45%\n",
      "Final Validation score: -0.0213\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0213\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 1e-05, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 0.9966, Acc: -8.98% | Val Loss: 1.1245, Acc: -0.96%\n",
      "Epoch 10: Train Loss: 0.9688, Acc: -5.61% | Val Loss: 1.1192, Acc: -0.49%\n",
      "Epoch 20: Train Loss: 0.9660, Acc: -4.57% | Val Loss: 1.1211, Acc: -0.66%\n",
      "Epoch 30: Train Loss: 0.9649, Acc: -4.14% | Val Loss: 1.1224, Acc: -0.77%\n",
      "Early stopping at epoch 34\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation score: -0.0078\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0078\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 1e-05, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1618, Acc: -14.88% | Val Loss: 0.8945, Acc: -21.54%\n",
      "Epoch 10: Train Loss: 1.0678, Acc: -7.46% | Val Loss: 0.7888, Acc: -7.18%\n",
      "Epoch 20: Train Loss: 1.0609, Acc: -3.04% | Val Loss: 0.7782, Acc: -5.74%\n",
      "Epoch 30: Train Loss: 1.0586, Acc: -3.52% | Val Loss: 0.7753, Acc: -5.34%\n",
      "Epoch 40: Train Loss: 1.0575, Acc: -1.84% | Val Loss: 0.7746, Acc: -5.25%\n",
      "Final Validation score: -0.0516\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0516\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 1e-05, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.4474, Acc: -61.84% | Val Loss: 1.6383, Acc: -52.37%\n",
      "Epoch 10: Train Loss: 1.0429, Acc: -10.55% | Val Loss: 1.2183, Acc: -13.31%\n",
      "Epoch 20: Train Loss: 0.9957, Acc: -5.79% | Val Loss: 1.1452, Acc: -6.51%\n",
      "Epoch 30: Train Loss: 0.9836, Acc: -5.75% | Val Loss: 1.1225, Acc: -4.40%\n",
      "Epoch 40: Train Loss: 0.9791, Acc: -4.52% | Val Loss: 1.1118, Acc: -3.40%\n",
      "Final Validation score: -0.0294\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0294\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 1e-05, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 8, 'n_epochs': 50, 'weight_decay': 0.00011288378916846884, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2747, Acc: -48.05% | Val Loss: 1.2042, Acc: -16.55%\n",
      "Epoch 10: Train Loss: 1.0282, Acc: -13.11% | Val Loss: 1.0471, Acc: -1.34%\n",
      "Epoch 20: Train Loss: 0.9994, Acc: -7.47% | Val Loss: 1.0416, Acc: -0.81%\n",
      "Epoch 30: Train Loss: 0.9920, Acc: -3.81% | Val Loss: 1.0421, Acc: -0.86%\n",
      "Epoch 40: Train Loss: 0.9888, Acc: -4.20% | Val Loss: 1.0431, Acc: -0.96%\n",
      "Final Validation score: -0.0103\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0103\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0241\n",
      "4 <class 'src.activation_functions.Activation_Sigmoid'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2890, Acc: -30.96% | Val Loss: 1.1936, Acc: -22.76%\n",
      "Epoch 10: Train Loss: 0.9989, Acc: -1.38% | Val Loss: 0.9872, Acc: -1.53%\n",
      "Epoch 20: Train Loss: 1.0010, Acc: -0.88% | Val Loss: 0.9843, Acc: -1.23%\n",
      "Epoch 30: Train Loss: 0.9991, Acc: -1.42% | Val Loss: 0.9827, Acc: -1.07%\n",
      "Epoch 40: Train Loss: 0.9992, Acc: -1.20% | Val Loss: 0.9820, Acc: -1.00%\n",
      "Final Validation score: -0.0095\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0095\n",
      "4 <class 'src.activation_functions.Activation_Sigmoid'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1755, Acc: -29.45% | Val Loss: 1.1780, Acc: -5.77%\n",
      "Epoch 10: Train Loss: 0.9638, Acc: -1.28% | Val Loss: 1.1238, Acc: -0.90%\n",
      "Epoch 20: Train Loss: 0.9636, Acc: -1.43% | Val Loss: 1.1246, Acc: -0.97%\n",
      "Epoch 30: Train Loss: 0.9633, Acc: -2.74% | Val Loss: 1.1250, Acc: -1.01%\n",
      "Early stopping at epoch 33\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0102\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0102\n",
      "4 <class 'src.activation_functions.Activation_Sigmoid'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1887, Acc: -15.63% | Val Loss: 0.9252, Acc: -25.72%\n",
      "Epoch 10: Train Loss: 1.0559, Acc: -0.97% | Val Loss: 0.7720, Acc: -4.89%\n",
      "Epoch 20: Train Loss: 1.0563, Acc: -1.21% | Val Loss: 0.7726, Acc: -4.98%\n",
      "Epoch 30: Train Loss: 1.0545, Acc: -0.09% | Val Loss: 0.7726, Acc: -4.98%\n",
      "Epoch 40: Train Loss: 1.0545, Acc: -1.23% | Val Loss: 0.7730, Acc: -5.03%\n",
      "Final Validation score: -0.0512\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0512\n",
      "4 <class 'src.activation_functions.Activation_Sigmoid'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1337, Acc: -19.60% | Val Loss: 1.2171, Acc: -13.19%\n",
      "Epoch 10: Train Loss: 0.9725, Acc: -2.60% | Val Loss: 1.0908, Acc: -1.45%\n",
      "Epoch 20: Train Loss: 0.9722, Acc: -1.41% | Val Loss: 1.0917, Acc: -1.53%\n",
      "Epoch 30: Train Loss: 0.9718, Acc: -1.40% | Val Loss: 1.0918, Acc: -1.54%\n",
      "Early stopping at epoch 37\n",
      "Restoring model weights from epoch 7\n",
      "Final Validation score: -0.0147\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0147\n",
      "4 <class 'src.activation_functions.Activation_Sigmoid'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 0.004641588833612777, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2195, Acc: -29.19% | Val Loss: 1.0597, Acc: -2.56%\n",
      "Epoch 10: Train Loss: 0.9838, Acc: -0.50% | Val Loss: 1.0448, Acc: -1.12%\n",
      "Epoch 20: Train Loss: 0.9823, Acc: -4.22% | Val Loss: 1.0468, Acc: -1.31%\n",
      "Epoch 30: Train Loss: 0.9828, Acc: -2.43% | Val Loss: 1.0476, Acc: -1.39%\n",
      "Early stopping at epoch 32\n",
      "Restoring model weights from epoch 2\n",
      "Final Validation score: -0.0141\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0141\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0199\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2427, Acc: -26.37% | Val Loss: 1.2162, Acc: -25.08%\n",
      "Epoch 10: Train Loss: 1.0185, Acc: -4.30% | Val Loss: 1.0247, Acc: -5.38%\n",
      "Epoch 20: Train Loss: 1.0109, Acc: -2.28% | Val Loss: 1.0121, Acc: -4.09%\n",
      "Epoch 30: Train Loss: 1.0079, Acc: -2.34% | Val Loss: 1.0067, Acc: -3.54%\n",
      "Epoch 40: Train Loss: 1.0064, Acc: -1.85% | Val Loss: 1.0037, Acc: -3.23%\n",
      "Final Validation score: -0.0303\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0303\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1278, Acc: -18.79% | Val Loss: 1.1311, Acc: -1.56%\n",
      "Epoch 10: Train Loss: 0.9764, Acc: -4.41% | Val Loss: 1.1119, Acc: 0.17%\n",
      "Early stopping at epoch 12\n",
      "Restoring model weights from epoch 2\n",
      "Final Validation score: 0.0014\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.0014\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0937, Acc: -5.10% | Val Loss: 0.7854, Acc: -6.72%\n",
      "Epoch 10: Train Loss: 1.0600, Acc: -1.46% | Val Loss: 0.7708, Acc: -4.73%\n",
      "Early stopping at epoch 19\n",
      "Restoring model weights from epoch 9\n",
      "Final Validation score: -0.0475\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0475\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2080, Acc: -25.29% | Val Loss: 1.2771, Acc: -18.77%\n",
      "Epoch 10: Train Loss: 0.9860, Acc: -2.05% | Val Loss: 1.1194, Acc: -4.11%\n",
      "Epoch 20: Train Loss: 0.9831, Acc: -1.47% | Val Loss: 1.1132, Acc: -3.53%\n",
      "Epoch 30: Train Loss: 0.9805, Acc: -1.84% | Val Loss: 1.1102, Acc: -3.25%\n",
      "Epoch 40: Train Loss: 0.9795, Acc: -1.65% | Val Loss: 1.1083, Acc: -3.08%\n",
      "Final Validation score: -0.0297\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0297\n",
      "6 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 10, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.3374, Acc: -42.53% | Val Loss: 1.2157, Acc: -17.66%\n",
      "Epoch 10: Train Loss: 1.0313, Acc: -7.81% | Val Loss: 1.0518, Acc: -1.79%\n",
      "Epoch 20: Train Loss: 1.0078, Acc: -6.38% | Val Loss: 1.0430, Acc: -0.94%\n",
      "Epoch 30: Train Loss: 1.0005, Acc: -3.59% | Val Loss: 1.0419, Acc: -0.84%\n",
      "Epoch 40: Train Loss: 0.9969, Acc: -3.20% | Val Loss: 1.0416, Acc: -0.81%\n",
      "Early stopping at epoch 49\n",
      "Restoring model weights from epoch 39\n",
      "Final Validation score: -0.0082\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0082\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0228\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.0016681005372000592, 'l2': 0.00021544346900318823, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.005455594781168515, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0881, Acc: -13.64% | Val Loss: 1.0144, Acc: -4.33%\n",
      "Epoch 10: Train Loss: 0.8230, Acc: 12.84% | Val Loss: 0.8839, Acc: 9.10%\n",
      "Epoch 20: Train Loss: 0.8084, Acc: 15.59% | Val Loss: 0.8527, Acc: 12.30%\n",
      "Epoch 30: Train Loss: 0.8019, Acc: 16.33% | Val Loss: 0.8434, Acc: 13.26%\n",
      "Epoch 40: Train Loss: 0.7982, Acc: 17.26% | Val Loss: 0.8454, Acc: 13.05%\n",
      "Epoch 50: Train Loss: 0.7953, Acc: 14.39% | Val Loss: 0.8539, Acc: 12.18%\n",
      "Epoch 60: Train Loss: 0.7942, Acc: 15.00% | Val Loss: 0.8535, Acc: 12.22%\n",
      "Early stopping at epoch 60\n",
      "Restoring model weights from epoch 30\n",
      "Final Validation score: 0.1222\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.1222\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.0016681005372000592, 'l2': 0.00021544346900318823, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.005455594781168515, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0466, Acc: -12.33% | Val Loss: 1.1223, Acc: -0.77%\n",
      "Epoch 10: Train Loss: 0.9633, Acc: -5.22% | Val Loss: 1.1241, Acc: -0.92%\n",
      "Epoch 20: Train Loss: 0.9628, Acc: -6.05% | Val Loss: 1.1248, Acc: -0.99%\n",
      "Epoch 30: Train Loss: 0.9626, Acc: -4.53% | Val Loss: 1.1251, Acc: -1.02%\n",
      "Early stopping at epoch 33\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0102\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0102\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.0016681005372000592, 'l2': 0.00021544346900318823, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.005455594781168515, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1316, Acc: -14.35% | Val Loss: 0.7562, Acc: -2.75%\n",
      "Epoch 10: Train Loss: 1.0560, Acc: -4.82% | Val Loss: 0.7744, Acc: -5.22%\n",
      "Epoch 20: Train Loss: 1.0553, Acc: -3.07% | Val Loss: 0.7692, Acc: -4.52%\n",
      "Epoch 30: Train Loss: 1.0549, Acc: -1.60% | Val Loss: 0.7722, Acc: -4.92%\n",
      "Early stopping at epoch 31\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0488\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0488\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.0016681005372000592, 'l2': 0.00021544346900318823, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.005455594781168515, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0392, Acc: -13.91% | Val Loss: 1.1005, Acc: -2.35%\n",
      "Epoch 10: Train Loss: 0.9745, Acc: -6.66% | Val Loss: 1.0949, Acc: -1.83%\n",
      "Epoch 20: Train Loss: 0.9728, Acc: -3.69% | Val Loss: 1.0916, Acc: -1.53%\n",
      "Epoch 30: Train Loss: 0.9726, Acc: -4.01% | Val Loss: 1.0903, Acc: -1.40%\n",
      "Early stopping at epoch 38\n",
      "Restoring model weights from epoch 8\n",
      "Final Validation score: -0.0149\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0149\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.0379269019073225, 'l1': 0.0016681005372000592, 'l2': 0.00021544346900318823, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.005455594781168515, 'patience': 30, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.0434, Acc: -11.60% | Val Loss: 1.0366, Acc: -0.32%\n",
      "Epoch 10: Train Loss: 0.8055, Acc: 13.80% | Val Loss: 0.8807, Acc: 14.77%\n",
      "Epoch 20: Train Loss: 0.7394, Acc: 21.64% | Val Loss: 0.7833, Acc: 24.19%\n",
      "Epoch 30: Train Loss: 0.7297, Acc: 21.06% | Val Loss: 0.7800, Acc: 24.51%\n",
      "Epoch 40: Train Loss: 0.7261, Acc: 21.44% | Val Loss: 0.7783, Acc: 24.67%\n",
      "Epoch 50: Train Loss: 0.7198, Acc: 21.10% | Val Loss: 0.7762, Acc: 24.87%\n",
      "Epoch 60: Train Loss: 0.7173, Acc: 21.83% | Val Loss: 0.7729, Acc: 25.20%\n",
      "Epoch 70: Train Loss: 0.7174, Acc: 21.93% | Val Loss: 0.7726, Acc: 25.22%\n",
      "Epoch 80: Train Loss: 0.7117, Acc: 22.78% | Val Loss: 0.7693, Acc: 25.55%\n",
      "Epoch 90: Train Loss: 0.7108, Acc: 23.98% | Val Loss: 0.7684, Acc: 25.63%\n",
      "Final Validation score: 0.2589\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.2589\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.0614\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 7.742636826811278e-05, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2499, Acc: -30.15% | Val Loss: 1.2767, Acc: -31.31%\n",
      "Epoch 10: Train Loss: 1.0177, Acc: -3.98% | Val Loss: 1.0196, Acc: -4.86%\n",
      "Epoch 20: Train Loss: 1.0039, Acc: -2.15% | Val Loss: 0.9972, Acc: -2.56%\n",
      "Epoch 30: Train Loss: 1.0014, Acc: -2.26% | Val Loss: 0.9908, Acc: -1.90%\n",
      "Epoch 40: Train Loss: 1.0003, Acc: -1.41% | Val Loss: 0.9878, Acc: -1.60%\n",
      "Epoch 50: Train Loss: 1.0004, Acc: -2.86% | Val Loss: 0.9861, Acc: -1.42%\n",
      "Epoch 60: Train Loss: 0.9996, Acc: -2.92% | Val Loss: 0.9850, Acc: -1.30%\n",
      "Epoch 70: Train Loss: 0.9994, Acc: -2.91% | Val Loss: 0.9843, Acc: -1.23%\n",
      "Epoch 80: Train Loss: 0.9993, Acc: -1.55% | Val Loss: 0.9837, Acc: -1.17%\n",
      "Epoch 90: Train Loss: 0.9992, Acc: -1.36% | Val Loss: 0.9832, Acc: -1.12%\n",
      "Final Validation score: -0.0108\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0108\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 7.742636826811278e-05, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2910, Acc: -38.21% | Val Loss: 1.2451, Acc: -11.79%\n",
      "Epoch 10: Train Loss: 0.9954, Acc: -7.23% | Val Loss: 1.1114, Acc: 0.21%\n",
      "Epoch 20: Train Loss: 0.9733, Acc: -3.33% | Val Loss: 1.1142, Acc: -0.04%\n",
      "Epoch 30: Train Loss: 0.9681, Acc: -1.65% | Val Loss: 1.1173, Acc: -0.32%\n",
      "Epoch 40: Train Loss: 0.9661, Acc: -2.19% | Val Loss: 1.1191, Acc: -0.48%\n",
      "Epoch 50: Train Loss: 0.9651, Acc: -3.40% | Val Loss: 1.1204, Acc: -0.60%\n",
      "Epoch 60: Train Loss: 0.9645, Acc: -1.68% | Val Loss: 1.1213, Acc: -0.68%\n",
      "Early stopping at epoch 61\n",
      "Restoring model weights from epoch 11\n",
      "Final Validation score: -0.0068\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0068\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 7.742636826811278e-05, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.4463, Acc: -43.94% | Val Loss: 1.1947, Acc: -62.34%\n",
      "Epoch 10: Train Loss: 1.1077, Acc: -8.43% | Val Loss: 0.8384, Acc: -13.93%\n",
      "Epoch 20: Train Loss: 1.0679, Acc: -2.16% | Val Loss: 0.7884, Acc: -7.13%\n",
      "Epoch 30: Train Loss: 1.0606, Acc: -2.08% | Val Loss: 0.7769, Acc: -5.56%\n",
      "Epoch 40: Train Loss: 1.0581, Acc: -2.45% | Val Loss: 0.7730, Acc: -5.03%\n",
      "Epoch 50: Train Loss: 1.0570, Acc: -1.57% | Val Loss: 0.7718, Acc: -4.88%\n",
      "Epoch 60: Train Loss: 1.0564, Acc: -0.73% | Val Loss: 0.7713, Acc: -4.80%\n",
      "Epoch 70: Train Loss: 1.0560, Acc: -0.81% | Val Loss: 0.7709, Acc: -4.75%\n",
      "Epoch 80: Train Loss: 1.0558, Acc: -1.06% | Val Loss: 0.7713, Acc: -4.80%\n",
      "Epoch 90: Train Loss: 1.0556, Acc: -1.83% | Val Loss: 0.7720, Acc: -4.89%\n",
      "Final Validation score: -0.0479\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0479\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 7.742636826811278e-05, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.2120, Acc: -27.72% | Val Loss: 1.4124, Acc: -31.36%\n",
      "Epoch 10: Train Loss: 0.9886, Acc: -5.12% | Val Loss: 1.1369, Acc: -5.74%\n",
      "Epoch 20: Train Loss: 0.9766, Acc: -1.59% | Val Loss: 1.1097, Acc: -3.21%\n",
      "Epoch 30: Train Loss: 0.9742, Acc: -2.32% | Val Loss: 1.1017, Acc: -2.46%\n",
      "Epoch 40: Train Loss: 0.9734, Acc: -1.24% | Val Loss: 1.0982, Acc: -2.14%\n",
      "Epoch 50: Train Loss: 0.9730, Acc: -1.72% | Val Loss: 1.0963, Acc: -1.96%\n",
      "Epoch 60: Train Loss: 0.9728, Acc: -2.09% | Val Loss: 1.0951, Acc: -1.85%\n",
      "Epoch 70: Train Loss: 0.9726, Acc: -1.94% | Val Loss: 1.0943, Acc: -1.77%\n",
      "Epoch 80: Train Loss: 0.9725, Acc: -0.80% | Val Loss: 1.0935, Acc: -1.70%\n",
      "Epoch 90: Train Loss: 0.9725, Acc: -1.15% | Val Loss: 1.0932, Acc: -1.67%\n",
      "Final Validation score: -0.0166\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0166\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.011288378916846888, 'l1': 7.742636826811278e-05, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0004832930238571752, 'patience': 50, 'CC': False, 'weights_init': 'gaussian_scaled'}\n",
      "Epoch 0: Train Loss: 1.1703, Acc: -21.87% | Val Loss: 1.0700, Acc: -3.56%\n",
      "Epoch 10: Train Loss: 0.9991, Acc: -3.35% | Val Loss: 1.0290, Acc: 0.42%\n",
      "Epoch 20: Train Loss: 0.9877, Acc: -1.84% | Val Loss: 1.0372, Acc: -0.38%\n",
      "Epoch 30: Train Loss: 0.9851, Acc: -2.07% | Val Loss: 1.0409, Acc: -0.75%\n",
      "Epoch 40: Train Loss: 0.9839, Acc: -1.88% | Val Loss: 1.0430, Acc: -0.94%\n",
      "Epoch 50: Train Loss: 0.9833, Acc: -1.95% | Val Loss: 1.0443, Acc: -1.07%\n",
      "Early stopping at epoch 56\n",
      "Restoring model weights from epoch 6\n",
      "Final Validation score: -0.0112\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0112\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0187\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.6290, Acc: -66.23% | Val Loss: 1.7484, Acc: -79.82%\n",
      "Epoch 10: Train Loss: 1.4968, Acc: -53.69% | Val Loss: 1.5892, Acc: -63.44%\n",
      "Epoch 20: Train Loss: 1.3217, Acc: -38.16% | Val Loss: 1.3846, Acc: -42.40%\n",
      "Epoch 30: Train Loss: 1.1893, Acc: -24.79% | Val Loss: 1.2601, Acc: -29.59%\n",
      "Epoch 40: Train Loss: 1.1516, Acc: -20.96% | Val Loss: 1.2275, Acc: -26.24%\n",
      "Epoch 50: Train Loss: 1.1289, Acc: -16.81% | Val Loss: 1.2050, Acc: -23.93%\n",
      "Epoch 60: Train Loss: 1.1110, Acc: -15.03% | Val Loss: 1.1821, Acc: -21.57%\n",
      "Epoch 70: Train Loss: 1.0983, Acc: -13.68% | Val Loss: 1.1613, Acc: -19.44%\n",
      "Epoch 80: Train Loss: 1.0863, Acc: -12.50% | Val Loss: 1.1407, Acc: -17.32%\n",
      "Epoch 90: Train Loss: 1.0775, Acc: -10.72% | Val Loss: 1.1225, Acc: -15.44%\n",
      "Final Validation score: -0.1440\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.1440\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1974, Acc: -26.86% | Val Loss: 1.2472, Acc: -11.98%\n",
      "Epoch 10: Train Loss: 1.1542, Acc: -22.82% | Val Loss: 1.2130, Acc: -8.91%\n",
      "Epoch 20: Train Loss: 1.0553, Acc: -12.34% | Val Loss: 1.1328, Acc: -1.71%\n",
      "Epoch 30: Train Loss: 1.0174, Acc: -8.10% | Val Loss: 1.1044, Acc: 0.85%\n",
      "Epoch 40: Train Loss: 1.0025, Acc: -6.11% | Val Loss: 1.0875, Acc: 2.36%\n",
      "Epoch 50: Train Loss: 0.9892, Acc: -7.09% | Val Loss: 1.0723, Acc: 3.72%\n",
      "Epoch 60: Train Loss: 0.9845, Acc: -5.25% | Val Loss: 1.0646, Acc: 4.42%\n",
      "Epoch 70: Train Loss: 0.9735, Acc: -4.40% | Val Loss: 1.0604, Acc: 4.79%\n",
      "Epoch 80: Train Loss: 0.9597, Acc: -1.55% | Val Loss: 1.0567, Acc: 5.12%\n",
      "Epoch 90: Train Loss: 0.9623, Acc: -1.20% | Val Loss: 1.0618, Acc: 4.67%\n",
      "Final Validation score: 0.0376\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.0376\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.5588, Acc: -50.57% | Val Loss: 1.2795, Acc: -73.85%\n",
      "Epoch 10: Train Loss: 1.4444, Acc: -40.36% | Val Loss: 1.2248, Acc: -66.43%\n",
      "Epoch 20: Train Loss: 1.2979, Acc: -24.30% | Val Loss: 1.1021, Acc: -49.75%\n",
      "Epoch 30: Train Loss: 1.2109, Acc: -17.57% | Val Loss: 0.9906, Acc: -34.60%\n",
      "Epoch 40: Train Loss: 1.1616, Acc: -13.49% | Val Loss: 0.9187, Acc: -24.83%\n",
      "Epoch 50: Train Loss: 1.1141, Acc: -9.66% | Val Loss: 0.8693, Acc: -18.12%\n",
      "Epoch 60: Train Loss: 1.0788, Acc: -2.69% | Val Loss: 0.8400, Acc: -14.13%\n",
      "Epoch 70: Train Loss: 1.0501, Acc: -2.22% | Val Loss: 0.8125, Acc: -10.40%\n",
      "Epoch 80: Train Loss: 1.0256, Acc: -1.21% | Val Loss: 0.7858, Acc: -6.78%\n",
      "Epoch 90: Train Loss: 1.0117, Acc: 1.15% | Val Loss: 0.7728, Acc: -5.01%\n",
      "Final Validation score: -0.0402\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0402\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1690, Acc: -23.17% | Val Loss: 1.3643, Acc: -26.88%\n",
      "Epoch 10: Train Loss: 1.1402, Acc: -24.27% | Val Loss: 1.3309, Acc: -23.78%\n",
      "Epoch 20: Train Loss: 1.1115, Acc: -19.91% | Val Loss: 1.2988, Acc: -20.79%\n",
      "Epoch 30: Train Loss: 1.0822, Acc: -15.98% | Val Loss: 1.2639, Acc: -17.54%\n",
      "Epoch 40: Train Loss: 1.0172, Acc: -6.04% | Val Loss: 1.1960, Acc: -11.23%\n",
      "Epoch 50: Train Loss: 0.9618, Acc: -1.59% | Val Loss: 1.1391, Acc: -5.94%\n",
      "Epoch 60: Train Loss: 0.9406, Acc: 1.94% | Val Loss: 1.1171, Acc: -3.90%\n",
      "Epoch 70: Train Loss: 0.9308, Acc: 1.53% | Val Loss: 1.1041, Acc: -2.69%\n",
      "Epoch 80: Train Loss: 0.9246, Acc: 4.96% | Val Loss: 1.0954, Acc: -1.87%\n",
      "Epoch 90: Train Loss: 0.9166, Acc: 2.72% | Val Loss: 1.0792, Acc: -0.37%\n",
      "Final Validation score: 0.0121\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.0121\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 0.1, 'l2': 0.004641588833612777, 'dropout_rate': 1e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.4418, Acc: -53.87% | Val Loss: 1.2968, Acc: -25.51%\n",
      "Epoch 10: Train Loss: 1.2586, Acc: -32.94% | Val Loss: 1.1915, Acc: -15.32%\n",
      "Epoch 20: Train Loss: 1.2202, Acc: -28.48% | Val Loss: 1.1636, Acc: -12.61%\n",
      "Epoch 30: Train Loss: 1.1902, Acc: -27.78% | Val Loss: 1.1419, Acc: -10.51%\n",
      "Epoch 40: Train Loss: 1.1679, Acc: -22.92% | Val Loss: 1.1255, Acc: -8.93%\n",
      "Epoch 50: Train Loss: 1.1492, Acc: -19.60% | Val Loss: 1.1102, Acc: -7.45%\n",
      "Epoch 60: Train Loss: 1.1336, Acc: -18.48% | Val Loss: 1.0962, Acc: -6.09%\n",
      "Epoch 70: Train Loss: 1.1206, Acc: -16.46% | Val Loss: 1.0862, Acc: -5.12%\n",
      "Epoch 80: Train Loss: 1.1101, Acc: -17.35% | Val Loss: 1.0783, Acc: -4.36%\n",
      "Epoch 90: Train Loss: 1.0990, Acc: -18.84% | Val Loss: 1.0702, Acc: -3.57%\n",
      "Final Validation score: -0.0300\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0300\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0329\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.008858667904100823, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2550, Acc: -32.11% | Val Loss: 1.2013, Acc: -23.55%\n",
      "Epoch 10: Train Loss: 1.0053, Acc: -4.18% | Val Loss: 0.9989, Acc: -2.73%\n",
      "Epoch 20: Train Loss: 1.0019, Acc: -4.81% | Val Loss: 0.9920, Acc: -2.03%\n",
      "Epoch 30: Train Loss: 1.0008, Acc: -4.62% | Val Loss: 0.9894, Acc: -1.75%\n",
      "Epoch 40: Train Loss: 1.0004, Acc: -5.79% | Val Loss: 0.9879, Acc: -1.60%\n",
      "Epoch 50: Train Loss: 1.0001, Acc: -3.15% | Val Loss: 0.9870, Acc: -1.51%\n",
      "Epoch 60: Train Loss: 0.9999, Acc: -5.24% | Val Loss: 0.9863, Acc: -1.44%\n",
      "Epoch 70: Train Loss: 0.9997, Acc: -5.27% | Val Loss: 0.9858, Acc: -1.39%\n",
      "Epoch 80: Train Loss: 0.9996, Acc: -4.32% | Val Loss: 0.9854, Acc: -1.34%\n",
      "Epoch 90: Train Loss: 0.9996, Acc: -2.68% | Val Loss: 0.9851, Acc: -1.31%\n",
      "Final Validation score: -0.0129\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0129\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.008858667904100823, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0413, Acc: -13.03% | Val Loss: 1.1162, Acc: -0.22%\n",
      "Epoch 10: Train Loss: 0.9676, Acc: -3.59% | Val Loss: 1.1177, Acc: -0.35%\n",
      "Epoch 20: Train Loss: 0.9652, Acc: -5.54% | Val Loss: 1.1201, Acc: -0.57%\n",
      "Epoch 30: Train Loss: 0.9644, Acc: -3.01% | Val Loss: 1.1212, Acc: -0.67%\n",
      "Early stopping at epoch 31\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0067\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0067\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.008858667904100823, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2290, Acc: -26.78% | Val Loss: 0.9333, Acc: -26.81%\n",
      "Epoch 10: Train Loss: 1.0624, Acc: -4.68% | Val Loss: 0.7839, Acc: -6.51%\n",
      "Epoch 20: Train Loss: 1.0586, Acc: -3.27% | Val Loss: 0.7758, Acc: -5.41%\n",
      "Epoch 30: Train Loss: 1.0574, Acc: -6.07% | Val Loss: 0.7745, Acc: -5.24%\n",
      "Epoch 40: Train Loss: 1.0568, Acc: -3.88% | Val Loss: 0.7738, Acc: -5.14%\n",
      "Epoch 50: Train Loss: 1.0565, Acc: -3.22% | Val Loss: 0.7729, Acc: -5.02%\n",
      "Epoch 60: Train Loss: 1.0562, Acc: -2.05% | Val Loss: 0.7730, Acc: -5.03%\n",
      "Epoch 70: Train Loss: 1.0560, Acc: -2.19% | Val Loss: 0.7728, Acc: -5.00%\n",
      "Epoch 80: Train Loss: 1.0559, Acc: -3.73% | Val Loss: 0.7728, Acc: -5.00%\n",
      "Epoch 90: Train Loss: 1.0564, Acc: -4.56% | Val Loss: 0.7729, Acc: -5.01%\n",
      "Final Validation score: -0.0500\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0500\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.008858667904100823, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1713, Acc: -28.52% | Val Loss: 1.2786, Acc: -18.91%\n",
      "Epoch 10: Train Loss: 0.9795, Acc: -7.24% | Val Loss: 1.1058, Acc: -2.84%\n",
      "Epoch 20: Train Loss: 0.9753, Acc: -2.86% | Val Loss: 1.0989, Acc: -2.20%\n",
      "Epoch 30: Train Loss: 0.9743, Acc: -4.41% | Val Loss: 1.0968, Acc: -2.01%\n",
      "Epoch 40: Train Loss: 0.9738, Acc: -6.75% | Val Loss: 1.0955, Acc: -1.88%\n",
      "Epoch 50: Train Loss: 0.9735, Acc: -4.94% | Val Loss: 1.0947, Acc: -1.81%\n",
      "Epoch 60: Train Loss: 0.9733, Acc: -4.34% | Val Loss: 1.0941, Acc: -1.76%\n",
      "Epoch 70: Train Loss: 0.9732, Acc: -5.39% | Val Loss: 1.0938, Acc: -1.72%\n",
      "Epoch 80: Train Loss: 0.9731, Acc: -2.87% | Val Loss: 1.0935, Acc: -1.70%\n",
      "Epoch 90: Train Loss: 0.9729, Acc: -1.40% | Val Loss: 1.0933, Acc: -1.68%\n",
      "Final Validation score: -0.0168\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0168\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.018329807108324356, 'l1': 0.1, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.008858667904100823, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2168, Acc: -39.05% | Val Loss: 1.1229, Acc: -8.68%\n",
      "Epoch 10: Train Loss: 0.9933, Acc: -2.90% | Val Loss: 1.0432, Acc: -0.96%\n",
      "Epoch 20: Train Loss: 0.9875, Acc: -4.81% | Val Loss: 1.0440, Acc: -1.04%\n",
      "Epoch 30: Train Loss: 0.9858, Acc: -5.57% | Val Loss: 1.0448, Acc: -1.12%\n",
      "Early stopping at epoch 36\n",
      "Restoring model weights from epoch 6\n",
      "Final Validation score: -0.0115\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0115\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0196\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 1e-05, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2596, Acc: -30.66% | Val Loss: 1.3087, Acc: -34.60%\n",
      "Epoch 10: Train Loss: 1.0213, Acc: -4.20% | Val Loss: 1.0310, Acc: -6.04%\n",
      "Epoch 20: Train Loss: 0.9837, Acc: -0.34% | Val Loss: 0.9849, Acc: -1.30%\n",
      "Epoch 30: Train Loss: 0.9911, Acc: -1.40% | Val Loss: 0.9920, Acc: -2.02%\n",
      "Early stopping at epoch 31\n",
      "Restoring model weights from epoch 21\n",
      "Final Validation score: -0.0220\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0220\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 1e-05, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2283, Acc: -32.70% | Val Loss: 1.2530, Acc: -12.50%\n",
      "Epoch 10: Train Loss: 0.9747, Acc: -3.50% | Val Loss: 1.0936, Acc: 1.81%\n",
      "Early stopping at epoch 19\n",
      "Restoring model weights from epoch 9\n",
      "Final Validation score: -0.0006\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0006\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 1e-05, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2793, Acc: -22.47% | Val Loss: 1.0500, Acc: -42.67%\n",
      "Epoch 10: Train Loss: 1.1915, Acc: -15.09% | Val Loss: 0.9465, Acc: -28.60%\n",
      "Epoch 20: Train Loss: 1.1451, Acc: -9.56% | Val Loss: 0.8860, Acc: -20.38%\n",
      "Epoch 30: Train Loss: 1.1142, Acc: -6.93% | Val Loss: 0.8347, Acc: -13.42%\n",
      "Epoch 40: Train Loss: 1.0900, Acc: -4.27% | Val Loss: 0.7986, Acc: -8.51%\n",
      "Final Validation score: -0.0623\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0623\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 1e-05, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.0847, Acc: -12.73% | Val Loss: 1.2371, Acc: -15.05%\n",
      "Epoch 10: Train Loss: 1.0047, Acc: -6.69% | Val Loss: 1.1209, Acc: -4.25%\n",
      "Epoch 20: Train Loss: 0.9853, Acc: -3.66% | Val Loss: 1.1010, Acc: -2.40%\n",
      "Epoch 30: Train Loss: 0.9797, Acc: -7.38% | Val Loss: 1.0952, Acc: -1.86%\n",
      "Epoch 40: Train Loss: 0.9772, Acc: -2.59% | Val Loss: 1.0942, Acc: -1.76%\n",
      "Final Validation score: -0.0164\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0164\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.00545559478116852, 'l1': 1e-05, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1188, Acc: -21.34% | Val Loss: 0.9944, Acc: 3.76%\n",
      "Epoch 10: Train Loss: 0.9923, Acc: -3.32% | Val Loss: 0.9814, Acc: 5.02%\n",
      "Early stopping at epoch 18\n",
      "Restoring model weights from epoch 8\n",
      "Final Validation score: 0.0411\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.0411\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0121\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.5012, Acc: -56.02% | Val Loss: 1.6131, Acc: -65.90%\n",
      "Epoch 10: Train Loss: 1.2458, Acc: -27.18% | Val Loss: 1.3262, Acc: -36.39%\n",
      "Epoch 20: Train Loss: 1.1932, Acc: -22.15% | Val Loss: 1.2777, Acc: -31.40%\n",
      "Epoch 30: Train Loss: 1.1458, Acc: -15.06% | Val Loss: 1.2256, Acc: -26.05%\n",
      "Epoch 40: Train Loss: 1.0122, Acc: -2.66% | Val Loss: 1.0741, Acc: -10.47%\n",
      "Final Validation score: 0.0719\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.0719\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.6802, Acc: -83.15% | Val Loss: 1.3907, Acc: -24.86%\n",
      "Epoch 10: Train Loss: 0.8676, Acc: 10.05% | Val Loss: 0.9647, Acc: 13.38%\n",
      "Epoch 20: Train Loss: 0.8236, Acc: 13.66% | Val Loss: 0.9196, Acc: 17.43%\n",
      "Epoch 30: Train Loss: 0.7956, Acc: 15.91% | Val Loss: 0.8900, Acc: 20.09%\n",
      "Epoch 40: Train Loss: 0.7719, Acc: 18.84% | Val Loss: 0.8699, Acc: 21.90%\n",
      "Final Validation score: 0.2295\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.2295\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3429, Acc: -29.00% | Val Loss: 1.1056, Acc: -50.22%\n",
      "Epoch 10: Train Loss: 1.0846, Acc: -3.59% | Val Loss: 0.9049, Acc: -22.95%\n",
      "Epoch 20: Train Loss: 0.9987, Acc: 5.15% | Val Loss: 0.8509, Acc: -15.62%\n",
      "Epoch 30: Train Loss: 0.9154, Acc: 13.19% | Val Loss: 0.8101, Acc: -10.08%\n",
      "Epoch 40: Train Loss: 0.8658, Acc: 17.82% | Val Loss: 0.7740, Acc: -5.17%\n",
      "Final Validation score: -0.0151\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0151\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3197, Acc: -37.17% | Val Loss: 1.3717, Acc: -27.57%\n",
      "Epoch 10: Train Loss: 1.2761, Acc: -31.34% | Val Loss: 1.3588, Acc: -26.38%\n",
      "Epoch 20: Train Loss: 1.2212, Acc: -26.81% | Val Loss: 1.3198, Acc: -22.74%\n",
      "Epoch 30: Train Loss: 1.1831, Acc: -22.97% | Val Loss: 1.2739, Acc: -18.48%\n",
      "Epoch 40: Train Loss: 0.8993, Acc: 7.12% | Val Loss: 1.0493, Acc: 2.42%\n",
      "Final Validation score: 0.0649\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.0649\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.003359818286283781, 'l1': 2.782559402207126e-05, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 10, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2092, Acc: -25.87% | Val Loss: 1.2835, Acc: -24.22%\n",
      "Epoch 10: Train Loss: 0.9139, Acc: 4.56% | Val Loss: 0.9613, Acc: 6.97%\n",
      "Epoch 20: Train Loss: 0.8958, Acc: 8.33% | Val Loss: 0.9524, Acc: 7.83%\n",
      "Epoch 30: Train Loss: 0.8853, Acc: 8.32% | Val Loss: 0.9481, Acc: 8.24%\n",
      "Epoch 40: Train Loss: 0.8803, Acc: 10.30% | Val Loss: 0.9480, Acc: 8.25%\n",
      "Early stopping at epoch 44\n",
      "Restoring model weights from epoch 34\n",
      "Final Validation score: 0.0825\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.0825\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.0867\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.00021544346900318823, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.1, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.7190, Acc: -75.90% | Val Loss: 1.7489, Acc: -79.87%\n",
      "Epoch 10: Train Loss: 1.6399, Acc: -64.95% | Val Loss: 1.7489, Acc: -79.87%\n",
      "Epoch 20: Train Loss: 1.6399, Acc: -66.27% | Val Loss: 1.7489, Acc: -79.87%\n",
      "Epoch 30: Train Loss: 1.6399, Acc: -64.74% | Val Loss: 1.7489, Acc: -79.87%\n",
      "Early stopping at epoch 30\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.7987\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.7987\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.00021544346900318823, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.1, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2035, Acc: -27.25% | Val Loss: 1.0013, Acc: 10.10%\n",
      "Epoch 10: Train Loss: 0.7673, Acc: 19.84% | Val Loss: 0.8355, Acc: 24.98%\n",
      "Epoch 20: Train Loss: 0.7341, Acc: 22.24% | Val Loss: 0.8080, Acc: 27.45%\n",
      "Epoch 30: Train Loss: 0.7222, Acc: 24.99% | Val Loss: 0.8005, Acc: 28.13%\n",
      "Epoch 40: Train Loss: 0.7125, Acc: 25.90% | Val Loss: 0.7900, Acc: 29.07%\n",
      "Final Validation score: 0.2953\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.2953\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.00021544346900318823, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.1, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2030, Acc: -15.87% | Val Loss: 0.9728, Acc: -32.18%\n",
      "Epoch 10: Train Loss: 0.7646, Acc: 26.90% | Val Loss: 0.6197, Acc: 15.80%\n",
      "Epoch 20: Train Loss: 0.7304, Acc: 30.50% | Val Loss: 0.5833, Acc: 20.75%\n",
      "Epoch 30: Train Loss: 0.7155, Acc: 31.29% | Val Loss: 0.5732, Acc: 22.11%\n",
      "Epoch 40: Train Loss: 0.7066, Acc: 33.08% | Val Loss: 0.5704, Acc: 22.50%\n",
      "Final Validation score: 0.2258\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2258\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.00021544346900318823, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.1, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.4758, Acc: -55.18% | Val Loss: 1.3337, Acc: -24.04%\n",
      "Epoch 10: Train Loss: 0.7633, Acc: 20.98% | Val Loss: 0.9129, Acc: 15.10%\n",
      "Epoch 20: Train Loss: 0.7213, Acc: 25.02% | Val Loss: 0.8653, Acc: 19.52%\n",
      "Epoch 30: Train Loss: 0.6853, Acc: 26.54% | Val Loss: 0.8344, Acc: 22.39%\n",
      "Epoch 40: Train Loss: 0.6581, Acc: 31.90% | Val Loss: 0.7982, Acc: 25.77%\n",
      "Final Validation score: 0.2730\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.2730\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 1e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.1, 'l1': 0.00021544346900318823, 'l2': 1e-05, 'dropout_rate': 1e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.1, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3157, Acc: -34.66% | Val Loss: 1.0355, Acc: -0.22%\n",
      "Epoch 10: Train Loss: 0.9552, Acc: 1.95% | Val Loss: 0.9873, Acc: 4.44%\n",
      "Epoch 20: Train Loss: 0.9336, Acc: 4.03% | Val Loss: 0.9596, Acc: 7.13%\n",
      "Epoch 30: Train Loss: 0.9088, Acc: 6.71% | Val Loss: 0.9405, Acc: 8.97%\n",
      "Epoch 40: Train Loss: 0.8615, Acc: 11.81% | Val Loss: 0.9270, Acc: 10.28%\n",
      "Final Validation score: 0.1141\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.1141\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.0219\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.004641588833612777, 'l2': 0.1, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1301, Acc: -19.11% | Val Loss: 1.1415, Acc: -17.40%\n",
      "Epoch 10: Train Loss: 1.0102, Acc: -4.79% | Val Loss: 1.0086, Acc: -3.73%\n",
      "Epoch 20: Train Loss: 1.0032, Acc: -2.54% | Val Loss: 0.9946, Acc: -2.29%\n",
      "Epoch 30: Train Loss: 1.0009, Acc: -3.59% | Val Loss: 0.9891, Acc: -1.72%\n",
      "Epoch 40: Train Loss: 0.9999, Acc: -2.49% | Val Loss: 0.9866, Acc: -1.47%\n",
      "Epoch 50: Train Loss: 0.9998, Acc: -4.93% | Val Loss: 0.9851, Acc: -1.31%\n",
      "Epoch 60: Train Loss: 0.9992, Acc: -4.34% | Val Loss: 0.9840, Acc: -1.21%\n",
      "Epoch 70: Train Loss: 0.9990, Acc: -4.29% | Val Loss: 0.9834, Acc: -1.13%\n",
      "Epoch 80: Train Loss: 0.9992, Acc: -2.08% | Val Loss: 0.9828, Acc: -1.08%\n",
      "Epoch 90: Train Loss: 0.9993, Acc: -5.79% | Val Loss: 0.9824, Acc: -1.03%\n",
      "Final Validation score: -0.0099\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0099\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.004641588833612777, 'l2': 0.1, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3102, Acc: -54.82% | Val Loss: 1.1006, Acc: 1.19%\n",
      "Epoch 10: Train Loss: 0.9648, Acc: -4.41% | Val Loss: 1.1230, Acc: -0.83%\n",
      "Epoch 20: Train Loss: 0.9636, Acc: -5.02% | Val Loss: 1.1252, Acc: -1.03%\n",
      "Epoch 30: Train Loss: 0.9630, Acc: -5.98% | Val Loss: 1.1254, Acc: -1.04%\n",
      "Epoch 40: Train Loss: 0.9624, Acc: -7.78% | Val Loss: 1.1255, Acc: -1.05%\n",
      "Epoch 50: Train Loss: 0.9616, Acc: -2.90% | Val Loss: 1.1257, Acc: -1.07%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0107\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0107\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.004641588833612777, 'l2': 0.1, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.4783, Acc: -47.67% | Val Loss: 0.9655, Acc: -31.18%\n",
      "Epoch 10: Train Loss: 1.0562, Acc: -4.06% | Val Loss: 0.7635, Acc: -3.74%\n",
      "Epoch 20: Train Loss: 1.0553, Acc: -3.36% | Val Loss: 0.7720, Acc: -4.90%\n",
      "Epoch 30: Train Loss: 1.0549, Acc: -4.26% | Val Loss: 0.7709, Acc: -4.75%\n",
      "Epoch 40: Train Loss: 1.0558, Acc: -3.34% | Val Loss: 0.7710, Acc: -4.76%\n",
      "Epoch 50: Train Loss: 1.0547, Acc: -3.43% | Val Loss: 0.7799, Acc: -5.97%\n",
      "Early stopping at epoch 54\n",
      "Restoring model weights from epoch 4\n",
      "Final Validation score: -0.0495\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0495\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.004641588833612777, 'l2': 0.1, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1693, Acc: -29.37% | Val Loss: 1.2917, Acc: -20.13%\n",
      "Epoch 10: Train Loss: 0.9729, Acc: -1.40% | Val Loss: 1.0921, Acc: -1.57%\n",
      "Epoch 20: Train Loss: 0.9728, Acc: -5.63% | Val Loss: 1.0902, Acc: -1.40%\n",
      "Epoch 30: Train Loss: 0.9744, Acc: -3.47% | Val Loss: 1.0918, Acc: -1.54%\n",
      "Epoch 40: Train Loss: 0.9727, Acc: -7.12% | Val Loss: 1.0897, Acc: -1.34%\n",
      "Epoch 50: Train Loss: 0.9774, Acc: -5.44% | Val Loss: 1.0924, Acc: -1.59%\n",
      "Epoch 60: Train Loss: 0.9713, Acc: -3.04% | Val Loss: 1.0913, Acc: -1.49%\n",
      "Epoch 70: Train Loss: 0.9724, Acc: -4.16% | Val Loss: 1.0914, Acc: -1.51%\n",
      "Epoch 80: Train Loss: 0.9724, Acc: -4.09% | Val Loss: 1.0921, Acc: -1.57%\n",
      "Epoch 90: Train Loss: 0.9749, Acc: -4.59% | Val Loss: 1.0903, Acc: -1.40%\n",
      "Final Validation score: -0.0149\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0149\n",
      "4 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.023357214690901212, 'l1': 0.004641588833612777, 'l2': 0.1, 'dropout_rate': 0.004641588833612777, 'batch_size': 8, 'n_epochs': 100, 'weight_decay': 0.00011288378916846884, 'patience': 50, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.1410, Acc: -32.24% | Val Loss: 1.0205, Acc: 1.23%\n",
      "Epoch 10: Train Loss: 0.9825, Acc: -3.09% | Val Loss: 1.0461, Acc: -1.24%\n",
      "Epoch 20: Train Loss: 0.9831, Acc: -4.43% | Val Loss: 1.0480, Acc: -1.42%\n",
      "Epoch 30: Train Loss: 0.9814, Acc: -1.70% | Val Loss: 1.0483, Acc: -1.46%\n",
      "Epoch 40: Train Loss: 0.9816, Acc: -7.44% | Val Loss: 1.0486, Acc: -1.48%\n",
      "Epoch 50: Train Loss: 0.9820, Acc: -6.03% | Val Loss: 1.0487, Acc: -1.50%\n",
      "Early stopping at epoch 51\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0149\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0149\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0200\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.012915496650148827, 'l2': 1e-05, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2289, Acc: -23.91% | Val Loss: 1.2932, Acc: -33.00%\n",
      "Epoch 10: Train Loss: 1.1725, Acc: -17.91% | Val Loss: 1.2249, Acc: -25.98%\n",
      "Epoch 20: Train Loss: 1.1131, Acc: -12.90% | Val Loss: 1.1508, Acc: -18.35%\n",
      "Epoch 30: Train Loss: 1.0645, Acc: -10.09% | Val Loss: 1.0874, Acc: -11.84%\n",
      "Epoch 40: Train Loss: 1.0354, Acc: -4.91% | Val Loss: 1.0473, Acc: -7.71%\n",
      "Epoch 50: Train Loss: 1.0220, Acc: -3.57% | Val Loss: 1.0245, Acc: -5.37%\n",
      "Epoch 60: Train Loss: 1.0141, Acc: -2.79% | Val Loss: 1.0116, Acc: -4.04%\n",
      "Epoch 70: Train Loss: 1.0079, Acc: -1.20% | Val Loss: 1.0037, Acc: -3.23%\n",
      "Epoch 80: Train Loss: 1.0053, Acc: -0.85% | Val Loss: 0.9988, Acc: -2.72%\n",
      "Epoch 90: Train Loss: 1.0038, Acc: -1.35% | Val Loss: 0.9955, Acc: -2.38%\n",
      "Final Validation score: -0.0217\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0217\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.012915496650148827, 'l2': 1e-05, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2354, Acc: -29.13% | Val Loss: 1.2594, Acc: -13.08%\n",
      "Epoch 10: Train Loss: 1.1319, Acc: -17.90% | Val Loss: 1.1798, Acc: -5.93%\n",
      "Epoch 20: Train Loss: 1.0378, Acc: -8.36% | Val Loss: 1.1244, Acc: -0.95%\n",
      "Epoch 30: Train Loss: 0.9916, Acc: -3.53% | Val Loss: 1.1107, Acc: 0.27%\n",
      "Epoch 40: Train Loss: 0.9795, Acc: -1.91% | Val Loss: 1.1109, Acc: 0.26%\n",
      "Early stopping at epoch 44\n",
      "Restoring model weights from epoch 34\n",
      "Final Validation score: 0.0020\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.0020\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.012915496650148827, 'l2': 1e-05, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2869, Acc: -22.79% | Val Loss: 1.0694, Acc: -45.31%\n",
      "Epoch 10: Train Loss: 1.2585, Acc: -20.79% | Val Loss: 1.0354, Acc: -40.68%\n",
      "Epoch 20: Train Loss: 1.2340, Acc: -18.98% | Val Loss: 1.0055, Acc: -36.63%\n",
      "Epoch 30: Train Loss: 1.2126, Acc: -15.89% | Val Loss: 0.9798, Acc: -33.13%\n",
      "Epoch 40: Train Loss: 1.1944, Acc: -14.27% | Val Loss: 0.9573, Acc: -30.08%\n",
      "Epoch 50: Train Loss: 1.1788, Acc: -13.05% | Val Loss: 0.9378, Acc: -27.42%\n",
      "Epoch 60: Train Loss: 1.1656, Acc: -13.47% | Val Loss: 0.9211, Acc: -25.15%\n",
      "Epoch 70: Train Loss: 1.1540, Acc: -9.44% | Val Loss: 0.9064, Acc: -23.17%\n",
      "Epoch 80: Train Loss: 1.1441, Acc: -8.62% | Val Loss: 0.8938, Acc: -21.45%\n",
      "Epoch 90: Train Loss: 1.1355, Acc: -7.78% | Val Loss: 0.8827, Acc: -19.94%\n",
      "Final Validation score: -0.1875\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.1875\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.012915496650148827, 'l2': 1e-05, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2023, Acc: -24.16% | Val Loss: 1.4038, Acc: -30.56%\n",
      "Epoch 10: Train Loss: 1.1582, Acc: -22.67% | Val Loss: 1.3513, Acc: -25.67%\n",
      "Epoch 20: Train Loss: 1.1064, Acc: -16.57% | Val Loss: 1.2847, Acc: -19.48%\n",
      "Epoch 30: Train Loss: 1.0512, Acc: -9.95% | Val Loss: 1.2114, Acc: -12.66%\n",
      "Epoch 40: Train Loss: 1.0066, Acc: -4.33% | Val Loss: 1.1501, Acc: -6.97%\n",
      "Epoch 50: Train Loss: 0.9872, Acc: -1.89% | Val Loss: 1.1207, Acc: -4.23%\n",
      "Epoch 60: Train Loss: 0.9788, Acc: -2.17% | Val Loss: 1.1088, Acc: -3.12%\n",
      "Epoch 70: Train Loss: 0.9775, Acc: -0.93% | Val Loss: 1.1036, Acc: -2.64%\n",
      "Epoch 80: Train Loss: 0.9772, Acc: -0.68% | Val Loss: 1.1010, Acc: -2.39%\n",
      "Epoch 90: Train Loss: 0.9769, Acc: -2.28% | Val Loss: 1.0991, Acc: -2.22%\n",
      "Final Validation score: -0.0215\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0215\n",
      "3 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0016681005372000592 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.0026366508987303583, 'l1': 0.012915496650148827, 'l2': 1e-05, 'dropout_rate': 0.0016681005372000592, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.0007847599703514606, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2595, Acc: -30.12% | Val Loss: 1.1708, Acc: -13.31%\n",
      "Epoch 10: Train Loss: 1.1894, Acc: -23.29% | Val Loss: 1.1240, Acc: -8.79%\n",
      "Epoch 20: Train Loss: 1.1060, Acc: -13.55% | Val Loss: 1.0751, Acc: -4.05%\n",
      "Epoch 30: Train Loss: 1.0388, Acc: -7.00% | Val Loss: 1.0447, Acc: -1.11%\n",
      "Epoch 40: Train Loss: 1.0078, Acc: -3.46% | Val Loss: 1.0376, Acc: -0.42%\n",
      "Epoch 50: Train Loss: 0.9973, Acc: -2.21% | Val Loss: 1.0379, Acc: -0.45%\n",
      "Early stopping at epoch 53\n",
      "Restoring model weights from epoch 43\n",
      "Final Validation score: -0.0049\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0049\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0467\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 7.742636826811278e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.1611, Acc: -21.01% | Val Loss: 1.0753, Acc: -10.59%\n",
      "Epoch 10: Train Loss: 0.9994, Acc: -2.23% | Val Loss: 0.9822, Acc: -1.01%\n",
      "Epoch 20: Train Loss: 1.0017, Acc: -1.88% | Val Loss: 0.9813, Acc: -0.93%\n",
      "Epoch 30: Train Loss: 0.9993, Acc: -1.96% | Val Loss: 0.9808, Acc: -0.87%\n",
      "Epoch 40: Train Loss: 0.9996, Acc: -1.27% | Val Loss: 0.9806, Acc: -0.85%\n",
      "Epoch 50: Train Loss: 0.9989, Acc: -2.59% | Val Loss: 0.9802, Acc: -0.81%\n",
      "Epoch 60: Train Loss: 0.9979, Acc: -2.72% | Val Loss: 0.9804, Acc: -0.83%\n",
      "Epoch 70: Train Loss: 0.9993, Acc: -2.83% | Val Loss: 0.9803, Acc: -0.82%\n",
      "Epoch 80: Train Loss: 0.9990, Acc: -1.48% | Val Loss: 0.9800, Acc: -0.79%\n",
      "Epoch 90: Train Loss: 0.9989, Acc: -1.30% | Val Loss: 0.9802, Acc: -0.81%\n",
      "Final Validation score: -0.0077\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0077\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 7.742636826811278e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.1442, Acc: -21.14% | Val Loss: 1.1217, Acc: -0.71%\n",
      "Epoch 10: Train Loss: 0.9640, Acc: -2.09% | Val Loss: 1.1235, Acc: -0.87%\n",
      "Epoch 20: Train Loss: 0.9627, Acc: -2.10% | Val Loss: 1.1243, Acc: -0.94%\n",
      "Epoch 30: Train Loss: 0.9633, Acc: -1.10% | Val Loss: 1.1249, Acc: -1.00%\n",
      "Epoch 40: Train Loss: 0.9624, Acc: -1.68% | Val Loss: 1.1250, Acc: -1.00%\n",
      "Epoch 50: Train Loss: 0.9626, Acc: -3.00% | Val Loss: 1.1252, Acc: -1.02%\n",
      "Early stopping at epoch 51\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0103\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0103\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 7.742636826811278e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2167, Acc: -18.31% | Val Loss: 0.8741, Acc: -18.77%\n",
      "Epoch 10: Train Loss: 1.0568, Acc: -1.37% | Val Loss: 0.7673, Acc: -4.26%\n",
      "Epoch 20: Train Loss: 1.0547, Acc: -0.58% | Val Loss: 0.7721, Acc: -4.91%\n",
      "Epoch 30: Train Loss: 1.0552, Acc: -0.38% | Val Loss: 0.7759, Acc: -5.42%\n",
      "Epoch 40: Train Loss: 1.0558, Acc: -1.57% | Val Loss: 0.7764, Acc: -5.50%\n",
      "Epoch 50: Train Loss: 1.0551, Acc: -2.18% | Val Loss: 0.7736, Acc: -5.11%\n",
      "Early stopping at epoch 55\n",
      "Restoring model weights from epoch 5\n",
      "Final Validation score: -0.0497\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0497\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 7.742636826811278e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.0938, Acc: -14.39% | Val Loss: 1.1171, Acc: -3.89%\n",
      "Epoch 10: Train Loss: 0.9729, Acc: -2.70% | Val Loss: 1.0886, Acc: -1.25%\n",
      "Epoch 20: Train Loss: 0.9703, Acc: -1.76% | Val Loss: 1.0917, Acc: -1.53%\n",
      "Epoch 30: Train Loss: 0.9758, Acc: -3.35% | Val Loss: 1.0863, Acc: -1.02%\n",
      "Epoch 40: Train Loss: 0.9718, Acc: -2.90% | Val Loss: 1.0877, Acc: -1.16%\n",
      "Epoch 50: Train Loss: 0.9725, Acc: -3.20% | Val Loss: 1.0890, Acc: -1.28%\n",
      "Early stopping at epoch 52\n",
      "Restoring model weights from epoch 2\n",
      "Final Validation score: -0.0129\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0129\n",
      "3 <class 'src.activation_functions.Activation_Sigmoid'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 7.742636826811278e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.0012742749857031334, 'patience': 50, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.0531, Acc: -9.65% | Val Loss: 1.0308, Acc: 0.23%\n",
      "Epoch 10: Train Loss: 0.9821, Acc: -0.82% | Val Loss: 1.0471, Acc: -1.34%\n",
      "Epoch 20: Train Loss: 0.9820, Acc: -1.11% | Val Loss: 1.0475, Acc: -1.38%\n",
      "Epoch 30: Train Loss: 0.9818, Acc: -2.59% | Val Loss: 1.0478, Acc: -1.41%\n",
      "Epoch 40: Train Loss: 0.9821, Acc: -1.42% | Val Loss: 1.0480, Acc: -1.43%\n",
      "Epoch 50: Train Loss: 0.9820, Acc: -3.32% | Val Loss: 1.0481, Acc: -1.43%\n",
      "Early stopping at epoch 50\n",
      "Restoring model weights from epoch 0\n",
      "Final Validation score: -0.0143\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0143\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0190\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 2.782559402207126e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.5451, Acc: -58.67% | Val Loss: 1.6209, Acc: -66.70%\n",
      "Epoch 10: Train Loss: 1.3961, Acc: -42.20% | Val Loss: 1.5247, Acc: -56.82%\n",
      "Epoch 20: Train Loss: 1.3584, Acc: -38.92% | Val Loss: 1.4991, Acc: -54.18%\n",
      "Epoch 30: Train Loss: 1.3355, Acc: -41.08% | Val Loss: 1.4858, Acc: -52.81%\n",
      "Epoch 40: Train Loss: 1.3221, Acc: -37.87% | Val Loss: 1.4767, Acc: -51.87%\n",
      "Epoch 50: Train Loss: 1.3135, Acc: -39.43% | Val Loss: 1.4696, Acc: -51.15%\n",
      "Epoch 60: Train Loss: 1.3066, Acc: -34.51% | Val Loss: 1.4629, Acc: -50.45%\n",
      "Epoch 70: Train Loss: 1.3006, Acc: -34.94% | Val Loss: 1.4569, Acc: -49.83%\n",
      "Epoch 80: Train Loss: 1.2949, Acc: -32.36% | Val Loss: 1.4513, Acc: -49.26%\n",
      "Epoch 90: Train Loss: 1.2895, Acc: -36.47% | Val Loss: 1.4464, Acc: -48.76%\n",
      "Final Validation score: -0.4836\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.4836\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 2.782559402207126e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.6027, Acc: -71.21% | Val Loss: 1.5031, Acc: -34.96%\n",
      "Epoch 10: Train Loss: 1.4710, Acc: -59.50% | Val Loss: 1.3747, Acc: -23.43%\n",
      "Epoch 20: Train Loss: 1.3995, Acc: -52.26% | Val Loss: 1.3114, Acc: -17.74%\n",
      "Epoch 30: Train Loss: 1.3545, Acc: -43.52% | Val Loss: 1.2739, Acc: -14.37%\n",
      "Epoch 40: Train Loss: 1.3200, Acc: -39.25% | Val Loss: 1.2441, Acc: -11.70%\n",
      "Epoch 50: Train Loss: 1.2913, Acc: -40.50% | Val Loss: 1.2205, Acc: -9.59%\n",
      "Epoch 60: Train Loss: 1.2667, Acc: -34.75% | Val Loss: 1.2043, Acc: -8.13%\n",
      "Epoch 70: Train Loss: 1.2443, Acc: -33.35% | Val Loss: 1.1896, Acc: -6.81%\n",
      "Epoch 80: Train Loss: 1.2261, Acc: -29.07% | Val Loss: 1.1782, Acc: -5.79%\n",
      "Epoch 90: Train Loss: 1.2103, Acc: -28.30% | Val Loss: 1.1679, Acc: -4.86%\n",
      "Final Validation score: -0.0412\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0412\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 2.782559402207126e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2737, Acc: -26.49% | Val Loss: 0.9932, Acc: -34.96%\n",
      "Epoch 10: Train Loss: 1.1164, Acc: -8.48% | Val Loss: 0.8692, Acc: -18.11%\n",
      "Epoch 20: Train Loss: 1.0726, Acc: -4.87% | Val Loss: 0.8467, Acc: -15.05%\n",
      "Epoch 30: Train Loss: 1.0500, Acc: -0.19% | Val Loss: 0.8304, Acc: -12.83%\n",
      "Epoch 40: Train Loss: 1.0345, Acc: 0.59% | Val Loss: 0.8202, Acc: -11.45%\n",
      "Epoch 50: Train Loss: 1.0220, Acc: 2.75% | Val Loss: 0.8136, Acc: -10.54%\n",
      "Epoch 60: Train Loss: 1.0129, Acc: 1.61% | Val Loss: 0.8084, Acc: -9.84%\n",
      "Epoch 70: Train Loss: 1.0054, Acc: 3.18% | Val Loss: 0.8042, Acc: -9.28%\n",
      "Epoch 80: Train Loss: 0.9989, Acc: 4.90% | Val Loss: 0.8006, Acc: -8.78%\n",
      "Epoch 90: Train Loss: 0.9930, Acc: 4.68% | Val Loss: 0.7972, Acc: -8.33%\n",
      "Final Validation score: -0.0795\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0795\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 2.782559402207126e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.2575, Acc: -34.79% | Val Loss: 1.5402, Acc: -43.24%\n",
      "Epoch 10: Train Loss: 1.2346, Acc: -29.64% | Val Loss: 1.5170, Acc: -41.09%\n",
      "Epoch 20: Train Loss: 1.2267, Acc: -28.40% | Val Loss: 1.5129, Acc: -40.70%\n",
      "Epoch 30: Train Loss: 1.2231, Acc: -28.80% | Val Loss: 1.5101, Acc: -40.44%\n",
      "Epoch 40: Train Loss: 1.2211, Acc: -30.13% | Val Loss: 1.5083, Acc: -40.28%\n",
      "Epoch 50: Train Loss: 1.2198, Acc: -30.65% | Val Loss: 1.5068, Acc: -40.14%\n",
      "Epoch 60: Train Loss: 1.2187, Acc: -29.78% | Val Loss: 1.5053, Acc: -40.00%\n",
      "Epoch 70: Train Loss: 1.2175, Acc: -26.61% | Val Loss: 1.5035, Acc: -39.83%\n",
      "Epoch 80: Train Loss: 1.2165, Acc: -27.34% | Val Loss: 1.5016, Acc: -39.65%\n",
      "Epoch 90: Train Loss: 1.2155, Acc: -26.02% | Val Loss: 1.4997, Acc: -39.48%\n",
      "Final Validation score: -0.3934\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.3934\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 2.782559402207126e-05, 'l2': 0.00021544346900318823, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 30, 'CC': False, 'weights_init': 'gaussian'}\n",
      "Epoch 0: Train Loss: 1.3563, Acc: -43.86% | Val Loss: 1.3794, Acc: -33.50%\n",
      "Epoch 10: Train Loss: 1.2924, Acc: -38.51% | Val Loss: 1.3612, Acc: -31.74%\n",
      "Epoch 20: Train Loss: 1.2637, Acc: -32.80% | Val Loss: 1.3501, Acc: -30.67%\n",
      "Epoch 30: Train Loss: 1.2370, Acc: -28.37% | Val Loss: 1.3402, Acc: -29.71%\n",
      "Epoch 40: Train Loss: 1.2247, Acc: -27.79% | Val Loss: 1.3336, Acc: -29.07%\n",
      "Epoch 50: Train Loss: 1.2145, Acc: -27.36% | Val Loss: 1.3282, Acc: -28.54%\n",
      "Epoch 60: Train Loss: 1.2069, Acc: -27.46% | Val Loss: 1.3237, Acc: -28.12%\n",
      "Epoch 70: Train Loss: 1.2008, Acc: -25.19% | Val Loss: 1.3200, Acc: -27.75%\n",
      "Epoch 80: Train Loss: 1.1956, Acc: -24.64% | Val Loss: 1.3165, Acc: -27.41%\n",
      "Epoch 90: Train Loss: 1.1907, Acc: -27.01% | Val Loss: 1.3133, Acc: -27.10%\n",
      "Final Validation score: -0.2683\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.2683\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.2532\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.00021544346900318823, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1457, Acc: -14.47% | Val Loss: 1.0447, Acc: -7.44%\n",
      "Epoch 10: Train Loss: 0.9991, Acc: -0.62% | Val Loss: 0.9817, Acc: -0.96%\n",
      "Epoch 20: Train Loss: 0.9991, Acc: -0.59% | Val Loss: 0.9808, Acc: -0.88%\n",
      "Epoch 30: Train Loss: 0.9990, Acc: -0.87% | Val Loss: 0.9806, Acc: -0.85%\n",
      "Epoch 40: Train Loss: 0.9990, Acc: -0.39% | Val Loss: 0.9806, Acc: -0.85%\n",
      "Final Validation score: -0.0084\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0084\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.00021544346900318823, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1481, Acc: -19.46% | Val Loss: 1.0735, Acc: 3.62%\n",
      "Epoch 10: Train Loss: 0.9636, Acc: -0.39% | Val Loss: 1.1249, Acc: -1.00%\n",
      "Epoch 20: Train Loss: 0.9625, Acc: -0.28% | Val Loss: 1.1252, Acc: -1.02%\n",
      "Epoch 30: Train Loss: 0.9625, Acc: -0.44% | Val Loss: 1.1254, Acc: -1.04%\n",
      "Epoch 40: Train Loss: 0.9625, Acc: -1.16% | Val Loss: 1.1255, Acc: -1.05%\n",
      "Final Validation score: -0.0106\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0106\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.00021544346900318823, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1872, Acc: -12.17% | Val Loss: 0.8576, Acc: -16.53%\n",
      "Epoch 10: Train Loss: 0.8693, Acc: 17.36% | Val Loss: 0.7185, Acc: 2.37%\n",
      "Epoch 20: Train Loss: 0.8362, Acc: 20.41% | Val Loss: 0.7116, Acc: 3.31%\n",
      "Epoch 30: Train Loss: 0.8347, Acc: 20.75% | Val Loss: 0.6996, Acc: 4.94%\n",
      "Epoch 40: Train Loss: 0.8319, Acc: 20.69% | Val Loss: 0.7017, Acc: 4.65%\n",
      "Final Validation score: 0.0349\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.0349\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.00021544346900318823, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0520, Acc: -8.88% | Val Loss: 1.1104, Acc: -3.27%\n",
      "Epoch 10: Train Loss: 0.9723, Acc: -0.14% | Val Loss: 1.0888, Acc: -1.26%\n",
      "Epoch 20: Train Loss: 0.9739, Acc: -0.39% | Val Loss: 1.0874, Acc: -1.13%\n",
      "Epoch 30: Train Loss: 0.9734, Acc: -0.71% | Val Loss: 1.0928, Acc: -1.64%\n",
      "Epoch 40: Train Loss: 0.9722, Acc: -0.13% | Val Loss: 1.0900, Acc: -1.38%\n",
      "Final Validation score: -0.0152\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0152\n",
      "6 <class 'src.activation_functions.Activation_ReLU'> 0.00021544346900318823 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.00021544346900318823, 'l2': 0.1, 'dropout_rate': 0.00021544346900318823, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.00206913808111479, 'patience': 50, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1488, Acc: -20.06% | Val Loss: 1.0037, Acc: 2.86%\n",
      "Epoch 10: Train Loss: 0.9821, Acc: -0.42% | Val Loss: 1.0473, Acc: -1.36%\n",
      "Epoch 20: Train Loss: 0.9818, Acc: -0.70% | Val Loss: 1.0480, Acc: -1.43%\n",
      "Epoch 30: Train Loss: 0.9817, Acc: -0.64% | Val Loss: 1.0483, Acc: -1.45%\n",
      "Epoch 40: Train Loss: 0.9817, Acc: -1.07% | Val Loss: 1.0484, Acc: -1.47%\n",
      "Final Validation score: -0.0149\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0149\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0028\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.0005994842503189409, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1777, Acc: -22.48% | Val Loss: 1.1346, Acc: -16.69%\n",
      "Epoch 10: Train Loss: 0.8383, Acc: 14.08% | Val Loss: 0.8228, Acc: 15.37%\n",
      "Epoch 20: Train Loss: 0.7959, Acc: 18.58% | Val Loss: 0.7834, Acc: 19.43%\n",
      "Epoch 30: Train Loss: 0.7878, Acc: 20.93% | Val Loss: 0.7861, Acc: 19.16%\n",
      "Epoch 40: Train Loss: 0.7818, Acc: 20.50% | Val Loss: 0.7924, Acc: 18.50%\n",
      "Epoch 50: Train Loss: 0.7372, Acc: 25.27% | Val Loss: 0.7526, Acc: 22.60%\n",
      "Early stopping at epoch 53\n",
      "Restoring model weights from epoch 43\n",
      "Final Validation score: 0.2273\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.2273\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.0005994842503189409, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2049, Acc: -29.96% | Val Loss: 1.1933, Acc: -7.14%\n",
      "Epoch 10: Train Loss: 0.9661, Acc: -1.41% | Val Loss: 1.1165, Acc: -0.24%\n",
      "Early stopping at epoch 13\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0031\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0031\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.0005994842503189409, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2502, Acc: -23.30% | Val Loss: 1.0046, Acc: -36.50%\n",
      "Epoch 10: Train Loss: 0.8329, Acc: 19.60% | Val Loss: 0.6870, Acc: 6.66%\n",
      "Early stopping at epoch 17\n",
      "Restoring model weights from epoch 7\n",
      "Final Validation score: 0.0741\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.0741\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.0005994842503189409, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1754, Acc: -22.88% | Val Loss: 1.3235, Acc: -23.09%\n",
      "Epoch 10: Train Loss: 0.8579, Acc: 9.91% | Val Loss: 1.0199, Acc: 5.15%\n",
      "Epoch 20: Train Loss: 0.8308, Acc: 13.43% | Val Loss: 0.9990, Acc: 7.09%\n",
      "Epoch 30: Train Loss: 0.8178, Acc: 15.45% | Val Loss: 0.9892, Acc: 8.00%\n",
      "Epoch 40: Train Loss: 0.8105, Acc: 16.85% | Val Loss: 0.9923, Acc: 7.71%\n",
      "Epoch 50: Train Loss: 0.8073, Acc: 17.32% | Val Loss: 0.9762, Acc: 9.21%\n",
      "Epoch 60: Train Loss: 0.8032, Acc: 16.88% | Val Loss: 0.9793, Acc: 8.92%\n",
      "Epoch 70: Train Loss: 0.8011, Acc: 15.83% | Val Loss: 0.9740, Acc: 9.41%\n",
      "Early stopping at epoch 78\n",
      "Restoring model weights from epoch 68\n",
      "Final Validation score: 0.0869\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.0869\n",
      "5 <class 'src.activation_functions.Activation_ReLU'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.01438449888287663, 'l1': 0.0005994842503189409, 'l2': 0.012915496650148827, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 6.951927961775606e-05, 'patience': 10, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1280, Acc: -28.87% | Val Loss: 0.9939, Acc: 3.80%\n",
      "Epoch 10: Train Loss: 0.7994, Acc: 15.81% | Val Loss: 0.8537, Acc: 17.37%\n",
      "Epoch 20: Train Loss: 0.7220, Acc: 25.18% | Val Loss: 0.7308, Acc: 29.27%\n",
      "Epoch 30: Train Loss: 0.6942, Acc: 27.43% | Val Loss: 0.6931, Acc: 32.92%\n",
      "Epoch 40: Train Loss: 0.6806, Acc: 30.12% | Val Loss: 0.6757, Acc: 34.61%\n",
      "Epoch 50: Train Loss: 0.6759, Acc: 30.49% | Val Loss: 0.6723, Acc: 34.93%\n",
      "Epoch 60: Train Loss: 0.6894, Acc: 28.30% | Val Loss: 0.6631, Acc: 35.82%\n",
      "Epoch 70: Train Loss: 0.6704, Acc: 31.20% | Val Loss: 0.6483, Acc: 37.25%\n",
      "Epoch 80: Train Loss: 0.6669, Acc: 30.03% | Val Loss: 0.6600, Acc: 36.12%\n",
      "Early stopping at epoch 89\n",
      "Restoring model weights from epoch 79\n",
      "Final Validation score: 0.3830\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.3830\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.1537\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.2341, Acc: -25.13% | Val Loss: 1.1141, Acc: -14.58%\n",
      "Epoch 10: Train Loss: 0.6720, Acc: 30.60% | Val Loss: 0.7026, Acc: 27.74%\n",
      "Epoch 20: Train Loss: 0.6300, Acc: 36.50% | Val Loss: 0.6667, Acc: 31.43%\n",
      "Epoch 30: Train Loss: 0.6161, Acc: 37.79% | Val Loss: 0.6550, Acc: 32.63%\n",
      "Epoch 40: Train Loss: 0.5978, Acc: 39.76% | Val Loss: 0.6518, Acc: 32.96%\n",
      "Final Validation score: 0.3322\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.3322\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0582, Acc: -10.45% | Val Loss: 0.8734, Acc: 21.58%\n",
      "Epoch 10: Train Loss: 0.6537, Acc: 30.04% | Val Loss: 0.6408, Acc: 42.46%\n",
      "Epoch 20: Train Loss: 0.6236, Acc: 34.90% | Val Loss: 0.6180, Acc: 44.51%\n",
      "Epoch 30: Train Loss: 0.6166, Acc: 34.12% | Val Loss: 0.6115, Acc: 45.10%\n",
      "Epoch 40: Train Loss: 0.6139, Acc: 36.18% | Val Loss: 0.6070, Acc: 45.50%\n",
      "Final Validation score: 0.4558\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4558\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1686, Acc: -11.26% | Val Loss: 0.8621, Acc: -17.14%\n",
      "Epoch 10: Train Loss: 0.6949, Acc: 32.01% | Val Loss: 0.5482, Acc: 25.51%\n",
      "Epoch 20: Train Loss: 0.6601, Acc: 37.17% | Val Loss: 0.5167, Acc: 29.79%\n",
      "Epoch 30: Train Loss: 0.6493, Acc: 36.80% | Val Loss: 0.5122, Acc: 30.40%\n",
      "Epoch 40: Train Loss: 0.6357, Acc: 36.93% | Val Loss: 0.5092, Acc: 30.81%\n",
      "Final Validation score: 0.3076\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.3076\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.0370, Acc: -9.51% | Val Loss: 1.0549, Acc: 1.89%\n",
      "Epoch 10: Train Loss: 0.6347, Acc: 34.30% | Val Loss: 0.7281, Acc: 32.28%\n",
      "Epoch 20: Train Loss: 0.6074, Acc: 37.45% | Val Loss: 0.6968, Acc: 35.19%\n",
      "Epoch 30: Train Loss: 0.5933, Acc: 38.57% | Val Loss: 0.6902, Acc: 35.81%\n",
      "Epoch 40: Train Loss: 0.5951, Acc: 38.92% | Val Loss: 0.6852, Acc: 36.28%\n",
      "Final Validation score: 0.3630\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.3630\n",
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier'}\n",
      "Epoch 0: Train Loss: 1.1126, Acc: -19.01% | Val Loss: 0.8819, Acc: 14.65%\n",
      "Epoch 10: Train Loss: 0.6853, Acc: 29.73% | Val Loss: 0.6076, Acc: 41.20%\n",
      "Epoch 20: Train Loss: 0.6416, Acc: 33.90% | Val Loss: 0.5864, Acc: 43.24%\n",
      "Epoch 30: Train Loss: 0.6393, Acc: 33.63% | Val Loss: 0.5776, Acc: 44.09%\n",
      "Epoch 40: Train Loss: 0.6205, Acc: 34.50% | Val Loss: 0.5729, Acc: 44.56%\n",
      "Final Validation score: 0.4449\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4449\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.3807\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00018329807108324357, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.3780, Acc: -44.50% | Val Loss: 1.4642, Acc: -50.59%\n",
      "Epoch 10: Train Loss: 1.2716, Acc: -32.06% | Val Loss: 1.3415, Acc: -37.97%\n",
      "Epoch 20: Train Loss: 1.1817, Acc: -21.64% | Val Loss: 1.2342, Acc: -26.93%\n",
      "Epoch 30: Train Loss: 1.1091, Acc: -12.21% | Val Loss: 1.1467, Acc: -17.93%\n",
      "Epoch 40: Train Loss: 1.0630, Acc: -7.88% | Val Loss: 1.0881, Acc: -11.91%\n",
      "Epoch 50: Train Loss: 1.0371, Acc: -5.83% | Val Loss: 1.0539, Acc: -8.39%\n",
      "Epoch 60: Train Loss: 1.0241, Acc: -4.39% | Val Loss: 1.0339, Acc: -6.33%\n",
      "Epoch 70: Train Loss: 1.0163, Acc: -4.00% | Val Loss: 1.0216, Acc: -5.07%\n",
      "Epoch 80: Train Loss: 1.0115, Acc: -2.81% | Val Loss: 1.0135, Acc: -4.23%\n",
      "Epoch 90: Train Loss: 1.0086, Acc: -3.29% | Val Loss: 1.0079, Acc: -3.66%\n",
      "Final Validation score: -0.0328\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0328\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00018329807108324357, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2868, Acc: -41.33% | Val Loss: 1.2696, Acc: -13.99%\n",
      "Epoch 10: Train Loss: 1.1152, Acc: -22.66% | Val Loss: 1.1593, Acc: -4.09%\n",
      "Epoch 20: Train Loss: 1.0453, Acc: -10.70% | Val Loss: 1.1251, Acc: -1.02%\n",
      "Epoch 30: Train Loss: 1.0130, Acc: -6.32% | Val Loss: 1.1149, Acc: -0.10%\n",
      "Epoch 40: Train Loss: 0.9972, Acc: -9.11% | Val Loss: 1.1118, Acc: 0.17%\n",
      "Epoch 50: Train Loss: 0.9879, Acc: -4.13% | Val Loss: 1.1112, Acc: 0.23%\n",
      "Epoch 60: Train Loss: 0.9822, Acc: -3.77% | Val Loss: 1.1115, Acc: 0.20%\n",
      "Epoch 70: Train Loss: 0.9782, Acc: -3.45% | Val Loss: 1.1121, Acc: 0.15%\n",
      "Epoch 80: Train Loss: 0.9755, Acc: -2.88% | Val Loss: 1.1130, Acc: 0.07%\n",
      "Epoch 90: Train Loss: 0.9729, Acc: -2.81% | Val Loss: 1.1137, Acc: 0.01%\n",
      "Final Validation score: -0.0005\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0005\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00018329807108324357, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2985, Acc: -27.50% | Val Loss: 0.9655, Acc: -31.19%\n",
      "Epoch 10: Train Loss: 1.2110, Acc: -15.46% | Val Loss: 0.8852, Acc: -20.28%\n",
      "Epoch 20: Train Loss: 1.1482, Acc: -9.43% | Val Loss: 0.8301, Acc: -12.79%\n",
      "Epoch 30: Train Loss: 1.1116, Acc: -5.65% | Val Loss: 0.8002, Acc: -8.73%\n",
      "Epoch 40: Train Loss: 1.0917, Acc: -5.03% | Val Loss: 0.7848, Acc: -6.63%\n",
      "Epoch 50: Train Loss: 1.0801, Acc: -3.42% | Val Loss: 0.7769, Acc: -5.57%\n",
      "Epoch 60: Train Loss: 1.0732, Acc: -3.54% | Val Loss: 0.7725, Acc: -4.97%\n",
      "Epoch 70: Train Loss: 1.0687, Acc: -3.36% | Val Loss: 0.7701, Acc: -4.64%\n",
      "Epoch 80: Train Loss: 1.0658, Acc: -1.00% | Val Loss: 0.7689, Acc: -4.47%\n",
      "Epoch 90: Train Loss: 1.0637, Acc: -3.14% | Val Loss: 0.7678, Acc: -4.33%\n",
      "Final Validation score: -0.0431\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0431\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00018329807108324357, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0255, Acc: -7.65% | Val Loss: 1.1580, Acc: -7.70%\n",
      "Epoch 10: Train Loss: 0.9968, Acc: -3.55% | Val Loss: 1.1254, Acc: -4.66%\n",
      "Epoch 20: Train Loss: 0.9867, Acc: -1.91% | Val Loss: 1.1124, Acc: -3.46%\n",
      "Epoch 30: Train Loss: 0.9819, Acc: -2.86% | Val Loss: 1.1063, Acc: -2.88%\n",
      "Epoch 40: Train Loss: 0.9792, Acc: -1.52% | Val Loss: 1.1025, Acc: -2.54%\n",
      "Epoch 50: Train Loss: 0.9775, Acc: -2.46% | Val Loss: 1.1002, Acc: -2.32%\n",
      "Epoch 60: Train Loss: 0.9764, Acc: -1.46% | Val Loss: 1.0987, Acc: -2.18%\n",
      "Epoch 70: Train Loss: 0.9756, Acc: -1.76% | Val Loss: 1.0975, Acc: -2.07%\n",
      "Epoch 80: Train Loss: 0.9748, Acc: -2.25% | Val Loss: 1.0966, Acc: -1.98%\n",
      "Epoch 90: Train Loss: 0.9746, Acc: -2.62% | Val Loss: 1.0958, Acc: -1.91%\n",
      "Final Validation score: -0.0187\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0187\n",
      "5 <class 'src.activation_functions.Activation_Sigmoid'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Sigmoid'>, 'batch_norm': False, 'learning_rate': 0.001623776739188721, 'l1': 0.0016681005372000592, 'l2': 0.1, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.00018329807108324357, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0967, Acc: -15.71% | Val Loss: 1.0934, Acc: -5.83%\n",
      "Epoch 10: Train Loss: 1.0409, Acc: -7.47% | Val Loss: 1.0590, Acc: -2.49%\n",
      "Epoch 20: Train Loss: 1.0168, Acc: -7.18% | Val Loss: 1.0474, Acc: -1.37%\n",
      "Epoch 30: Train Loss: 1.0050, Acc: -4.92% | Val Loss: 1.0436, Acc: -1.00%\n",
      "Epoch 40: Train Loss: 0.9983, Acc: -4.45% | Val Loss: 1.0424, Acc: -0.88%\n",
      "Epoch 50: Train Loss: 0.9949, Acc: -2.73% | Val Loss: 1.0422, Acc: -0.86%\n",
      "Epoch 60: Train Loss: 0.9915, Acc: -2.36% | Val Loss: 1.0424, Acc: -0.88%\n",
      "Epoch 70: Train Loss: 0.9896, Acc: -2.62% | Val Loss: 1.0427, Acc: -0.91%\n",
      "Epoch 80: Train Loss: 0.9882, Acc: -4.00% | Val Loss: 1.0431, Acc: -0.95%\n",
      "Epoch 90: Train Loss: 0.9876, Acc: -1.36% | Val Loss: 1.0435, Acc: -0.99%\n",
      "Final Validation score: -0.0102\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0102\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0211\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2308, Acc: -23.37% | Val Loss: 1.2987, Acc: -33.57%\n",
      "Epoch 10: Train Loss: 1.2196, Acc: -22.99% | Val Loss: 1.2855, Acc: -32.21%\n",
      "Epoch 20: Train Loss: 1.2092, Acc: -21.90% | Val Loss: 1.2731, Acc: -30.94%\n",
      "Epoch 30: Train Loss: 1.1994, Acc: -21.89% | Val Loss: 1.2614, Acc: -29.73%\n",
      "Epoch 40: Train Loss: 1.1902, Acc: -19.24% | Val Loss: 1.2504, Acc: -28.60%\n",
      "Final Validation score: -0.2763\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.2763\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2386, Acc: -34.14% | Val Loss: 1.2671, Acc: -13.77%\n",
      "Epoch 10: Train Loss: 1.2244, Acc: -28.68% | Val Loss: 1.2602, Acc: -13.15%\n",
      "Epoch 20: Train Loss: 1.2095, Acc: -27.25% | Val Loss: 1.2540, Acc: -12.59%\n",
      "Epoch 30: Train Loss: 1.1913, Acc: -27.64% | Val Loss: 1.2471, Acc: -11.97%\n",
      "Epoch 40: Train Loss: 1.1677, Acc: -22.86% | Val Loss: 1.2354, Acc: -10.92%\n",
      "Final Validation score: -0.0916\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0916\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2876, Acc: -26.11% | Val Loss: 1.0720, Acc: -45.66%\n",
      "Epoch 10: Train Loss: 1.2759, Acc: -21.54% | Val Loss: 1.0563, Acc: -43.53%\n",
      "Epoch 20: Train Loss: 1.2636, Acc: -21.77% | Val Loss: 1.0390, Acc: -41.18%\n",
      "Epoch 30: Train Loss: 1.2499, Acc: -18.78% | Val Loss: 1.0192, Acc: -38.49%\n",
      "Epoch 40: Train Loss: 1.2345, Acc: -18.26% | Val Loss: 0.9962, Acc: -35.36%\n",
      "Final Validation score: -0.3210\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.3210\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2033, Acc: -24.41% | Val Loss: 1.4065, Acc: -30.81%\n",
      "Epoch 10: Train Loss: 1.1825, Acc: -24.21% | Val Loss: 1.3822, Acc: -28.55%\n",
      "Epoch 20: Train Loss: 1.1575, Acc: -20.28% | Val Loss: 1.3520, Acc: -25.74%\n",
      "Epoch 30: Train Loss: 1.1204, Acc: -18.56% | Val Loss: 1.3090, Acc: -21.74%\n",
      "Epoch 40: Train Loss: 1.0574, Acc: -9.63% | Val Loss: 1.2343, Acc: -14.79%\n",
      "Final Validation score: -0.0642\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0642\n",
      "4 <class 'src.activation_functions.Activation_ReLU'> 0.004641588833612777 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 4, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.001, 'l1': 1e-05, 'l2': 0.0005994842503189409, 'dropout_rate': 0.004641588833612777, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.0004832930238571752, 'patience': 30, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2618, Acc: -31.49% | Val Loss: 1.1742, Acc: -13.64%\n",
      "Epoch 10: Train Loss: 1.2447, Acc: -29.08% | Val Loss: 1.1604, Acc: -12.31%\n",
      "Epoch 20: Train Loss: 1.2269, Acc: -26.52% | Val Loss: 1.1464, Acc: -10.95%\n",
      "Epoch 30: Train Loss: 1.2083, Acc: -23.38% | Val Loss: 1.1322, Acc: -9.58%\n",
      "Epoch 40: Train Loss: 1.1898, Acc: -21.71% | Val Loss: 1.1184, Acc: -8.24%\n",
      "Final Validation score: -0.0709\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0709\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.1648\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2041, Acc: -23.35% | Val Loss: 1.2197, Acc: -25.44%\n",
      "Epoch 10: Train Loss: 1.0157, Acc: -2.69% | Val Loss: 1.0178, Acc: -4.68%\n",
      "Epoch 20: Train Loss: 1.0048, Acc: -1.60% | Val Loss: 0.9988, Acc: -2.73%\n",
      "Epoch 30: Train Loss: 1.0023, Acc: -0.54% | Val Loss: 0.9933, Acc: -2.16%\n",
      "Epoch 40: Train Loss: 1.0012, Acc: -0.95% | Val Loss: 0.9906, Acc: -1.88%\n",
      "Epoch 50: Train Loss: 1.0007, Acc: -0.78% | Val Loss: 0.9890, Acc: -1.71%\n",
      "Epoch 60: Train Loss: 1.0003, Acc: -0.75% | Val Loss: 0.9879, Acc: -1.60%\n",
      "Epoch 70: Train Loss: 1.0001, Acc: -1.28% | Val Loss: 0.9871, Acc: -1.52%\n",
      "Epoch 80: Train Loss: 1.0000, Acc: -0.63% | Val Loss: 0.9865, Acc: -1.46%\n",
      "Epoch 90: Train Loss: 0.9998, Acc: -1.04% | Val Loss: 0.9860, Acc: -1.41%\n",
      "Final Validation score: -0.0137\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0137\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.1612, Acc: -23.95% | Val Loss: 1.1474, Acc: -3.02%\n",
      "Epoch 10: Train Loss: 0.9637, Acc: -1.51% | Val Loss: 1.1224, Acc: -0.78%\n",
      "Early stopping at epoch 11\n",
      "Restoring model weights from epoch 1\n",
      "Final Validation score: -0.0079\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0079\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2185, Acc: -15.69% | Val Loss: 0.8863, Acc: -20.43%\n",
      "Epoch 10: Train Loss: 1.0577, Acc: -1.00% | Val Loss: 0.7733, Acc: -5.07%\n",
      "Early stopping at epoch 13\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0488\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0488\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.1609, Acc: -19.94% | Val Loss: 1.2882, Acc: -19.81%\n",
      "Epoch 10: Train Loss: 0.9747, Acc: -1.35% | Val Loss: 1.1005, Acc: -2.35%\n",
      "Epoch 20: Train Loss: 0.9734, Acc: -0.49% | Val Loss: 1.0958, Acc: -1.91%\n",
      "Epoch 30: Train Loss: 0.9730, Acc: -0.31% | Val Loss: 1.0944, Acc: -1.78%\n",
      "Epoch 40: Train Loss: 0.9733, Acc: -0.73% | Val Loss: 1.0936, Acc: -1.71%\n",
      "Epoch 50: Train Loss: 0.9728, Acc: -0.77% | Val Loss: 1.0931, Acc: -1.66%\n",
      "Epoch 60: Train Loss: 0.9733, Acc: -0.30% | Val Loss: 1.0927, Acc: -1.63%\n",
      "Epoch 70: Train Loss: 0.9727, Acc: -0.55% | Val Loss: 1.0925, Acc: -1.61%\n",
      "Epoch 80: Train Loss: 0.9726, Acc: -1.01% | Val Loss: 1.0924, Acc: -1.59%\n",
      "Epoch 90: Train Loss: 0.9726, Acc: -0.47% | Val Loss: 1.0922, Acc: -1.58%\n",
      "Final Validation score: -0.0157\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0157\n",
      "5 <class 'src.activation_functions.Activation_Leaky_ReLU'> 0.0005994842503189409 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 5, 'hidden_activation': <class 'src.activation_functions.Activation_Leaky_ReLU'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.03593813663804626, 'l2': 0.004641588833612777, 'dropout_rate': 0.0005994842503189409, 'batch_size': 32, 'n_epochs': 100, 'weight_decay': 0.06158482110660261, 'patience': 10, 'CC': False, 'weights_init': 'random'}\n",
      "Epoch 0: Train Loss: 1.2126, Acc: -25.29% | Val Loss: 1.0985, Acc: -6.32%\n",
      "Epoch 10: Train Loss: 0.9851, Acc: -1.64% | Val Loss: 1.0424, Acc: -0.88%\n",
      "Early stopping at epoch 13\n",
      "Restoring model weights from epoch 3\n",
      "Final Validation score: -0.0097\n",
      "âœ… Fold 5/5 | Validation Accuracy: -0.0097\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0191\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.3024, Acc: -36.24% | Val Loss: 1.3131, Acc: -35.05%\n",
      "Epoch 10: Train Loss: 1.0622, Acc: -8.24% | Val Loss: 1.0835, Acc: -11.43%\n",
      "Epoch 20: Train Loss: 1.0322, Acc: -9.85% | Val Loss: 1.0432, Acc: -7.29%\n",
      "Epoch 30: Train Loss: 1.0207, Acc: -3.77% | Val Loss: 1.0261, Acc: -5.53%\n",
      "Epoch 40: Train Loss: 1.0146, Acc: -4.11% | Val Loss: 1.0165, Acc: -4.54%\n",
      "Epoch 50: Train Loss: 1.0111, Acc: -2.30% | Val Loss: 1.0106, Acc: -3.94%\n",
      "Epoch 60: Train Loss: 1.0089, Acc: -2.70% | Val Loss: 1.0066, Acc: -3.53%\n",
      "Epoch 70: Train Loss: 1.0074, Acc: -2.23% | Val Loss: 1.0037, Acc: -3.23%\n",
      "Epoch 80: Train Loss: 1.0062, Acc: -3.19% | Val Loss: 1.0015, Acc: -3.00%\n",
      "Epoch 90: Train Loss: 1.0054, Acc: -2.78% | Val Loss: 0.9998, Acc: -2.83%\n",
      "Final Validation score: -0.0270\n",
      "âœ… Fold 1/5 | Validation Accuracy: -0.0270\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2305, Acc: -37.32% | Val Loss: 1.2527, Acc: -12.48%\n",
      "Epoch 10: Train Loss: 1.1128, Acc: -18.51% | Val Loss: 1.1762, Acc: -5.60%\n",
      "Epoch 20: Train Loss: 1.0010, Acc: -4.64% | Val Loss: 1.1360, Acc: -1.99%\n",
      "Epoch 30: Train Loss: 0.9821, Acc: -2.90% | Val Loss: 1.1292, Acc: -1.39%\n",
      "Epoch 40: Train Loss: 0.9753, Acc: -3.60% | Val Loss: 1.1270, Acc: -1.19%\n",
      "Epoch 50: Train Loss: 0.9720, Acc: -3.10% | Val Loss: 1.1261, Acc: -1.11%\n",
      "Epoch 60: Train Loss: 0.9701, Acc: -3.19% | Val Loss: 1.1257, Acc: -1.07%\n",
      "Epoch 70: Train Loss: 0.9688, Acc: -2.16% | Val Loss: 1.1254, Acc: -1.05%\n",
      "Epoch 80: Train Loss: 0.9679, Acc: -2.64% | Val Loss: 1.1253, Acc: -1.03%\n",
      "Epoch 90: Train Loss: 0.9673, Acc: -1.34% | Val Loss: 1.1252, Acc: -1.03%\n",
      "Final Validation score: -0.0102\n",
      "âœ… Fold 2/5 | Validation Accuracy: -0.0102\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2556, Acc: -22.68% | Val Loss: 1.0283, Acc: -39.72%\n",
      "Epoch 10: Train Loss: 1.0938, Acc: -4.05% | Val Loss: 0.8045, Acc: -9.31%\n",
      "Epoch 20: Train Loss: 1.0674, Acc: -1.57% | Val Loss: 0.7881, Acc: -7.08%\n",
      "Epoch 30: Train Loss: 1.0617, Acc: -2.83% | Val Loss: 0.7804, Acc: -6.03%\n",
      "Epoch 40: Train Loss: 1.0596, Acc: -2.51% | Val Loss: 0.7767, Acc: -5.53%\n",
      "Epoch 50: Train Loss: 1.0586, Acc: -0.83% | Val Loss: 0.7749, Acc: -5.30%\n",
      "Epoch 60: Train Loss: 1.0579, Acc: -0.67% | Val Loss: 0.7741, Acc: -5.18%\n",
      "Epoch 70: Train Loss: 1.0575, Acc: -3.49% | Val Loss: 0.7733, Acc: -5.07%\n",
      "Epoch 80: Train Loss: 1.0572, Acc: -1.22% | Val Loss: 0.7727, Acc: -5.00%\n",
      "Epoch 90: Train Loss: 1.0569, Acc: -1.70% | Val Loss: 0.7723, Acc: -4.94%\n",
      "Final Validation score: -0.0492\n",
      "âœ… Fold 3/5 | Validation Accuracy: -0.0492\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.2014, Acc: -26.34% | Val Loss: 1.3770, Acc: -28.06%\n",
      "Epoch 10: Train Loss: 1.0622, Acc: -9.90% | Val Loss: 1.2212, Acc: -13.58%\n",
      "Epoch 20: Train Loss: 1.0097, Acc: -7.59% | Val Loss: 1.1518, Acc: -7.12%\n",
      "Epoch 30: Train Loss: 0.9874, Acc: -4.06% | Val Loss: 1.1205, Acc: -4.21%\n",
      "Epoch 40: Train Loss: 0.9812, Acc: -2.21% | Val Loss: 1.1106, Acc: -3.29%\n",
      "Epoch 50: Train Loss: 0.9785, Acc: -1.99% | Val Loss: 1.1056, Acc: -2.83%\n",
      "Epoch 60: Train Loss: 0.9771, Acc: -5.29% | Val Loss: 1.1028, Acc: -2.57%\n",
      "Epoch 70: Train Loss: 0.9762, Acc: -1.81% | Val Loss: 1.1010, Acc: -2.40%\n",
      "Epoch 80: Train Loss: 0.9756, Acc: -1.56% | Val Loss: 1.0997, Acc: -2.27%\n",
      "Epoch 90: Train Loss: 0.9752, Acc: -1.38% | Val Loss: 1.0986, Acc: -2.18%\n",
      "Final Validation score: -0.0211\n",
      "âœ… Fold 4/5 | Validation Accuracy: -0.0211\n",
      "3 <class 'src.activation_functions.Activation_ReLU'> 2.782559402207126e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 3, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_ReLU'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 0.1, 'l2': 0.0005994842503189409, 'dropout_rate': 2.782559402207126e-05, 'batch_size': 16, 'n_epochs': 100, 'weight_decay': 0.01438449888287663, 'patience': 50, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1917, Acc: -31.32% | Val Loss: 1.0637, Acc: -2.95%\n",
      "Epoch 10: Train Loss: 1.0181, Acc: -6.46% | Val Loss: 0.9954, Acc: 3.66%\n",
      "Epoch 20: Train Loss: 1.0138, Acc: -5.92% | Val Loss: 1.0095, Acc: 2.30%\n",
      "Epoch 30: Train Loss: 1.0165, Acc: -3.97% | Val Loss: 1.0217, Acc: 1.12%\n",
      "Epoch 40: Train Loss: 1.0105, Acc: -7.02% | Val Loss: 1.0238, Acc: 0.92%\n",
      "Epoch 50: Train Loss: 1.0051, Acc: -4.75% | Val Loss: 1.0252, Acc: 0.78%\n",
      "Early stopping at epoch 55\n",
      "Restoring model weights from epoch 5\n",
      "Final Validation score: 0.0072\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.0072\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: -0.0201\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.1058, Acc: -12.10% | Val Loss: 0.9765, Acc: -0.43%\n",
      "Epoch 10: Train Loss: 0.6641, Acc: 33.07% | Val Loss: 0.7167, Acc: 26.29%\n",
      "Epoch 20: Train Loss: 0.6209, Acc: 36.92% | Val Loss: 0.6799, Acc: 30.08%\n",
      "Epoch 30: Train Loss: 0.6072, Acc: 38.55% | Val Loss: 0.6663, Acc: 31.47%\n",
      "Epoch 40: Train Loss: 0.5977, Acc: 40.33% | Val Loss: 0.6587, Acc: 32.26%\n",
      "Final Validation score: 0.3246\n",
      "âœ… Fold 1/5 | Validation Accuracy: 0.3246\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0184, Acc: -7.99% | Val Loss: 0.9242, Acc: 17.02%\n",
      "Epoch 10: Train Loss: 0.6496, Acc: 32.08% | Val Loss: 0.6970, Acc: 37.42%\n",
      "Epoch 20: Train Loss: 0.6282, Acc: 34.01% | Val Loss: 0.6791, Acc: 39.02%\n",
      "Epoch 30: Train Loss: 0.6175, Acc: 35.48% | Val Loss: 0.6582, Acc: 40.90%\n",
      "Epoch 40: Train Loss: 0.6036, Acc: 36.44% | Val Loss: 0.6208, Acc: 44.26%\n",
      "Final Validation score: 0.4509\n",
      "âœ… Fold 2/5 | Validation Accuracy: 0.4509\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0864, Acc: -2.30% | Val Loss: 0.8034, Acc: -9.16%\n",
      "Epoch 10: Train Loss: 0.6938, Acc: 33.93% | Val Loss: 0.5754, Acc: 21.82%\n",
      "Epoch 20: Train Loss: 0.6593, Acc: 37.53% | Val Loss: 0.5684, Acc: 22.77%\n",
      "Epoch 30: Train Loss: 0.6532, Acc: 37.72% | Val Loss: 0.5657, Acc: 23.13%\n",
      "Epoch 40: Train Loss: 0.6500, Acc: 37.36% | Val Loss: 0.5631, Acc: 23.48%\n",
      "Final Validation score: 0.2368\n",
      "âœ… Fold 3/5 | Validation Accuracy: 0.2368\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 0.8713, Acc: 9.83% | Val Loss: 0.8511, Acc: 20.85%\n",
      "Epoch 10: Train Loss: 0.6003, Acc: 37.54% | Val Loss: 0.7030, Acc: 34.61%\n",
      "Epoch 20: Train Loss: 0.5933, Acc: 37.57% | Val Loss: 0.6929, Acc: 35.56%\n",
      "Epoch 30: Train Loss: 0.5820, Acc: 38.93% | Val Loss: 0.6923, Acc: 35.62%\n",
      "Epoch 40: Train Loss: 0.5794, Acc: 40.26% | Val Loss: 0.6886, Acc: 35.96%\n",
      "Final Validation score: 0.3607\n",
      "âœ… Fold 4/5 | Validation Accuracy: 0.3607\n",
      "5 <class 'src.activation_functions.Activation_Tanh'> 7.742636826811278e-05 False\n",
      "Data shapes:\n",
      "X_train: (160, 12), y_train: (160, 3)\n",
      "Hyperparams: {'hidden_size': 5, 'n_h_layers': 4, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.06158482110660261, 'l1': 0.0005994842503189409, 'l2': 2.782559402207126e-05, 'dropout_rate': 7.742636826811278e-05, 'batch_size': 32, 'n_epochs': 50, 'weight_decay': 0.03792690190732246, 'patience': 30, 'CC': False, 'weights_init': 'he'}\n",
      "Epoch 0: Train Loss: 1.0106, Acc: -5.51% | Val Loss: 0.8442, Acc: 18.30%\n",
      "Epoch 10: Train Loss: 0.6310, Acc: 35.06% | Val Loss: 0.5924, Acc: 42.66%\n",
      "Epoch 20: Train Loss: 0.6185, Acc: 36.31% | Val Loss: 0.5818, Acc: 43.69%\n",
      "Epoch 30: Train Loss: 0.6150, Acc: 34.86% | Val Loss: 0.5780, Acc: 44.06%\n",
      "Epoch 40: Train Loss: 0.6129, Acc: 35.53% | Val Loss: 0.5757, Acc: 44.28%\n",
      "Final Validation score: 0.4440\n",
      "âœ… Fold 5/5 | Validation Accuracy: 0.4440\n",
      "\n",
      "ðŸ“Š Manual K-Fold | Mean Validation Accuracy over 5 folds: 0.3634\n",
      "{'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier', 'val_accuracy': np.float64(0.38068977137334004)}\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams, best_performance = random_search(X_train=X_train,\n",
    "                                                   y_train=y_train,\n",
    "                                                   param_distributions=param_distributions,\n",
    "                                                   n_iters=50, regression=True)  # adjust n_iters as needed\n",
    "\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ba0459b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier', 'val_accuracy': np.float64(0.38068977137334004)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3e9a3af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 <class 'src.activation_functions.Activation_Tanh'> 0.03593813663804626 False\n",
      "Data shapes:\n",
      "X_train: (200, 12), y_train: (200, 3)\n",
      "Hyperparams: {'hidden_size': 6, 'n_h_layers': 3, 'hidden_activation': <class 'src.activation_functions.Activation_Tanh'>, 'batch_norm': False, 'learning_rate': 0.008858667904100823, 'l1': 1e-05, 'l2': 0.0016681005372000592, 'dropout_rate': 0.03593813663804626, 'batch_size': 16, 'n_epochs': 50, 'weight_decay': 0.0012742749857031334, 'patience': 30, 'CC': False, 'weights_init': 'xavier', 'val_accuracy': np.float64(0.38068977137334004)}\n",
      "Epoch 0: Train Loss: 1.1939, Acc: -24.20% | Val Loss: 1.2043, Acc: -18.05%\n",
      "Epoch 10: Train Loss: 0.7081, Acc: 27.23% | Val Loss: 0.7381, Acc: 27.65%\n",
      "Epoch 20: Train Loss: 0.6573, Acc: 32.34% | Val Loss: 0.6893, Acc: 32.44%\n",
      "Epoch 30: Train Loss: 0.6361, Acc: 33.41% | Val Loss: 0.6779, Acc: 33.56%\n",
      "Epoch 40: Train Loss: 0.6315, Acc: 35.52% | Val Loss: 0.6736, Acc: 33.98%\n",
      "Final Validation score: 0.3419\n",
      "Test score: 0.3419\n",
      "Final Validation RÂ² Score: 0.3419\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if best_hyperparams['CC']:\n",
    "    model = CascadeCorrelation(input_size = 12, output_size=3, activation=Activation_Leaky_ReLU, output_activation = Activation_Sigmoid)\n",
    "else:\n",
    "    model = NN(\n",
    "        l1=best_hyperparams['l1'],\n",
    "        l2=best_hyperparams['l2'],\n",
    "        input_size=12,\n",
    "        hidden_size=best_hyperparams['hidden_size'],\n",
    "        output_size=3,\n",
    "        hidden_activation=best_hyperparams['hidden_activation'],\n",
    "        dropout_rate=best_hyperparams['dropout_rate'],\n",
    "        use_batch_norm=best_hyperparams['batch_norm'],\n",
    "        n_h_layers=best_hyperparams['n_h_layers']\n",
    "    )\n",
    "\n",
    "train = Train(best_hyperparams, model, regression=True)\n",
    "train.train_and_evaluate(X_train, y_train, X_val, y_val)\n",
    "train.test(X_val, y_val)\n",
    "print(f\"Final Validation RÂ² Score: {train.test_score:.4f}\")\n",
    "train.plot(score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82601c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
